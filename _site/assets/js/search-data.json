{"0": {
    "doc": "Elysium documentation",
    "title": "Getting started",
    "content": ". | About OpenSearch | Quickstart | Install OpenSearch | Install OpenSearch Dashboards | See the FAQ | . ",
    "url": "http://localhost:4000/#getting-started",
    "relUrl": "/#getting-started"
  },"1": {
    "doc": "Elysium documentation",
    "title": "Why use OpenSearch?",
    "content": "With OpenSearch, you can perform the following use cases: . ",
    "url": "http://localhost:4000/#why-use-opensearch",
    "relUrl": "/#why-use-opensearch"
  },"2": {
    "doc": "Elysium documentation",
    "title": "Elysium documentation",
    "content": " ",
    "url": "http://localhost:4000/",
    "relUrl": "/"
  },"3": {
    "doc": "Overview",
    "title": "Overview",
    "content": "Get started using OpenSearch and OpenSearch Dashboards by deploying your containers with Docker. Before proceeding, you need to get Docker and Docker Compose installed on your local machine. ",
    "url": "http://localhost:4000/overview/",
    "relUrl": "/overview/"
  },"4": {
    "doc": "Quickstart",
    "title": "Quickstart",
    "content": "Get started using OpenSearch and OpenSearch Dashboards by deploying your containers with Docker. Before proceeding, you need to get Docker and Docker Compose installed on your local machine. ",
    "url": "http://localhost:4000/quickstart/",
    "relUrl": "/quickstart/"
  },"5": {
    "doc": "Version history",
    "title": "Version history",
    "content": "| OpenSearch version | Release highlights | Release date | . | 2.5.0 | Includes index management UI enhancements, multi-layer maps, Jaeger support for observability, Debian distributions, returning cluster health by awareness attribute, cluster manager task throttling, weighted zonal search request routing policy, and query string support in index rollups. Experimental features include request-level durability in remote-backed storage and GPU acceleration for ML nodes. For a full list of release highlights, see the Release Notes. | 24 January 2023 | . | 2.4.1 | Includes maintenance changes and bug fixes for gradle check and indexing pressure tests. Adds support for skipping changelog. | 13 December 2022 | . | 2.4.0 | Includes Windows support, Point-in-time search, custom k-NN filtering, xy_point and xy_shape field types for Cartesian coordinates, GeoHex grid aggregation, and resilience enhancements, including search backpressure. In OpenSearch Dashboards, this release adds snapshot restore functionality, multiple authentication, and aggregate view of saved objects. This release includes the following experimental features: searchable snapshots, Compare Search Results, multiple data sources in OpenSearch Dashboards, a new Model Serving Framework in ML Commons, a new Neural Search plugin that supports semantic search, and a new Security Analytics plugin to analyze security logs. For a full list of release highlights, see the Release Notes. | 15 November 2022 | . | 2.3.0 | This release includes the following experimental features: segment replication, remote-backed storage, and drag and drop for OpenSearch Dashboards. Experimental features allow you to test new functionality in OpenSearch. Because these features are still being developed, your testing and feedback can help shape the development of the feature before it’s official released. We do not recommend use of experimental features in production. Additionally, this release adds maketime and makedate datetime functions for the SQL plugin. Creates a new OpenSearch Playground demo site for OpenSearch Dashboards. For a full list of release highlights, see the Release Notes. | 14 September 2022 | . | 2.2.1 | Includes gradle updates and bug fixes for gradle check. | 01 September 2022 | . | 2.2.0 | Includes support for Logistic Regression and RCFSummarize machine learning algorithms in ML Commons, Lucene or C-based Nmslib and Faiss libraries for approximate k-NN search, search by relevance using SQL and PPL queries, custom region maps for visualizations, and rollup enhancements. For a full list of release highlights, see the Release Notes. | 11 August 2022 | . | 2.1.0 | Includes support for dedicated ML node in the ML Commons plugin, relevance search and other features in SQL, multi-terms aggregation, and Snapshot Management. For a full list of release highlights, see the Release Notes. | 07 July 2022 | . | 2.0.1 | Includes bug fixes and maintenance updates for Alerting and Anomaly Detection. | 16 June 2022 | . | 2.0.0 | Includes document-level monitors for alerting, OpenSearch Notifications plugins, and Geo Map Tiles in OpenSearch Dashboards. Also adds support for Lucene 9 and bug fixes for all OpenSearch plugins. For a full list of release highlights, see the Release Notes. | 26 May 2022 | . | 2.0.0-rc1 | The Release Candidate for 2.0.0. This version allows you to preview the upcoming 2.0.0 release before the GA release. The preview release adds document-level alerting, support for Lucene 9, and the ability to use term lookup queries in document level security. | 03 May 2022 | . | 1.3.7 | Adds Windows support. Includes maintenance updates and bug fixes for error handling. | 13 December 2022 | . | 1.3.6 | Includes maintenance updates and bug fixes for tenancy in the OpenSearch Security Dashboards plugin. | 06 October 2022 | . | 1.3.5 | Includes maintenance updates and bug fixes for gradle check and OpenSearch security. | 01 September 2022 | . | 1.3.4 | Includes maintenance updates and bug fixes for OpenSearch and OpenSearch Dashboards. | 14 July 2022 | . | 1.3.3 | Adds enhancements to Anomaly Detection and ML Commons. Bug fixes for Anomaly Detection, Observability, and k-NN. | 09 June 2022 | . | 1.3.2 | Bug fixes for Anomaly Detection and the Security Dashboards Plugin, adds the option to install OpenSearch using RPM, as well as enhancements to the ML Commons execute task, and the removal of the job-scheduler zip in Anomaly Detection. | 05 May 2022 | . | 1.3.1 | Bug fixes when using document-level security, and adjusted ML Commons to use the latest RCF jar and protostuff to RCF model serialization. | 30 March 2022 | . | 1.3.0 | Adds Model Type Validation to Validate Detector API, continuous transforms, custom actions, applied policy parameter to Explain API, default action retries, and new rollover and transition conditions to Index Management, new ML Commons plugin, parse command to SQL, Application Analytics, Live Tail, Correlation, and Events Flyout to Observability, and auto backport and support for OPENSEARCH_JAVA_HOME to Performance Analyzer. Bug fixes. | 17 March 2022 | . | 1.2.4 | Updates Performance Analyzer, SQL, and Security plugins to Log4j 2.17.1, Alerting and Job Scheduler to cron-utils 9.1.6, and gson in Anomaly Detection and SQL. | 18 January 2022 | . | 1.2.3 | Updates the version of Log4j used in OpenSearch to Log4j 2.17.0 as recommended by the advisory in CVE-2021-45105. | 22 December 2021 | . | 1.2.0 | Adds observability, new validation API for Anomaly Detection, shard-level indexing back-pressure, new “match” query type for SQL and PPL, support for Faiss libraries in k-NN, and custom Dashboards branding. | 23 November 2021 | . | 1.1.0 | Adds cross-cluster replication, security for Index Management, bucket-level alerting, a CLI to help with upgrading from Elasticsearch OSS to OpenSearch, and enhancements to high cardinality data in the anomaly detection plugin. | 05 October 2021 | . | 1.0.1 | Bug fixes. | 01 September 2021 | . | 1.0.0 | General availability release. Adds compatibility setting for clients that require a version check before connecting. | 12 July 2021 | . | 1.0.0-rc1 | First release candidate. | 07 June 2021 | . | 1.0.0-beta1 | Initial beta release. Refactors plugins to work with OpenSearch. | 13 May 2021 | . ",
    "url": "http://localhost:4000/version-history/",
    "relUrl": "/version-history/"
  },"6": {
    "doc": "Configure",
    "title": "Configure",
    "content": "Configuration Documentation . ",
    "url": "http://localhost:4000/configure/index.html",
    "relUrl": "/configure/index.html"
  },"7": {
    "doc": "Integrations",
    "title": "Elysium Integrations",
    "content": "search engine . ",
    "url": "http://localhost:4000/configure/integrations/index.html#elysium-integrations",
    "relUrl": "/configure/integrations/index.html#elysium-integrations"
  },"8": {
    "doc": "Integrations",
    "title": "Introduction",
    "content": "Elysium Integrations is a Integrations tool designed to help users quickly integrate and Monitor data within a database. ",
    "url": "http://localhost:4000/configure/integrations/index.html#introduction",
    "relUrl": "/configure/integrations/index.html#introduction"
  },"9": {
    "doc": "Integrations",
    "title": "Integrations",
    "content": " ",
    "url": "http://localhost:4000/configure/integrations/index.html",
    "relUrl": "/configure/integrations/index.html"
  },"10": {
    "doc": "Query Workbench",
    "title": "Elysium Query Workbench",
    "content": "search engine . ",
    "url": "http://localhost:4000/configure/query-workbench/index.html#elysium-query-workbench",
    "relUrl": "/configure/query-workbench/index.html#elysium-query-workbench"
  },"11": {
    "doc": "Query Workbench",
    "title": "Introduction",
    "content": "Elysium Query Workbench is a Monitor tool designed to help users quickly Monitor and Monitor data within a database. ",
    "url": "http://localhost:4000/configure/query-workbench/index.html#introduction",
    "relUrl": "/configure/query-workbench/index.html#introduction"
  },"12": {
    "doc": "Query Workbench",
    "title": "Query Workbench",
    "content": " ",
    "url": "http://localhost:4000/configure/query-workbench/index.html",
    "relUrl": "/configure/query-workbench/index.html"
  },"13": {
    "doc": "Stack Managements",
    "title": "Elysium Stack Managements",
    "content": "search engine . ",
    "url": "http://localhost:4000/configure/stack-managements/index.html#elysium-stack-managements",
    "relUrl": "/configure/stack-managements/index.html#elysium-stack-managements"
  },"14": {
    "doc": "Stack Managements",
    "title": "Introduction",
    "content": "Elysium Stack Managements is a Monitor tool designed to help users quickly Monitor and Monitor data within a database. ",
    "url": "http://localhost:4000/configure/stack-managements/index.html#introduction",
    "relUrl": "/configure/stack-managements/index.html#introduction"
  },"15": {
    "doc": "Stack Managements",
    "title": "Stack Managements",
    "content": " ",
    "url": "http://localhost:4000/configure/stack-managements/index.html",
    "relUrl": "/configure/stack-managements/index.html"
  },"16": {
    "doc": "Anomaly Detection",
    "title": "Anomaly detection",
    "content": "An anomaly in Elysium Analytics is any unusual behaviour change in your time-series data. Anomalies can provide valuable insights into your data. For example, for IT infrastructure data, an anomaly in the memory usage metric might help you uncover early signs of a system failure. It can be challenging to discover anomalies using conventional methods such as creating visualizations and dashboards. You could configure an alert based on a static threshold, but this requires prior domain knowledge and isn’t adaptive to data that exhibits organic growth or seasonalbehavior. Anomaly detection automatically detects anomalies in your data in near real-time using the Random Cut Forest (RCF) algorithm. RCF is an unsupervised machine learning algorithm that models a sketch of your incoming data stream to compute ananomaly gradeandconfidence scorevalue for each incoming data point. These values are used to differentiate an anomaly from normal variations. For more information about how RCF works, see. You can pair the anomaly detection plugin with theto notify you as soon as an anomaly is detected. To get started, choose Anomaly Detection in OpenSearch Dashboards. To first test with sample streaming data, you can try out one of the preconfigured detectors with one of the sample datasets. ",
    "url": "http://localhost:4000/analytics/anomaly-detection/index.html#anomaly-detection",
    "relUrl": "/analytics/anomaly-detection/index.html#anomaly-detection"
  },"17": {
    "doc": "Anomaly Detection",
    "title": "Step 1: Define a detector",
    "content": "A detector is an individual anomaly detection task. You can define multiple detectors, and all the detectors can run simultaneously, with eachanalyzingdata from different sources. Choose Create detector . Add in the detector details. | Enter a name and brief description. Make sure the name is unique and descriptive enough to help you to identify the purpose of the detector. Specify the data source. | For Data source , choose the index you want to use as the data source. You can optionally use index patterns to choose multiple indexes. | (Optional) For Data filter , filter the index you chose as the data source. From the Data filter menu, choose Add data filter , and then design your filter query by selecting Field , Operator , and Value , or choose Use query DSL and add your own JSON filter query. Specify a timestamp. | Select the Timestamp field in your index. Define operation settings. | For Operation settings , define the Detector interval , which is the time interval at which the detector collects data. | The detector aggregates the data in this interval, then feeds the aggregated result into the anomaly detection model. The shorter you set thisinterval,the fewer data points the detector aggregates. The anomaly detection model uses a shingling process, a technique that uses consecutive data points to create a sample for the model. This process needs a certain number of aggregated data points from contiguous intervals. | We recommend setting the detector interval based on your actual data. If it’s too long it might delay the results, and if it’s too short it might miss some data. It also won’t havea sufficient number ofconsecutive data points for the shingle process. | (Optional) To add extra processing time for data collection, specify a Window delay value. | This value tells the detector that the data is not ingested into OpenSearch in real time but with a certain delay. Set the window delay to shift the detector interval to account for this delay. | For example, say the detector interval is 10 minutes and dataisingested into your cluster with a general delay of 1 minute. Assume the detector runs at 2:00. The detector attempts to get the last 10 minutes of data from 1:50 to 2:00, but because of the 1-minute delay, it only gets 9 minutes of data and misses the data from 1:59 to 2:00. Setting the window delay to1 minuteshifts the interval window to 1:49 - 1:59, so the detector accounts for all 10 minutes of the detector interval time. Specify custom result index. | If you want to store the anomaly detection results in your own index, choose Enable custom result index and specify the custom index to store the result. The anomaly detection plugin adds anopensearch-ad-plugin-result-prefix to the index name that you input. For example, if you inputabcas the result index name, the final index name isopensearch-ad-plugin-result-abc. | . You can use the dash “-” sign to separate the namespace to manage custom result index permissions. For example, if you use opensearch-ad-plugin-result-financial-us-group1 as the result index, you can create a permission role based on the pattern opensearch-ad-plugin-result-financial-us-* to represent the “financial” department at a granular level for the “us” area. | If the custom index you specify doesn’t already exist, the anomaly detection plugin creates this index when you create the detector and start your real-time or historical analysis. | If the custom index already exists, the plugin checks if the index mapping of the custom index matches the anomaly result file. You need to makesure the custom index has valid mapping as shown here:. | To use the custom result index option, you need the following permissions: indices:admin/create- If the custom index already exists, you don’t need this. | . indices:data/write/index- You need thewritepermission for the anomaly detection plugin to write results into the custom index for a single-entity detector. indices:data/read/search- You need thesearchpermission because the Anomaly Detection plugin needs to search custom result indexes to show results on the anomaly detection UI. indices:data/write/delete- Because the detector might generatea large number ofanomaly results, you need thedeletepermission to delete old data and save disk space. indices:data/write/bulk- You need thebulkpermission because the anomaly detection plugin uses the bulk API to write results into the custom index. | Managing the custom result index: The anomaly detection dashboard queries all detectors’ results from all custom result indexes. Having too many custom result indexes might impact the performance of the Anomaly Detection plugin. | . You can useto rollover old result indexes. You can also manually delete or archive any old result indexes. We recommend reusing a custom result index for multiple detectors. Choose Next . After you define the detector, the next step is to configure the model. ",
    "url": "http://localhost:4000/analytics/anomaly-detection/index.html#step-1-define-a-detector",
    "relUrl": "/analytics/anomaly-detection/index.html#step-1-define-a-detector"
  },"18": {
    "doc": "Anomaly Detection",
    "title": "Step 2: Configure the model",
    "content": "ADD FEATURES TO YOUR DETECTOR . A feature is the field in your index that you want to check for anomalies. A detector can discover anomalies across one or more features. You must choose an aggregation method for each feature:average(),count(),sum(),min(), ormax(). The aggregation method determines what constitutes an anomaly. For example, if you choosemin(), the detector focuses on finding anomalies based on the minimum values of your feature. If you chooseaverage(), the detector finds anomalies based on the average values of your feature. A multi-feature model correlates anomalies across all its features. The  makes it less likely for multi-feature models to identify smaller anomalies as compared to a single-feature model. Adding more features might negatively impact the  of a model. A higher proportion of noise in your data might further amplify this negative impact. Selecting the optimal feature set is usually an iterative process. By default, the maximum number of features for a detector is 5. You can adjust this limit with the plugins.anomaly_detection.max_anomaly_features setting. To configure an anomaly detection model based on an aggregation method, follow these steps: . | On the Configure Model page, enter the Feature name and check Enable feature . | For Find anomalies based on , select Field Value . | For aggregation method , select either average() , count() , sum() , min() , or max() . | For Field , select from the available options. To configure an anomaly detection model based on a JSON aggregation query, follow these steps: | . On the Configure Model page, enter the Feature name and check Enable feature . For Find anomalies based on , select Custom expression . You will see the JSON editor windowopen up. Enter your JSON aggregation query in the editor. For acceptable JSON query syntax, see  . (OPTIONAL) SET CATEGORY FIELDS FOR HIGH CARDINALITY . You can categorize anomalies based on a keyword or IP field type. The category field categorizes or slices the source time series with a dimension like IP addresses, product IDs, country codes, and so on. This helps to see a granular view of anomalies within each entity of the category field to isolate and debug issues. To set a category field, choose Enable a category field and select a field. You can’t change the category fields after you create the detector. Only a certain number of unique entities are supported in the category field. Use the following equation to calculate the recommended total number of entities supported in a cluster: . (datanodes * heap size * anomaly detection maximum memory percentage) / (entity model size of a detector) . To get the entity model size of a detector, use the. You can adjust the maximum memory percentage with theplugins.anomaly_detection.model_max_size_percentsetting. This formula provides a good starting point, but make sure to test with a representative workload. For example, for a cluster with three data nodes, each with 8 GB of JVM heap size, a maximum memory percentage of 10% (default), and the entity model size of the detector as 1MB: the total number of unique entities supported is (8.096 * 10^9 * 0.1 / 1MB )* 3 = 2429. If the actual total number of unique entities higher than this number that you calculate (in this case: 2429), the anomaly detector makes its best effort to model the extra entities. The detector prioritizes entities that occur more often and are more recent. (ADVANCED SETTINGS) SET A SHINGLE SIZE . Set the number of aggregation intervals from your data stream to consider in a detection window. It’s best to choose this value based on your actual data to see which one leads to the best results for your use case. The anomaly detector expects the shingle size to be in the range of 1 and 60. The default shingle size is 8. We recommend that you don’t choose 1 unless you have two or more features. Smaller values might increasebut also false positives. Larger values might be useful for ignoring noise in a signal. PREVIEW SAMPLE ANOMALIES . Preview sample anomalies and adjust the feature settings if needed. For sample previews, the anomaly detection plugin selects a small number of data samples—for example, one data point every 30 minutes—and uses interpolation to estimate the remaining data points to approximate the actual feature data. It loads this sample dataset into the detector. The detector uses this sample dataset to generate a sample preview of anomaly results. Examine the sample preview and use it to fine-tune your feature configurations (for example, enable or disable features) to get more accurate results. Choose Preview sample anomalies . If you don’t see any sample anomaly result, check the detectorintervaland make sure you have more than 400 data points for some entities during the preview date range. Choose Next . ",
    "url": "http://localhost:4000/analytics/anomaly-detection/index.html#step-2-configure-the-model",
    "relUrl": "/analytics/anomaly-detection/index.html#step-2-configure-the-model"
  },"19": {
    "doc": "Anomaly Detection",
    "title": "Step 3: Set up detector jobs",
    "content": "To start a real-time detector to find anomalies in your data in near real-time, check Start real-time detector automatically (recommended) . Alternatively, if you want to perform historical analysis and find patterns in long historical data windows (weeks or months), check Run historical analysis detection and select a date range (at least 128 detection intervals). Analyzinghistorical data helps you get familiar with the anomaly detection plugin. You can also evaluate the performance of a detector with historical data to further fine-tune it. We recommend experimenting with historical analysis with different feature sets and checking the precision before moving on to real-time detectors. ",
    "url": "http://localhost:4000/analytics/anomaly-detection/index.html#step-3-set-up-detector-jobs",
    "relUrl": "/analytics/anomaly-detection/index.html#step-3-set-up-detector-jobs"
  },"20": {
    "doc": "Anomaly Detection",
    "title": "Step 4: Review and create",
    "content": "Review your detector settings and model configurations to make sure that they’re valid and then select Create detector . If you see any validation errors, edit the settings to fix the errors and then return back to this page. ",
    "url": "http://localhost:4000/analytics/anomaly-detection/index.html#step-4-review-and-create",
    "relUrl": "/analytics/anomaly-detection/index.html#step-4-review-and-create"
  },"21": {
    "doc": "Anomaly Detection",
    "title": "Step 5: Observe the results",
    "content": "Choose the Real-time results or Historical analysis tab. For real-time results, you need to wait for some time to see the anomaly results. If the detector interval is 10 minutes, the detector might take more than an hour to start, because its waiting for sufficient data to generate anomalies. A shorter interval means the model passes the shingle process more quickly and starts to generate the anomaly results sooner. Use theoperation to make sure you have sufficient data points. If you see the detector pending in “initialization” for longer than a day, aggregate your existing data using the detector interval to check for any missing data points. If you find a lot of missing data points from the aggregated data, consider increasing the detector interval. Choose and drag over the anomaly line chart to zoom in and see a more detailed view of an anomaly. Analyzeanomalies with the following visualizations: . | Live anomalies (for real-time results)displayslive anomaly results for the last 60 intervals. For example, if the interval is 10, it shows results for the last 600 minutes. The chart refreshes every 30 seconds. | Anomaly overview (for real-time results) / Anomaly history (for historical analysis in the Historical analysis tab) plots the anomaly grade with the corresponding measure of confidence. This pane includes: . | . The number of anomaly occurrences based on the given data-time range. The Average anomaly grade , a number between 0 and 1 that indicates how anomalous a data point is. An anomaly grade of 0 represents “not an anomaly,” and a non-zero value represents the relative severity of the anomaly. | Confidence estimateof the probability that the reported anomaly grade matches the expected anomaly grade. Confidence increases as the model observes more data and learns the databehaviorand trends. Note that confidence is distinct from model accuracy. | Last anomaly occurrence is the time at which the last anomaly occurred. | . Underneath Anomaly overview / Anomaly history are: . | Feature breakdown plots the features based on the aggregation method. You can vary the date-time range of the detector. Selecting a point on the feature line chart shows the Feature output , the number of times a field appears in your index, and the Expected value , a predicted value for the feature output. Where there is no anomaly, the output and expected values are equal. | . | Anomaly occurrences shows theStart time,End time,Data confidence, andAnomaly gradefor each detected anomaly. | . Selecting a point on the anomaly line chart shows Feature Contribution , the percentage of a feature that contributes to theanomaly . If you set the category field, you see an additional Heat map chart. The heat map correlates results for anomalous entities. This chart is empty until you select an anomalous entity. You also see the anomaly and feature line chart for thetime periodof the anomaly (anomaly_grade&gt; 0). If you have set multiple category fields, you can select a subset of fields to filter and sort the fields by. Selecting a subset of fields lets you see the top values of one field that share a common value with another field. For example, if you have a detector with the category fieldsipandendpoint, you can selectendpointin the View by dropdown menu. Then, select a specific cell to overlay the top 20 values ofipon the charts. The anomaly detection plugin selects the topipby default. You can see a maximum of 5 individual time-series values at the same time. ",
    "url": "http://localhost:4000/analytics/anomaly-detection/index.html#step-5-observe-the-results",
    "relUrl": "/analytics/anomaly-detection/index.html#step-5-observe-the-results"
  },"22": {
    "doc": "Anomaly Detection",
    "title": "Step 6: Set up alerts",
    "content": "Under Real-time results , choose Set up alerts and configure a monitor to notify you when anomalies are detected. For steps to create a monitor and set up notifications based on your anomaly detector, see. If you stop or delete a detector, make sure to delete any monitors associated with it. ",
    "url": "http://localhost:4000/analytics/anomaly-detection/index.html#step-6-set-up-alerts",
    "relUrl": "/analytics/anomaly-detection/index.html#step-6-set-up-alerts"
  },"23": {
    "doc": "Anomaly Detection",
    "title": "Step 7: Adjust the model",
    "content": "To see all the configuration settings for a detector, choose the Detector configuration tab. To make any changes to the detector configuration, or fine tune the time interval to minimize any false positives, go to the Detector configuration section and choose Edit . You need to stop real-time and historical analysis to change its configuration. Confirm that you want to stop the detector and proceed. To enable or disable features, in the Features section, choose Edit and adjust the feature settings as needed. After you make your changes, choose Save and start detector . ",
    "url": "http://localhost:4000/analytics/anomaly-detection/index.html#step-7-adjust-the-model",
    "relUrl": "/analytics/anomaly-detection/index.html#step-7-adjust-the-model"
  },"24": {
    "doc": "Anomaly Detection",
    "title": "Step 8: Manage your detectors",
    "content": "To start, stop, or delete a detector, go to the Detectors page. Choose the detector name. Choose Actions and select Start real-time detectors , Stopreal-time detectors , or Delete detectors . ",
    "url": "http://localhost:4000/analytics/anomaly-detection/index.html#step-8-manage-your-detectors",
    "relUrl": "/analytics/anomaly-detection/index.html#step-8-manage-your-detectors"
  },"25": {
    "doc": "Anomaly Detection",
    "title": "Anomaly Detection",
    "content": " ",
    "url": "http://localhost:4000/analytics/anomaly-detection/index.html",
    "relUrl": "/analytics/anomaly-detection/index.html"
  },"26": {
    "doc": "How to Perform Search",
    "title": "How to Perform a Search",
    "content": ". | Launch the Elysium Analytic app, log in with your credentials, and click on the Discover page under the Analytics section at the left sidebar. | Click on the Change Index Pattern dropdown and make sure you have selected the correct index to search the data. | Type the query in the search bar and set the parameters from the search options, then set the date and time as your choice from the calendar picker. The search will be automatically performed or you can also click on the Refresh button to execute the search with aggregated results. | . Note: You can apply multiple types of search in the Elysium search such as Quoted search, Unquoted search, Wildcard search, and more. For more information follow the “Types of Search” section. ",
    "url": "http://localhost:4000/analytics/discover/perform-search/index.html#how-to-perform-a-search",
    "relUrl": "/analytics/discover/perform-search/index.html#how-to-perform-a-search"
  },"27": {
    "doc": "How to Perform Search",
    "title": "Search Options",
    "content": "The search operation can be optimized based on your query requirements by switching between different search options. Case Sensitivity . In this option, uppercase and lowercase letters are considered distinct and are treated as separate characters while performing the search. For example, the words “hello” and “Hello” would be treated as two different words, whereas in a case-insensitive system, they would be treated as the same word. You can enable the case sensitivity by toggling ON or disable it by toggling OFF. Query Timeout in Minutes . This is best suitable if the query is not executed properly or is consuming too much time. By using this search option, the query in progress will be automatically stopped after the defined time limit has elapsed. You can define the time limit only in “minutes”. Federated Search . This search option relies upon OpenSearch and Snowflake databases to query and retrieve the data. If the data is 7 days old or less, then the same shall be queried from OpenSearch. If the data is older than 7 days, then the same shall be queried from Snowflake. You can enable the Federated Search by toggling ON or disabling it by toggling OFF, by default it is disabled. ",
    "url": "http://localhost:4000/analytics/discover/perform-search/index.html#search-options",
    "relUrl": "/analytics/discover/perform-search/index.html#search-options"
  },"28": {
    "doc": "How to Perform Search",
    "title": "Selecting Date to a Query (Date Picker)",
    "content": "Define the date range for which you want to filter the results of your executed query. Additionally, you can select the _Commonly used or Recently used date ranges with the Refresh every time feature. ",
    "url": "http://localhost:4000/analytics/discover/perform-search/index.html#selecting-date-to-a-query-date-picker",
    "relUrl": "/analytics/discover/perform-search/index.html#selecting-date-to-a-query-date-picker"
  },"29": {
    "doc": "How to Perform Search",
    "title": "Adding Filters",
    "content": "Elysium Search provides you the functionality to filter the records returned by your query by following this workflow: . Adding the Filters with Fields . Select the fields from the field section at the left bar &gt; Add the filter in the query by clicking on the ( + ) button or remove the filter by clicking on the ( – ) button respectively as illustrated below. Note: By simply clicking on the search bar, a dropdown will suggest you a list of fields based on which you can perform the search for the values. Adding the Filter Individually . You can set this filter based on the fields in the table/index and enter the correct value according to the record you want to get from the database. Click on + Add Filter Button &gt; select the Field you want to search value from &gt; select the operator based on your value &gt; and Save the filter. This will automatically execute the query and render the results as illustrated below. ",
    "url": "http://localhost:4000/analytics/discover/perform-search/index.html#adding-filters",
    "relUrl": "/analytics/discover/perform-search/index.html#adding-filters"
  },"30": {
    "doc": "How to Perform Search",
    "title": "Save the Search",
    "content": "You can save your recent search by simply clicking on the save button beside the search bar. ",
    "url": "http://localhost:4000/analytics/discover/perform-search/index.html#save-the-search",
    "relUrl": "/analytics/discover/perform-search/index.html#save-the-search"
  },"31": {
    "doc": "How to Perform Search",
    "title": "How to Perform Search",
    "content": " ",
    "url": "http://localhost:4000/analytics/discover/perform-search/index.html",
    "relUrl": "/analytics/discover/perform-search/index.html"
  },"32": {
    "doc": "Discover",
    "title": "Overview",
    "content": "Elysium Search is an analytics engine provided by Elysium Analytics that allows users to index and search large amounts of data from the connected database in which you can search any collection/records by inputting the string values that will return the matched records. It is a search tool that offers a range of features, including full-text search, real-time analytics, data visualization, search by field, search multiple indices, boost fields, ranking results by score, sorting results by fields, and aggregate results. Elysium Search is designed to be highly scalable and can be deployed across multiple servers to handle large amounts of data; it is compatible with a range of programming languages and offers APIs for easy integration with other applications. In this documentation, we will cover how you can manage the index and how you’re able to do the many types of searches provided by Elysium: . | Managing the Index | How to Perform a Search | Types of Search | . Let’s get started 🚀 . ",
    "url": "http://localhost:4000/analytics/discover/index.html#overview",
    "relUrl": "/analytics/discover/index.html#overview"
  },"33": {
    "doc": "Discover",
    "title": "Discover",
    "content": " ",
    "url": "http://localhost:4000/analytics/discover/index.html",
    "relUrl": "/analytics/discover/index.html"
  },"34": {
    "doc": "Managing Index",
    "title": "Managing Index",
    "content": "Setting the Index is the method that is mandatory before performing any type of search on the data based on the Elysium platform. Managing the index is the process to map the data and enhance the retrieval of that data produced by the Elysium search engine. | Launch the Elysium Analytic app, log in with your credentials, and click on Stack Management under the Configure section at the left sidebar. | Click on the index pattern in the Stack Management tab. | Click on the ”+ Create index pattern” button in the top-right corner. | Type the index name manually, the entered index name will match with the existing indices, and Click on the Next step button. You will be navigating to the configure setting page which will require you to select the time field of your choice and create the index by clicking on Create index pattern button. | . After successfully creating the index, you can perform any type of search on top of it by navigating to the Discover page. ",
    "url": "http://localhost:4000/analytics/discover/manage-index/index.html",
    "relUrl": "/analytics/discover/manage-index/index.html"
  },"35": {
    "doc": "Types of Search",
    "title": "Types of Search",
    "content": " ",
    "url": "http://localhost:4000/analytics/discover/types-of-search/index.html",
    "relUrl": "/analytics/discover/types-of-search/index.html"
  },"36": {
    "doc": "Types of Search",
    "title": "Quoted Search",
    "content": "This refers to a type of online search where the search terms are enclosed within quotation marks. This is also known as an exact match search. When quotation marks are used, the search engine will look for the exact phrase within the quotes and return results that match that exact phrase. To search the data/records it will filter the given input values in the double quotes and will display the results based on matching the input values from the records stored in the database. For Example, . Field/Property is denoted by username and the string value is denoted by “john smith” . Note: The field/property is optional, you can simply search by inputting the values. The search engine will find the records based on the given input from all the fields available in the database. ",
    "url": "http://localhost:4000/analytics/discover/types-of-search/index.html#quoted-search",
    "relUrl": "/analytics/discover/types-of-search/index.html#quoted-search"
  },"37": {
    "doc": "Types of Search",
    "title": "Unquoted Search",
    "content": "Unquoted search refers to performing a search in a search engine from the database without enclosing the search terms in quotation marks. In unquoted search, the Elysium search engine will return results that contain all the words in the search query in any order, and sometimes results that contain synonyms or related words. To search the data/records it will filter the given input value and will display results based on matching the input values from the records stored in the database. For example, . Field/Property is denoted by username and the string value is denoted by “smith” . Note: The field/property is optional, you can simply search by inputting the values. The search engine will find the records based on the given input from all the fields available in the database. ",
    "url": "http://localhost:4000/analytics/discover/types-of-search/index.html#unquoted-search",
    "relUrl": "/analytics/discover/types-of-search/index.html#unquoted-search"
  },"38": {
    "doc": "Types of Search",
    "title": "Wildcard Search",
    "content": "A wildcard search is a type of search that allows you to use special characters, called wildcards ( * ), to represent one or more characters in a search term. This can be useful when you are looking for variations of a word or when you are searching for a term that has multiple spellings. Wildcard search can only be used in unquoted search and the most commonly used wildcards are the asterisk ( * ). The asterisk represents any number of characters. For example: . To search the data/records starting with ‘smith’ use the query syntax illustrated below . To search the data/records ending with ‘smith’ use the query syntax illustrated below . Wildcard search is also used to get all the records stored in the database using the query syntax illustrated below . Note 1: If you put the asterisk ( * ) at the starting and end ( *smith ) of the input then it will explicit the values and consider as ( * ) will result in getting all records. Note 2: The field/property is optional, you can simply search by inputting the values. The search engine will find the records based on the given input from all the fields available in the database. Field/Property denoted by username and string value denoted by “smith” . Matching Multiple Fields in Wildcard Search . Wildcard search can also be used to query with multiple fields while searching the data where any of the sub-field (http.response) containing “error” as illustrated below . For example: . ",
    "url": "http://localhost:4000/analytics/discover/types-of-search/index.html#wildcard-search",
    "relUrl": "/analytics/discover/types-of-search/index.html#wildcard-search"
  },"39": {
    "doc": "Types of Search",
    "title": "Smart Search",
    "content": "This refers to a search algorithm or technology that uses advanced techniques to provide more relevant search results to users. on the other hand, uses artificial intelligence, machine learning, and natural language processing to understand the context and intent of a search query and deliver more accurate and personalized results. When you’re searching for something on the Elysium search engine enables the smart search by default. It can also understand the meaning of a query, rather than just matching keywords, and provide results based on the intent of the user’s search. It is the technology provided by Elysium Analytics that helps to improve the accuracy and relevance of search results, making it easier for users to find the information they need. ",
    "url": "http://localhost:4000/analytics/discover/types-of-search/index.html#smart-search",
    "relUrl": "/analytics/discover/types-of-search/index.html#smart-search"
  },"40": {
    "doc": "Types of Search",
    "title": "Negating Search",
    "content": "Negating means to deny or negate the truth or validity of something. In logic and mathematics, negation refers to the operation of reversing or negating the truth value of a statement or proposition. In negate search specify some keywords with the query and the execution of the query resulting to retrieve the data. Keywords that can be used to negate a query NOT, AND, OR . Negating search with NOT . NOT keyword is used to exclude the related data to the given query, you can use it in combination with other search terms to exclude certain results from your search. For example, . The given query will filter the data except for the “HTTP GET methods” and will retrieve all the HTTP methods except the GET method. Negating search with AND . AND keyword is used to retrieve the data by combining two or more search queries to narrow down your results to only those that include both terms. For example, . The given query will filter the data by combining both the queries and resulting to fetch all the HTTP GET methods including response code 400. Negating search with OR . OR keyword is used to help you find a wider variety of results that include any of the terms you are interested in querying. For example, . The given query will tell the search engine to return results that include any of the terms. Negating Search with Combining Keywords . You can combine OR, AND, and NOT keywords with the parenthesis to create more complex search queries that include multiple search terms and operators. Here is an example of a search query that uses all three operators: . You can also use the parenthesis for shorthand syntax while generating multiple queries for the same field. For Example, . ",
    "url": "http://localhost:4000/analytics/discover/types-of-search/index.html#negating-search",
    "relUrl": "/analytics/discover/types-of-search/index.html#negating-search"
  },"41": {
    "doc": "Types of Search",
    "title": "Characters Need Escaping",
    "content": "Escaping is the process of inserting special characters, called escape sequences, into a string literal or character sequence. This is necessary when you need to include characters that would otherwise be interpreted as part of the programming language syntax, such as quotes or backslashes. For example, . If you want to include a double quote character (“) within a string literal that is also enclosed in double quotes, you need to escape the inner double quote character using a backslash (“). Otherwise, the string literal would be interpreted as ending at the first occurrence of the double quote, causing a syntax error. Similarly, if you want to include a backslash () character within a string literal, you also need to escape it using another backslash (). Otherwise, the backslash would be interpreted as an escape character, and the subsequent character would be interpreted as an escape sequence. Characters that commonly need escaping including: . \\():&lt;&gt;\"*[]{} . ",
    "url": "http://localhost:4000/analytics/discover/types-of-search/index.html#characters-need-escaping",
    "relUrl": "/analytics/discover/types-of-search/index.html#characters-need-escaping"
  },"42": {
    "doc": "Analytics",
    "title": "Elysium Analytics",
    "content": "Elysium Analytics . ",
    "url": "http://localhost:4000/analytics/index.html#elysium-analytics",
    "relUrl": "/analytics/index.html#elysium-analytics"
  },"43": {
    "doc": "Analytics",
    "title": "Introduction",
    "content": " ",
    "url": "http://localhost:4000/analytics/index.html#introduction",
    "relUrl": "/analytics/index.html#introduction"
  },"44": {
    "doc": "Analytics",
    "title": "Analytics",
    "content": " ",
    "url": "http://localhost:4000/analytics/index.html",
    "relUrl": "/analytics/index.html"
  },"45": {
    "doc": "Configuring a Web Map Service (WMS)",
    "title": "Configuring a Web Map Service (WMS)",
    "content": "The Open Geospatial Consortium (OGC) Web Map Service (WMS) specification is an international specification for requesting dynamic maps on the web. OpenSearch Dashboards includes default map tiles. For specialized maps, you can configure a WMS on OpenSearch Dashboards following these steps: . | Log in to OpenSearch Dashboards at https://&lt;host&gt;:&lt;port&gt;. For example, you can connect to OpenSearch Dashboards by connecting to https://localhost:5601. The default username and password are admin. | Choose Management &gt; Advanced Settings. | Locate visualization:tileMap:WMSdefaults. | Change enabled to true and add the URL of a valid WMS server, as shown in the following example: . { \"enabled\": true, \"url\": \"&lt;wms-map-server-url&gt;\", \"options\": { \"format\": \"image/png\", \"transparent\": true } } . | . Web map services may have licensing fees or restrictions, and you are responsible for complying with any such fees or restrictions. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/building-data-visualizations/conf-wms/index.html",
    "relUrl": "/analytics/opensearch-dashboard/building-data-visualizations/conf-wms/index.html"
  },"46": {
    "doc": "Using coordinate and region maps",
    "title": "Using coordinate and region maps",
    "content": "OpenSearch has a standard set of GeoJSON files that provide a vector map with each region map. OpenSearch Dashboards also provides basic map tiles with a standard vector map to create region maps. You can configure the base map tiles using Web Map Service (WMS). For more information, see Configuring WMS in OpenSearch Dashboards. For air gapped environments, OpenSearch Dashboards provides a self-host maps server. For more information, see Using the self-host maps server . While you can’t configure a server to support user-defined vector map layers, you can configure your own GeoJSON file and upload it for this purpose. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/building-data-visualizations/using-coor-maps/index.html",
    "relUrl": "/analytics/opensearch-dashboard/building-data-visualizations/using-coor-maps/index.html"
  },"47": {
    "doc": "Using coordinate and region maps",
    "title": "Customizing vector maps with GeoJSON",
    "content": "If you have a specific locale that is not provided by OpenSearch Dashboards vector maps, such as a US county or US ZIP Code, you can create your own custom vector map with a GeoJSON file. To create a custom region map you would define a geographic shape such as a polygon with multiple coordinates. To learn more about the various geographic shapes that support a custom region map location, see Geoshape field type. GeoJSON format allows you to encode geographic data structures. To learn more about the GeoJSON specification, go to geojson.org. You can use geojson.io to extract GeoJSON files. PREREQUISITE To use a custom vector map with GeoJSON, install these two required plugins: . | OpenSearch Dashboards Maps dashboards-maps front-end plugin | OpenSearch geospatial backend plugin | . Step 1: Creating a region map visualization . To create your own custom vector map, upload a JSON file that contains GEO data for your customized regional maps. The JSON file contains vector layers for visualization. | Prepare a JSON file to upload. Make sure the file has either a .geojson or .json extension. | On the top menu bar, go to OpenSearch Dashboards &gt; Visualize. | Select the Create Visualization button. | Select Region Map. | Choose a source. For example, [Flights] Flight Log. | In the right panel, select Import Vector Map. | In Upload map, select or drag and drop your JSON file and then enter Map name prefix (for example, usa-counties). Your map will have the prefix that you defined followed by the -map suffix (for example, usa-counties-map), as shown in the following image: . | Select the Import file button and then select the Refresh button in the pop-up window confirming successful upload, as shown in the following image. | . Step 2: Viewing the custom region map in OpenSearch Dashboards . After you upload a custom GeoJSON file, you need to set the vector map layer to custom, and select your vector map: . | From Layer Options &gt; Layer settings, select Custom vector map. | Under Vector map, select the name of the vector map that you just uploaded. | Optional: Under Style settings, increase Border thickness to see the borders more clearly. | Select the Update button. | View your region map in the Dashboards. For example, the following image shows the Los Angeles and San Diego county regions: | . EXAMPLE GEOJSON FILE . The following example GeoJSON file provides coordinates for two US counties. { \"type\": \"FeatureCollection\", \"name\": \"usa counties\", \"features\": [ { \"type\": \"Feature\", \"properties\": { \"iso2\": \"US\", \"iso3\": \"LA-CA\", \"name\": \"Los Angeles County\", \"country\": \"US\", \"county\": \"LA\" }, \"geometry\": { \"type\": \"Polygon\", \"coordinates\":[[[-118.71826171875,34.07086232376631],[-118.69628906249999,34.03445260967645],[-118.56994628906249,34.02990029603907],[-118.487548828125,33.957030069982316],[-118.37219238281249,33.86129311351553],[-118.45458984375,33.75631505992707],[-118.33923339843749,33.715201644740844],[-118.22937011718749,33.75631505992707],[-118.1414794921875,33.678639851675555],[-117.9107666015625,33.578014746143985],[-117.75146484375,33.4955977448657],[-117.55920410156249,33.55512901742288],[-117.3065185546875,33.5963189611327],[-117.0703125,33.67406853374198],[-116.69677734375,34.06176136129718],[-116.9439697265625,34.28445325435288],[-117.18017578125,34.42956713470528],[-117.3779296875,34.542762387234845],[-117.62512207031251,34.56990638085636],[-118.048095703125,34.615126683462194],[-118.44909667968749,34.542762387234845],[-118.61938476562499,34.38877925439021],[-118.740234375,34.21180215769026],[-118.71826171875,34.07086232376631]]] } }, { \"type\": \"Feature\", \"properties\": { \"iso2\": \"US\", \"iso3\": \"SD-CA\", \"name\": \"San Diego County\", \"country\": \"US\", \"county\": \"SD\" }, \"geometry\": { \"type\": \"Polygon\", \"coordinates\":[[[-117.23510742187501,32.861132322810946],[-117.2406005859375,32.75494243654723],[-117.1636962890625,32.68099643258195],[-117.14172363281251,32.58384932565662],[-117.09228515624999,32.46342595776104],[-117.0538330078125,32.29177633471201],[-116.96044921875,32.194208672875384],[-116.85607910156249,32.16631295696736],[-116.6748046875,32.20350534542368],[-116.3671875,32.319633552035214],[-116.1474609375,32.55144352864431],[-116.1639404296875,32.80574473290688],[-116.4111328125,33.073130945006625],[-116.72973632812499,33.08233672856376],[-117.09228515624999,32.99484290420988],[-117.2515869140625,32.96258644191747], [-117.23510742187501,32.861132322810946]]] } } ] } . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/building-data-visualizations/using-coor-maps/index.html#customizing-vector-maps-with-geojson",
    "relUrl": "/analytics/opensearch-dashboard/building-data-visualizations/using-coor-maps/index.html#customizing-vector-maps-with-geojson"
  },"48": {
    "doc": "Using coordinate and region maps",
    "title": "Related articles",
    "content": ". | Using maps | Configuring a Web Map Service (WMS) | Using the self-host maps server | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/building-data-visualizations/using-coor-maps/index.html#related-articles",
    "relUrl": "/analytics/opensearch-dashboard/building-data-visualizations/using-coor-maps/index.html#related-articles"
  },"49": {
    "doc": "Using area charts",
    "title": "Using area charts",
    "content": "An area chart is a line chart with the area between the line and the axis shaded with a color, and is a primary visualization type used to display time series data. You can create area charts in Dashboards using the Area visualization type or using the Time Series Visual Builder (TSVB), Vega, or VisBuilder visualization tools. For this tutorial, you’ll use the Area visualization type. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/building-data-visualizations/using-areacharts/index.html",
    "relUrl": "/analytics/opensearch-dashboard/building-data-visualizations/using-areacharts/index.html"
  },"50": {
    "doc": "Using area charts",
    "title": "Try it: Create a simple aggregation-based area chart",
    "content": "In this tutorial you’ll create a simple area chart using sample data and aggregations in OpenSearch Dashboards by connecting to http://localhost:5601 from a browser. You have several aggregation options in Dashboards, and the choice influences your analysis. The use cases for aggregations vary from analyzing data in real time to using Dashboards to create a visualization dashboard. If you need an overview of aggregations in OpenSearch, see Aggregations before starting this tutorial. Make sure you have installed the latest version of Dashboards and added the sample data before continuing with this tutorial. This tutorial uses Dashboards version 2.4.1. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/building-data-visualizations/using-areacharts/index.html#try-it-create-a-simple-aggregation-based-area-chart",
    "relUrl": "/analytics/opensearch-dashboard/building-data-visualizations/using-areacharts/index.html#try-it-create-a-simple-aggregation-based-area-chart"
  },"51": {
    "doc": "Using area charts",
    "title": "Set up the area chart",
    "content": ". | Access Dashboards by connecting to http://localhost:5601 from a browser. | Select Visualize from the menu and then select Create visualization. | Select Area from the window. | Select opensearch_dashboards_sample_data_flights in the New Area/Choose a source window. | Select the calendar icon and set the time filter to Last 7 days. | Select Update. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/building-data-visualizations/using-areacharts/index.html#set-up-the-area-chart",
    "relUrl": "/analytics/opensearch-dashboard/building-data-visualizations/using-areacharts/index.html#set-up-the-area-chart"
  },"52": {
    "doc": "Using area charts",
    "title": "Add aggregations to the area chart",
    "content": "Continuing with the area chart created in the preceding steps, you’ll create a visualization that displays the top five logs for flights delayed for every three hours over the last seven days: . | Add a Metrics aggregation. | Under Metrics, select the Aggregation dropdown list and choose Average and then select the Field dropdown list and choose FlightDelayMin. | Under Metrics, select Add to add another Y-axis aggregation. | Select the Aggregation dropdown list and choose Max and then select the Field dropdown list and choose FlightDelayMin. | . | Add a Buckets aggregation. | Select Add to open the Add Bucket window and then select X-axis. | From the Aggregation dropdown list, select Date Histogram. | From the Field dropdown list, select timestamp. | Select Update. | . | Add a sub-aggregation. | Select Add to open the Add Sub-Buckets window and then select Split series. | From the Sub aggregation dropdown list, select Terms. | From the Field dropdown list, select FlightDelay. | Select Update to reflect these parameters in the graph. | . | . You’ve now created the following aggregation-based area chart. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/building-data-visualizations/using-areacharts/index.html#add-aggregations-to-the-area-chart",
    "relUrl": "/analytics/opensearch-dashboard/building-data-visualizations/using-areacharts/index.html#add-aggregations-to-the-area-chart"
  },"53": {
    "doc": "Using area charts",
    "title": "Related links",
    "content": ". | Visualize | Visualization types in OpenSearch Dashboards | Install and configure OpenSearch Dashboards | Aggregations | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/building-data-visualizations/using-areacharts/index.html#related-links",
    "relUrl": "/analytics/opensearch-dashboard/building-data-visualizations/using-areacharts/index.html#related-links"
  },"54": {
    "doc": "Gantt charts",
    "title": "Gantt charts",
    "content": "OpenSearch Dashboards includes a Gantt chart visualization. Gantt charts show the start, end, and duration of unique events in a sequence. Gantt charts are useful in trace analytics, telemetry, and anomaly detection use cases, where you want to understand interactions and dependencies between various events in a schedule. For example, consider an index of log data. The fields in a typical set of log data, especially audit logs, contain a specific operation or event with a start time and duration. To create a Gantt chart, perform the following steps: . | In the visualizations menu, choose Create visualization and Gantt Chart. | Choose a source for the chart (e.g. some log data). | Under Metrics, choose Event. For log data, each log is an event. | Select the Start Time and Duration fields from your data set. The start time is the timestamp for the beginning of an event. The duration is the amount of time to add to the start time. | Under Results, choose the number of events to display on the chart. Gantt charts sequence events from earliest to latest based on start time. | Choose Panel settings to adjust axis labels, time format, and colors. | Choose Update. | . This Gantt chart displays the ID of each log on the y-axis. Each bar is a unique event that spans some amount of time. Hover over a bar to see the duration of that event. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/building-data-visualizations/using-gantt/index.html",
    "relUrl": "/analytics/opensearch-dashboard/building-data-visualizations/using-gantt/index.html"
  },"55": {
    "doc": "Using maps",
    "title": "Using maps",
    "content": "With OpenSearch Dashboards, you can create maps to visualize your geographical data. OpenSearch lets you construct map visualizations with multiple layers, combining data across different indexes. You can build each layer from a different index pattern. Additionally, you can configure maps to show specific data at different zoom levels. OpenSearch maps are powered by the OpenSearch maps service, which uses vector tiles to render maps. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/building-data-visualizations/using-maps/index.html",
    "relUrl": "/analytics/opensearch-dashboard/building-data-visualizations/using-maps/index.html"
  },"56": {
    "doc": "Using maps",
    "title": "Creating a new map",
    "content": "You can create a new map from the Maps or Visualize workflows by performing the following steps: . | To create a new map from the Maps workflow, perform the following steps: . | On the top menu bar, go to OpenSearch Plugins &gt; Maps. | Choose the Create map button. | . | To create a new map from the Visualize workflow, perform the following steps: . | On the top menu bar, go to OpenSearch Dashboards &gt; Visualize. | Choose the Create visualization button. | In the New Visualization dialog, choose Maps. | . | . You can now see the default OpenSearch basemap. To examine the Default map layer configuration, in the Layers panel on the upper left of the map, select Default map, as shown in the following image. To hide the Layers panel, select the collapse (arrow) icon in the panel’s upper-right corner. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/building-data-visualizations/using-maps/index.html#creating-a-new-map",
    "relUrl": "/analytics/opensearch-dashboard/building-data-visualizations/using-maps/index.html#creating-a-new-map"
  },"57": {
    "doc": "Using maps",
    "title": "Layer settings",
    "content": "To change the default map settings, select Default map in the Layers panel. Under Layer settings, you can change the layer name and description and configure zoom levels and opacity for your layer: . | Zoom levels: By default, a layer is visible at all zoom levels. If you want to make a layer visible only for a certain range of zoom levels, you can specify the zoom levels either by entering them in the text boxes or by sliding the range slider to the desired values. | Opacity: If your map contains multiple layers, one layer can obscure another one. In this case, you may want to reduce the opacity of the top layer so you can see both layers at the same time. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/building-data-visualizations/using-maps/index.html#layer-settings",
    "relUrl": "/analytics/opensearch-dashboard/building-data-visualizations/using-maps/index.html#layer-settings"
  },"58": {
    "doc": "Using maps",
    "title": "Adding layers",
    "content": "To add a layer to the map, in the Layers panel, select the Add layer button. The Add layer dialog is shown in the following image. You can add base layers or data layers to the map: . | A base layer serves as a basemap. To use your own or a third-party map as a base layer, add it as a Custom map. | Data layers let you visualize data from various data sources. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/building-data-visualizations/using-maps/index.html#adding-layers",
    "relUrl": "/analytics/opensearch-dashboard/building-data-visualizations/using-maps/index.html#adding-layers"
  },"59": {
    "doc": "Using maps",
    "title": "Adding a custom map",
    "content": "OpenSearch supports Web Map Service (WMS) or Tile Map Service (TMS) custom maps. To add a TMS custom map, perform the following steps: . | In the Layers panel, select the Add layer button. | From the Add layer dialog, select Base layer &gt; Custom map. Follow the next steps in the New layer dialog, which is shown in the following image. | In the Custom type dropdown list, select Tile Map Service (TMS). | Enter the TMS URL. | (Optional) In TMS attribution, enter a TMS attribution for the basemap. For example, if you’re using a custom basemap, enter the custom map name. This name will be displayed in the lower-right corner of the map. | Select the Settings tab to edit the layer settings. | Enter the layer name in Name. | (Optional) Enter the layer description in Description. | (Optional) Select the zoom levels and opacity for this layer. | Select the Update button. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/building-data-visualizations/using-maps/index.html#adding-a-custom-map",
    "relUrl": "/analytics/opensearch-dashboard/building-data-visualizations/using-maps/index.html#adding-a-custom-map"
  },"60": {
    "doc": "Using maps",
    "title": "Adding a document layer",
    "content": "Adding document layers lets you visualize your data. You can add one index pattern per document layer. To view multiple index patterns, create multiple layers. Document layers can display geopoint and geoshape document fields. The following example assumes that you have the opensearch_dashboards_sample_data_flights dataset installed. If you don’t have this dataset installed, perform the following steps: . | On the top left, select the home icon. | Select Add sample data. | In the Sample flight data panel, select the Add data button. | . Add a document layer as follows: . | In the Layers panel, select the Add layer button. | From the Add layer dialog, select Data layer &gt; Documents. | In Data source, select opensearch_dashboards_sample_data_flights. Alternatively, you can enter another index pattern to visualize. | In Geospatial field, select a geospatial field (geopoint or geoshape) to be displayed in the visualization. In this example, select DestLocation. | (Optional) Select the Style tab to change the fill color, border color, border thickness, or marker size. | Select the Settings tab to edit layer settings. | Enter Flight destination in Name. | Select the Update button. | To see more data, in the upper-right corner select the calendar icon dropdown list, then under Quick select, choose Last 15 days and select the Apply button. | . You should see the flight destination data, as in the following image. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/building-data-visualizations/using-maps/index.html#adding-a-document-layer",
    "relUrl": "/analytics/opensearch-dashboard/building-data-visualizations/using-maps/index.html#adding-a-document-layer"
  },"61": {
    "doc": "Using maps",
    "title": "Filtering data",
    "content": "To show a subset of the data in the index, filter the data. The following example filters the flight destination data to display only United States destinations: . | In the Layers panel, select Flight destination. | Select Filters. | Select Add filter. | In Edit filter, select DestCountry in Field. | In Operator, select is. | In Value, select US. | Select the Save button. | Select the Update button. | . For large datasets, you may want to avoid loading data for the whole map. To load data only for the part of the map that is currently visible, select the Only request data around map extent checkbox. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/building-data-visualizations/using-maps/index.html#filtering-data",
    "relUrl": "/analytics/opensearch-dashboard/building-data-visualizations/using-maps/index.html#filtering-data"
  },"62": {
    "doc": "Using maps",
    "title": "Using tooltips to visualize additional data",
    "content": "Document layers show geopoint and geoshape document fields as locations on the map. To add more information to the locations, you can use tooltips. For example, you may want to to show flight delay, destination weather, and destination country information in the Flight destination layer. Perform the following steps to configure tooltips to show additional data: . | In the Layers panel, select Flight destination. | Select Tooltips. | Select the Show tooltips checkbox. | In the Tooltip fields dropdown list, select the fields that you’d like to display. In this example, select FlightDelay, DestWeather, and DestCountry. | Select the Update button. | . To view tooltips, hover over the geographical point you’re interested in. One tooltip can display many data points. For example, in the Flight destination layer there are multiple flights for a single destination city. To paginate over the flights, select the city you’re interested in and use the arrows in the tooltip, as shown in the following image. If a point on the map contains data from multiple layers, one tooltip can display data from multiple layers. To see all layers, select All layers. To choose a particular layer, select the layer name in the tooltip layer selection panel, as shown in the following image. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/building-data-visualizations/using-maps/index.html#using-tooltips-to-visualize-additional-data",
    "relUrl": "/analytics/opensearch-dashboard/building-data-visualizations/using-maps/index.html#using-tooltips-to-visualize-additional-data"
  },"63": {
    "doc": "Using maps",
    "title": "Reordering, hiding, and deleting layers",
    "content": "The Layers panel lets you reorder, hide, and delete layers: . | Layers on a map are stacked on top of each other. To reorder layers, use the handlebar (two horizontal lines) icon next to the layer name to drag the layer to the desired position. | If you’d like to hide a layer, select the show/hide (eye) icon next to the layer name. Toggle the show/hide icon to show the layer again. | To delete a layer, select the delete (trash can) icon next to the layer name. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/building-data-visualizations/using-maps/index.html#reordering-hiding-and-deleting-layers",
    "relUrl": "/analytics/opensearch-dashboard/building-data-visualizations/using-maps/index.html#reordering-hiding-and-deleting-layers"
  },"64": {
    "doc": "Using maps",
    "title": "Refreshing data for a real-time dataset",
    "content": "If you want to visualize a real-time dataset, after adding layers to the map, perform the following steps to set the refresh interval: . | Select the calendar icon in the upper-right corner. | Under Refresh every, select or enter the refresh interval (for example, 1 second). | Select the Start button. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/building-data-visualizations/using-maps/index.html#refreshing-data-for-a-real-time-dataset",
    "relUrl": "/analytics/opensearch-dashboard/building-data-visualizations/using-maps/index.html#refreshing-data-for-a-real-time-dataset"
  },"65": {
    "doc": "Using maps",
    "title": "Saving a map",
    "content": "To save a map with all the layers that you set up, perform the following steps: . | Select the Save button in the upper-right corner. | In the Save map dialog, enter the map name in the Title text box. | (Optional) In the Description text box, enter the map description. | Select the Save button. | . To open your saved map, choose Maps in the upper-left corner. The list of saved maps is displayed. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/building-data-visualizations/using-maps/index.html#saving-a-map",
    "relUrl": "/analytics/opensearch-dashboard/building-data-visualizations/using-maps/index.html#saving-a-map"
  },"66": {
    "doc": "Using maps",
    "title": "Adding a map to a dashboard",
    "content": "You can add a new or existing map to a new or existing dashboard by performing the following steps: . | To add a map to a new dashboard, first create the dashboard as follows: . | On the top menu bar, go to OpenSearch Dashboards &gt; Dashboard. | Choose the Create dashboard button. | Choose the Create new button. | . | To add a map to an existing dashboard, first open the dashboard as follows: . | On the top menu bar, go to OpenSearch Dashboards &gt; Dashboard. | Select the dashboard you want to open from the list. | In the upper-right corner, choose Edit. | . | . Once you’ve opened a dashboard, you can add a new or existing map to it. Adding an existing map . | From the top menu, choose Add. | In the Types dropdown list, select Maps. | Select the map you want to add from the list. | . Adding a new map . | From the top menu, choose the Create new button. | In the New Visualization dialog, choose Maps. | Edit the default map by adding a basemap, layers, or tooltips. | In the upper-right corner, choose the Save button. | In the Save map dialog, enter the Title and optional Description of the map. | Select Add to Dashboard after saving (this option is selected by default). | Choose the Save and return button. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/building-data-visualizations/using-maps/index.html#adding-a-map-to-a-dashboard",
    "relUrl": "/analytics/opensearch-dashboard/building-data-visualizations/using-maps/index.html#adding-a-map-to-a-dashboard"
  },"67": {
    "doc": "Using maps",
    "title": "Editing a map from a dashboard",
    "content": ". | In the dashboard, choose the gear icon in the upper-right corner of the map you want to edit. | Choose Edit maps. | Edit the map. | In the upper-right corner, choose the Save button. | In the Save map dialog, choose the Save and return button. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/building-data-visualizations/using-maps/index.html#editing-a-map-from-a-dashboard",
    "relUrl": "/analytics/opensearch-dashboard/building-data-visualizations/using-maps/index.html#editing-a-map-from-a-dashboard"
  },"68": {
    "doc": "Using the self-host maps server",
    "title": "Using the self-host maps server",
    "content": "The self-host maps server for OpenSearch Dashboards allows users to access the default maps service in air-gapped environments. OpenSearch-compatible map URLs include a map manifest with map tiles and vectors, the map tiles, and the map vectors. The following sections provide steps for setting up and using the self-host maps server with OpenSearch Dashboards. You can access the maps-server image via the official OpenSearch Docker Hub repository. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/building-data-visualizations/selfhost-maps-server/index.html",
    "relUrl": "/analytics/opensearch-dashboard/building-data-visualizations/selfhost-maps-server/index.html"
  },"69": {
    "doc": "Using the self-host maps server",
    "title": "Pulling the Docker image",
    "content": "Open your terminal and run the following command: . docker pull opensearch/opensearch-maps-server . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/building-data-visualizations/selfhost-maps-server/index.html#pulling-the-docker-image",
    "relUrl": "/analytics/opensearch-dashboard/building-data-visualizations/selfhost-maps-server/index.html#pulling-the-docker-image"
  },"70": {
    "doc": "Using the self-host maps server",
    "title": "Setting up the server",
    "content": "You must set up the map tiles before running the server. You have two setup options: Use the OpenSearch-provided maps service tiles set, or generate the raster tiles set. Option 1: Use the OpenSearch-provided maps service tiles set . Create a Docker volume to hold the tiles set: . docker volume create tiles-data . Download the tiles set from the OpenSearch maps service. Two planet tiles sets are available based on the desired zoom level: . | Zoom Level 8 (https://maps.opensearch.org/offline/planet-osm-default-z0-z8.tar.gz) | Zoom level 10 (https://maps.opensearch.org/offline/planet-osm-default-z0-z10.tar.gz) | . The planet tiles set for zoom level 10 (2 GB compressed/6.8 GB uncompressed) is approximately 10 times larger than the set for zoom level 8 (225 MB compressed/519 MB uncompressed). docker run \\ -e DOWNLOAD_TILES=https://maps.opensearch.org/offline/planet-osm-default-z0-z8.tar.gz \\ -v tiles-data:/usr/src/app/public/tiles/data/ \\ opensearch/opensearch-maps-server \\ import . Option 2: Generate the raster tiles set . To generate the raster tiles set, use the raster tile generation pipeline and then use the tiles set absolute path to create a volume to start the server. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/building-data-visualizations/selfhost-maps-server/index.html#setting-up-the-server",
    "relUrl": "/analytics/opensearch-dashboard/building-data-visualizations/selfhost-maps-server/index.html#setting-up-the-server"
  },"71": {
    "doc": "Using the self-host maps server",
    "title": "Starting the server",
    "content": "Use the following command to start the server using the Docker volume tiles-data. The following command is an example using host URL “localhost” and port “8080”: . docker run \\ -v tiles-data:/usr/src/app/public/tiles/data/ \\ -e HOST_URL='http://localhost' \\ -p 8080:8080 \\ opensearch/opensearch-maps-server \\ run . Or, if you generated the raster tiles set, run the server using that tiles set: . docker run \\ -v /absolute/path/to/tiles/:/usr/src/app/dist/public/tiles/data/ \\ -p 8080:8080 \\ opensearch/opensearch-maps-server \\ run . To access the tiles set, open the URLs in a browser on the host or use the curl command curl http://localhost:8080/manifest.json. Confirm the server is running by opening each of the following links in a browser on your host or with a curl command (for example, curl http://localhost:8080/manifest.json). | Map manifest URL: http://localhost:8080/manifest.json | Map tiles URL: http://localhost:8080/tiles/data/{z}/{x}/{y}.png | Map tiles demo URL: http://localhost:8080/ | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/building-data-visualizations/selfhost-maps-server/index.html#starting-the-server",
    "relUrl": "/analytics/opensearch-dashboard/building-data-visualizations/selfhost-maps-server/index.html#starting-the-server"
  },"72": {
    "doc": "Using the self-host maps server",
    "title": "Using the self-host maps server with OpenSearch Dashboards",
    "content": "You can use the self-host maps server with OpenSearch Dashboards by either adding the parameter to opensearch_dashboards.yml or configuring the default WMS properties in OpenSearch Dashboards. Option 1: Configure opensearch_dashboards.yml . Configure the manifest URL in opensearch_dashboards.yml: . map.opensearchManifestServiceUrl: \"http://localhost:8080/manifest.json\" . Option 2: Configure Default WMS properties in OpenSearch Dashboards . | On the OpenSearch Dashboards console, select Stack Management &gt; Advanced Settings. | Locate visualization:tileMap:WMSdefaults under Default WMS properties. | Change \"enabled\": false to \"enabled\": true and add the URL for the valid map server. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/building-data-visualizations/selfhost-maps-server/index.html#using-the-self-host-maps-server-with-opensearch-dashboards",
    "relUrl": "/analytics/opensearch-dashboard/building-data-visualizations/selfhost-maps-server/index.html#using-the-self-host-maps-server-with-opensearch-dashboards"
  },"73": {
    "doc": "Using the self-host maps server",
    "title": "Licenses",
    "content": "Tiles are generated per Terms of Use for Natural Earth vector map data and Copyright and License for OpenStreetMap. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/building-data-visualizations/selfhost-maps-server/index.html#licenses",
    "relUrl": "/analytics/opensearch-dashboard/building-data-visualizations/selfhost-maps-server/index.html#licenses"
  },"74": {
    "doc": "Using the self-host maps server",
    "title": "Related articles",
    "content": ". | Configuring a Web Map Service (WMS) | Using coordinate and region maps | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/building-data-visualizations/selfhost-maps-server/index.html#related-articles",
    "relUrl": "/analytics/opensearch-dashboard/building-data-visualizations/selfhost-maps-server/index.html#related-articles"
  },"75": {
    "doc": "Using VisBuilder",
    "title": "Using VisBuilder",
    "content": "VisBuilder is an experimental feature and shouldn’t be used in a production environment. For updates on its progress, or if you want to leave feedback that helps improve the feature, see the GitHub issue. You can use the VisBuilder visualization type in OpenSearch Dashboards to create data visualizations by using a drag-and-drop gesture. With VisBuilder you have: . | An immediate view of your data without the need to preselect the visualization output. | The flexibility to change visualization types and index patterns quickly. | The ability to easily navigate between multiple screens. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/building-data-visualizations/using-vizbuilder/index.html",
    "relUrl": "/analytics/opensearch-dashboard/building-data-visualizations/using-vizbuilder/index.html"
  },"76": {
    "doc": "Using VisBuilder",
    "title": "Try VisBuilder in the OpenSearch Dashboards playground",
    "content": "If you’d like to try out VisBuilder without installing OpenSearch locally, you can do so in the Dashboards playground. VisBuilder is enabled by default. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/building-data-visualizations/using-vizbuilder/index.html#try-visbuilder-in-the-opensearch-dashboards-playground",
    "relUrl": "/analytics/opensearch-dashboard/building-data-visualizations/using-vizbuilder/index.html#try-visbuilder-in-the-opensearch-dashboards-playground"
  },"77": {
    "doc": "Using VisBuilder",
    "title": "Try VisBuilder locally",
    "content": "VisBuilder is enabled by default. If you want to disable it, set the feature flag vis_builder.enabled: to false in the opensearch_dashboards.yml file as follows: . # Set the value of this setting to false to disable VisBuilder # functionality in Visualization. vis_builder.enabled: false . Follow these steps to create a new visualization using VisBuilder in your environment: . | Open Dashboards: . | If you’re not running the security plugin, go to http://localhost:5601. | If you’re running the security plugin, go to https://localhost:5601 and log in with your username and password (default is admin/admin). | . | Confirm that the Enable experimental visualizations option is turned on. | From the top menu, select Management &gt; Stack Management &gt; Advanced Settings. | Select Visualization and verify that the option is turned on. | . | From the top menu, select Visualize &gt; Create visualization &gt; VisBuilder. | Drag and drop field names from the left column into the Configuration panel to generate a visualization. | . Here’s an example visualization. Your visualization will look different depending on your data and the fields you select. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/building-data-visualizations/using-vizbuilder/index.html#try-visbuilder-locally",
    "relUrl": "/analytics/opensearch-dashboard/building-data-visualizations/using-vizbuilder/index.html#try-visbuilder-locally"
  },"78": {
    "doc": "Building data visualizations",
    "title": "Building data visualizations",
    "content": "By visualizing your data, you translate complex, high-volume, or numerical data into a visual representation that is easier to process. OpenSearch Dashboards gives you data visualization tools to improve and automate the visual communication process. By using visual elements like charts, graphs, or maps to represent data, you can advance business intelligence and support data-driven decision-making and strategic planning. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/building-data-visualizations/index.html",
    "relUrl": "/analytics/opensearch-dashboard/building-data-visualizations/index.html"
  },"79": {
    "doc": "Building data visualizations",
    "title": "Understanding the visualization types in OpenSearch Dashboards",
    "content": "Dashboards has several visualization types to support your data analysis needs. The following sections provide an overview of the visualization types in Dashboards and their common use cases. Area charts . Area charts depict changes over time, and they are commonly used to show trends. Area charts more efficiently identify patterns in log data, such as sales data for a time range and trends over that time. See Using area charts to learn more about how to create and use them in Dashboards. Bar charts . Bar charts (vertical or horizontal) compare categorical data and depict changes of a variable over a period of time. Vertical bar chart . Horizontal bar chart . Controls . Controls is a panel, instead of a visualization type, added to a dashboard to filter data. Controls gives users the capability to add interactive inputs to a dashboard. You can create two types of controls in Dashboards: Options list and Range slider. Options list is a dropdown options list that allows filtering of data by a terms aggregation, such as machine.os.keyword. Range slider allows filtering within specified value ranges, such as hour_of_day. Data tables . Data tables, or tables, show your raw data in tabular form. Gantt charts . Gantt charts show the start, end, and duration of unique events in a sequence. Gantt charts are useful in trace analytics, telemetry, and anomaly detection use cases where you want to understand interactions and dependencies between various events in a schedule. Gantt chart is currently a plugin, instead of built-in, visualization type in Dashboards. See Gantt charts to learn how to create and use them in Dashboards. Gauge charts . Gauge charts look similar to an analog speedometer that reads left to right from zero. They display how much there is of the thing you are measuring, and this measurement can exist alone or in relation to another measurement, such as tracking performance against benchmarks or goals. Heat maps . A heat map is a view of a histogram (a graphical representation of the distribution of numerical data) over time. Instead of using bar height as a representation of frequency, as with a histogram, heat maps display data in a tabular form using colors to differentiate where values fall in a range. Line charts . Line charts compare changes in measured values over a period of time, such as gross sales by month or gross sales and net sales by month. Maps . You can create two types of maps in Dashboards: Coordinate maps and Region maps. Coordinate maps show the difference between data values for each location by size. Region maps show the difference between data values for each location by varying shades of color. See Using maps to learn more about maps capabilities in Dashboards. COORDINATE MAPS . Coordinate maps show location-based data on a map. Use coordinate maps to visualize GPS data (latitude and longitude coordinates) on a map. For information about OpenSearch-supported coordinate field types, see Geographic field types and Cartesian field types. REGION MAPS . Region maps show patterns and trends across geographic locations. A region map is one of the basemaps in Dashboards. For information about creating custom vector maps in Dashboards, see Using coordinate and region maps to learn how to create and use maps in Dashboards. Markdown . Markdown is a the markup language used in Dashboards to provide context to your data visualizations. Using Markdown, you can display information and instructions along with the visualization. Metric values . Metric values, or number charts, compare values in different measures. For example, you can create a metrics visualization to compare two values, such as actual sales compared to sales goals. Pie charts . Pie charts compare values for items in a dimension, such as a percentage of a total amount. TSVB . The time-series visual builder (TSVB) is a data visualization tool in Dashboards used to create detailed time-series visualizations. For example, you can use TSVB to build visualizations that show data over time, such as flights by status over time or flight delays by delay type over time. Currently, TSVB can be used to create the following Dashboards visualization types: Area, Line, Metric, Gauge, Markdown, and Data Table. Tag cloud . Tag (or word) clouds are a way to display how often a word is used in relation to other words in a dataset. The best use for this type of visual is to show word or phrase frequency. Timeline . Timeline is a data visualization tool in Dashboards that you can use to create time-series visualizations. Currently, Timeline can be used to create the following Dashboards visualization types: Area and Line. VisBuilder . VisBuilder is a drag-and-drop data visualization tool in Dashboards. It gives you an immediate view of your data without the need to preselect the data source or visualization type output. Currently, VisBuilder can be used to create the following Dashboards visualization types: Area, Bar, Line, Metric, and Data Table. See VisBuilder to learn how to create and use drag-and-drop visualizations in Dashboards. Vega . Vega and Vega-Lite are open-source, declarative language visualization grammars for creating, sharing, and saving interactive data visualizations. Vega visualizations give you the flexibility to visualize multidimensional data using a layered approach in order to build and manipulate visualizations in a structured manner. Vega can be used to create customized visualizations using any Dashboards visualization type. . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/building-data-visualizations/index.html#understanding-the-visualization-types-in-opensearch-dashboards",
    "relUrl": "/analytics/opensearch-dashboard/building-data-visualizations/index.html#understanding-the-visualization-types-in-opensearch-dashboards"
  },"80": {
    "doc": "Building data visualizations",
    "title": "Related articles",
    "content": ". | Using area charts | Using coordinate and region maps | Using Gantt charts | Using VisBuilder | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/building-data-visualizations/index.html#related-articles",
    "relUrl": "/analytics/opensearch-dashboard/building-data-visualizations/index.html#related-articles"
  },"81": {
    "doc": "Creating dashboards",
    "title": "Creating dashboards",
    "content": "The Dashboard application in OpenSearch Dashboards lets you visually represent your analytical, operational, and strategic data to help you quickly understand the trends in your data, giving you a high-level view of key metrics, simplifying data exploration, and delivering insights when and where you need them. In this tutorial you’ll learn the basics of creating a dashboard using the Dashboard application and OpenSearch sample data. The sample dataset has existing sample visualizations, and you can use those visualizations or create new visualizations for the dashboard. In this tutorial, you’ll do both. Once you’ve completed this tutorial, you’ll have learned the foundations of creating a new dashboard with multiple panels in OpenSearch Dashboards. This OpenSearch Playground dashboard example shows you what’s possible with OpenSearch Dashboards. ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/create-dashboard/index.html",
    "relUrl": "/analytics/opensearch-dasboard/create-dashboard/index.html"
  },"82": {
    "doc": "Creating dashboards",
    "title": "Getting familiar with the UI",
    "content": "Before getting started, let’s get familiar with the Dashboard UI. The UI comprises the following main components: . | The navigation panel (A) on the left contains the OpenSearch Dashboards applications. | The search bar (B) lets you search for documents and other objects and add filters. | The filter (C) lets you narrow a dashboard’s results. | The toolbar (D) contains frequently used commands and shortcuts. | The time filter (E) lets you customize the time and date. | The panel (F) allows you to add existing visualizations to the dashboard or create new ones for the dashboard. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/create-dashboard/index.html#getting-familiar-with-the-ui",
    "relUrl": "/analytics/opensearch-dasboard/create-dashboard/index.html#getting-familiar-with-the-ui"
  },"83": {
    "doc": "Creating dashboards",
    "title": "Defining terminology",
    "content": "The following is some useful terminology for working with OpenSearch Dashboards and the Dashboard application: . | Dashboards is the abbreviated name for OpenSearch Dashboards. OpenSearch Dashboards is an open-source visualization tool designed to work with OpenSearch. | Dashboard is the OpenSearch Dashboards application used to track, analyze, and display data. | dashboard or dashboards are common names for a tool used to visually display data. | Panel is a term used to refer to a visualization displayed on a dashboard. The terms panel and visualization may be used interchangeably throughout this and other Dashboards documentation. | . The following tutorial assumes you’re either using your existing installation of OpenSearch Dashboards or using the OpenSearch Playground. Depending on which one you use, certain capabilities may not be available. For example, sample datasets may not be included in your existing installation, and saving a dashboard isn’t an option in the OpenSearch Playground. ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/create-dashboard/index.html#defining-terminology",
    "relUrl": "/analytics/opensearch-dasboard/create-dashboard/index.html#defining-terminology"
  },"84": {
    "doc": "Creating dashboards",
    "title": "Creating a dashboard and adding an existing visualization",
    "content": "To create a dashboard and add a sample visualization: . | Connect to https://localhost:5601. The username and password are admin. Alternatively, go to the OpenSearch Playground. | On the top menu, go to OpenSearch Dashboards &gt; Dashboard. | From the Dashboards panel, choose Create Dashboard. | Choose the calendar icon and set the time filter to Last 30 days. | From the panel, choose Add an existing. | From the Add panels window, choose [eCommerce] Promotion Tracking, and then choose x to close the panel. | . You’ve now created the following basic dashboard with a single panel, which you’ll continue using throughout this tutorial. ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/create-dashboard/index.html#creating-a-dashboard-and-adding-an-existing-visualization",
    "relUrl": "/analytics/opensearch-dasboard/create-dashboard/index.html#creating-a-dashboard-and-adding-an-existing-visualization"
  },"85": {
    "doc": "Creating dashboards",
    "title": "Creating visualizations",
    "content": "Continuing with the dashboard you created in the preceding steps, you’ll create a new visualization and save it to the dashboard: . | From the dashboard toolbar, choose Create new. | From the New Visualization window, choose Gauge and then select the index pattern opensearch_dashboards_sample_data_ecommerce. | From the toolbar, choose Save. | In the Save visualization window, enter a title for the visualization. For example, the title for the gauge chart panel is [eCommerce] Orders. | Choose Save and return. | . The gauge chart visualization is now saved and you are taken back to the dashboard. You’ll see two visualizations on the dashboard, like the following. ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/create-dashboard/index.html#creating-visualizations",
    "relUrl": "/analytics/opensearch-dasboard/create-dashboard/index.html#creating-visualizations"
  },"86": {
    "doc": "Creating dashboards",
    "title": "Adding subsequent panels",
    "content": "Continuing with the dashboard you created in the preceding steps, you’ll add an existing visualization to the dashboard: . | From the dashboard toolbar, choose Add. | From the Add panels window, choose [eCommerce] Sales by Category. | Choose x to close the Add panels window. | . You’ll see an area chart visualization display on the dashboard, as shown in the following image. ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/create-dashboard/index.html#adding-subsequent-panels",
    "relUrl": "/analytics/opensearch-dasboard/create-dashboard/index.html#adding-subsequent-panels"
  },"87": {
    "doc": "Creating dashboards",
    "title": "Saving dashboards",
    "content": "When you’ve finalized your dashboard, save it. If you’re saving a new dashboard: . | In the toolbar, choose Save. | In the Save dashboard window, enter the Title. The Description is optional. | To save the time filter to the dashboard, select Store time with dashboard. | Choose Save. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/create-dashboard/index.html#saving-dashboards",
    "relUrl": "/analytics/opensearch-dasboard/create-dashboard/index.html#saving-dashboards"
  },"88": {
    "doc": "Creating dashboards",
    "title": "Customizing the look of a panel",
    "content": "To customize the panels, you’ll need to be in edit mode: . | Choose Edit at the top right of the toolbar. | . If you see Create new at the top right of the toolbar, you’re already in edit mode. Displaying a legend can give readers more information, while hiding a legend can give the panel a cleaner look. If you want to display or hide the panel legend: . | Choose the list icon in the panel’s lower left corner. | . If you want to change the color of the panel legend: . | From the visualization legend, select a category and then select a color from the flyout. The area chart updates with your change. | . This color change is only saved for the current panel and dashboard and doesn’t affect the saved visualization. If you want to change the color of the panel legend in the visualization: . | Choose the gear icon on the area chart panel. | From the Options window, select Edit visualization. | From the visualization legend, select a category and then select a color from the flyout. The area chart updates with your change. | Choose Save and return. | . This color change affects the saved visualization and any dashboard that links to the visualization. If you want to display, hide, or customize the panel title: . | Choose the gear icon on the panel. | From the Options window, select Edit panel title. | From the Customize panel, enter a title under Panel title or toggle the Show panel title to hide the title. | Choose Save. | . Changing panel titles only affects the particular panel on the particular dashboard and won’t affect any other panel containing that same visualization or any other dashboard. ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/create-dashboard/index.html#customizing-the-look-of-a-panel",
    "relUrl": "/analytics/opensearch-dasboard/create-dashboard/index.html#customizing-the-look-of-a-panel"
  },"89": {
    "doc": "Creating dashboards",
    "title": "Arranging panels",
    "content": "To organize panels, arrange them side by side, or resize them, you can use these options: . | To move a panel, select and hold the panel title or the top of the panel and drag to the new location. | To resize a panel, choose the resize icon in the panel’s lower-right corner and drag to the new dimensions. | To view a panel in full screen mode, choose the gear icon (edit mode) or vertical ellipsis (⋮) at the top right of the panel and select Maximize panel. To minimize the full screen mode, choose the gear icon or vertical ellipsis and select Minimize. | . The following is an example of a customized dashboard created by using this tutorial. ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/create-dashboard/index.html#arranging-panels",
    "relUrl": "/analytics/opensearch-dasboard/create-dashboard/index.html#arranging-panels"
  },"90": {
    "doc": "Creating reports with the Dashboards interface",
    "title": "Creating reports with the Dashboards interface",
    "content": "You can use OpenSearch Dashboards to create PNG, PDF, and CSV reports. To create reports, you must have the correct permissions. For a summary of the predefined roles and the permissions they grant, see the security plugin. CSV reports have a non-configurable 10,000 row limit. They have no explicit size limit (for example, MB), but extremely large documents could cause report generation to fail with an out of memory error from the V8 JavaScript engine. ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/create-reports-dashboard/index.html",
    "relUrl": "/analytics/opensearch-dasboard/create-reports-dashboard/index.html"
  },"91": {
    "doc": "Creating reports with the Dashboards interface",
    "title": "Generating reports with the interface",
    "content": "To generate a report from the interface: . | From the navigation panel, choose Reporting. | For dashboards, visualizations, or notebooks, choose Download PDF or Download PNG. If you’re creating a report from the Discover page, choose Generate CSV. REPORTS GENERATE ASYNCHRONOUSLY IN THE BACKGROUND AND MIGHT TAKE A FEW MINUTES, DEPENDING ON THE SIZE OF THE REPORT. A NOTIFICATION APPEARS WHEN YOUR REPORT IS READY TO DOWNLOAD. | To create a schedule-based report, choose Create report definition. Then proceed to Create reports using a definition. This option pre-fills many of the fields for you based on the visualization, dashboard, or data you were viewing. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/create-reports-dashboard/index.html#generating-reports-with-the-interface",
    "relUrl": "/analytics/opensearch-dasboard/create-reports-dashboard/index.html#generating-reports-with-the-interface"
  },"92": {
    "doc": "Creating reports with the Dashboards interface",
    "title": "Creating reports using a definition",
    "content": "Definitions let you generate reports on a periodic schedule. | From the navigation panel, choose Reporting. | Choose Create. | Under Report settings, enter a name and optional description for your report. | Choose the Report source (i.e. the page from which the report is generated). You can generate reports from the Dashboard, Visualize, Discover (saved search), or Notebooks pages. | Select your dashboard, visualization, saved search, or notebook. Then choose a time range for the report. | Choose an appropriate file format for the report. | (Optional) Add a header or footer to the report. Headers and footers are only available for dashboard, visualization, and notebook reports. | Under Report trigger, choose either On demand or Schedule. For scheduled reports, select either Recurring or Cron based. You can receive reports daily or at some other time interval, and Cron expressions give you more flexibility. See Cron expression reference for more information. | Choose Create. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/create-reports-dashboard/index.html#creating-reports-using-a-definition",
    "relUrl": "/analytics/opensearch-dasboard/create-reports-dashboard/index.html#creating-reports-using-a-definition"
  },"93": {
    "doc": "Creating reports with the Dashboards interface",
    "title": "Troubleshooting",
    "content": "Chromium fails to launch with OpenSearch Dashboards . While creating a report for dashboards or visualizations, you might see a the following error: . This problem can occur for two reasons: . | You don’t have the correct version of headless-chrome to match the operating system on which OpenSearch Dashboards is running. Download the correct version. | You’re missing additional dependencies. Install the required dependencies for your operating system from the additional libraries section. | . Characters not loading in reports . You might encounter an issue where UTF-8 encoded characters look fine in your browser, but they don’t load in your generated reports because you’re missing the required font dependencies. Install the font dependencies, and then generate your reports again. ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/create-reports-dashboard/index.html#troubleshooting",
    "relUrl": "/analytics/opensearch-dasboard/create-reports-dashboard/index.html#troubleshooting"
  },"94": {
    "doc": "Creating and requesting a visualization report",
    "title": "Creating and requesting a visualization report",
    "content": "First, you need to get the URL for the visualization that you want to download as an image file or PDF. To generate a visualization report, you need to specify the Dashboards URL. Open the visualization for which you want to generate a report, and select Share &gt; Permalinks &gt; Generate link as Shapshot &gt; Short URL &gt; Copy link, as shown in the following image. You will need to add the URL with the -u argument when you request the report in the CLI. EXAMPLE: REQUESTING A PNG FILE . The following command requests a report in PNG format with basic authentication and sends the report to an email address using Amazon SES: . opensearch-reporting-cli -u https://localhost:5601/app/dashboards#/view/7adfa750-4c81-11e8-b3d7-01146121b73d -a basic -c admin:Test@1234 -e ses -s &lt;email address&gt; -r &lt;email address&gt; -f png . EXAMPLE: REQUESTING A PDF FILE . The following command requests a PDF file and specifies the recipient’s email address: . opensearch-reporting-cli -u https://localhost:5601/app/dashboards#/view/7adfa750-4c81-11e8-b3d7-01146121b73d -a basic -c admin:Test@1234 -e ses -s &lt;email address&gt; -r &lt;email address&gt; -f pdf . Upon success, the file will be sent to the specified email address. The following image shows an example PDF report. EXAMPLE: REQUESTING A CSV FILE . The following command generates a report that contains all table content in CSV format and sends the report to an email address using Amazon SES transport: . opensearch-reporting-cli -u https://localhost:5601/app/dashboards#/view/7adfa750-4c81-11e8-b3d7-01146121b73d -f csv -a basic -c admin:Test@1234 -e ses -s &lt;email address&gt; -r &lt;email address&gt; . Upon success, the email will be sent to the specified email address with the CSV file attached. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/creating-reports-with-the-reporting-cli/create-viz-report/index.html",
    "relUrl": "/analytics/opensearch-dashboard/creating-reports-with-the-reporting-cli/create-viz-report/index.html"
  },"95": {
    "doc": "Downloading and installing the Reporting CLI tool",
    "title": "Downloading and installing the Reporting CLI tool",
    "content": "You can download and install the Reporting CLI tool from either the npm software registry or the OpenSearch.org Artifacts hub. Refer to the following sections for instructions. To learn more about the npm software registry, see the npm documentation. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/creating-reports-with-the-reporting-cli/download-cli/index.html",
    "relUrl": "/analytics/opensearch-dashboard/creating-reports-with-the-reporting-cli/download-cli/index.html"
  },"96": {
    "doc": "Downloading and installing the Reporting CLI tool",
    "title": "Downloading and installing the Reporting CLI from npm",
    "content": "To download and install the Reporting CLI from npm, run the following command to initiate installation: . npm i @opensearch-project/reporting-cli . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/creating-reports-with-the-reporting-cli/download-cli/index.html#downloading-and-installing-the-reporting-cli-from-npm",
    "relUrl": "/analytics/opensearch-dashboard/creating-reports-with-the-reporting-cli/download-cli/index.html#downloading-and-installing-the-reporting-cli-from-npm"
  },"97": {
    "doc": "Downloading and installing the Reporting CLI tool",
    "title": "Downloading and installing the Reporting CLI from OpenSearch.org",
    "content": "You can download the opensearch-reporting-cli tool from the OpenSearch.org Artifacts hub. Next, run the following command to install the .tar archive: . npm install -g opensearch-reporting-cli-1.0.0.tgz . To provide better security for artifacts, we recommend that you verify signatures by downloading the Reporting CLI signature file. To learn more about verifying signatures, see How to verify signatures for downloadable artifacts. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/creating-reports-with-the-reporting-cli/download-cli/index.html#downloading-and-installing-the-reporting-cli-from-opensearchorg",
    "relUrl": "/analytics/opensearch-dashboard/creating-reports-with-the-reporting-cli/download-cli/index.html#downloading-and-installing-the-reporting-cli-from-opensearchorg"
  },"98": {
    "doc": "Creating reports with the Reporting CLI",
    "title": "Creating reports with the Reporting CLI",
    "content": "You can programmatically create dashboard reports in PDF or PNG format with the Reporting CLI without using OpenSearch Dashboards or the Reporting plugin. This allows you to create reports automatically within your email workflows. If you want to download a CSV file, you need to have the Reporting plugin installed. For any dashboard view, you can request a report in PNG or PDF format to be sent to an email address. This can be useful for sending reports to multiple email recipients with an email alias. The only dashboard application that supports creating a CSV report is Discover. With the Reporting CLI, you can specify options for your report in the command line. The report is sent to an email address as a PDF attachment by default. You can also request a PNG image or a CSV file with the --formats argument. You can download the report to the directory in which you are running the Reporting CLI, or you can email the report by specifying Amazon Simple Email Service (Amazon SES) or SMTP for the email transport option. You can connect to OpenSearch with any of the following authentication types: . | Basic – Basic HTTP authentication. Use -a basic. | Cognito – Authentication through Amazon Cognito. Use -a cognito. | SAML – Authentication between an identity provider and a service provider. Use -a saml. Okta provides the SAML third-party authentication. | No auth – No authentication. Use -a none. Authentication defaults to No auth if the -a flag is not specified. | . To learn more about Amazon Cognito, see What is Amazon Cognito?. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/creating-reports-with-the-reporting-cli/index.html",
    "relUrl": "/analytics/opensearch-dashboard/creating-reports-with-the-reporting-cli/index.html"
  },"99": {
    "doc": "Creating reports with the Reporting CLI",
    "title": "Related articles",
    "content": ". | Downloading and installing the Reporting CLI tool | Creating and requesting a visualization report | Scheduling reports with the cron utility | Scheduling reports with AWS Lambda | Reporting CLI options | Using environment variables with the Reporting CLI | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/creating-reports-with-the-reporting-cli/index.html#related-articles",
    "relUrl": "/analytics/opensearch-dashboard/creating-reports-with-the-reporting-cli/index.html#related-articles"
  },"100": {
    "doc": "Reporting CLI options",
    "title": "Reporting CLI options",
    "content": "You can use any of the following arguments with the opensearch-reporting-cli tool. | Argument | Description | Acceptable values and usage | Environment variable | . | -u, –url | The URL for the visualization. | Obtain from OpenSearch Dashboards &gt; Visualize &gt; Share &gt; Permalinks &gt; Copy link. | OPENSEARCH_URL | . | -a, –auth | The authentication type for the report. | You can specify either Basic basic, Cognito cognito, SAML saml, or No Auth none. If no value is specified, the Reporting CLI tool defaults to no authentication, type none. Basic, Cognito, and SAML require credentials with the -c flag. | N/A | . | -c, –credentials | The OpenSearch login credentials. | Enter your username and password separated by a colon. For example, username:password. Required for Basic, Cognito, and SAML authentication types. | OPENSEARCH_USERNAME and OPENSEARCH_PASSWORD | . | -t, –tenant | The tenants in OpenSearch Dashboards. | The default tenant is private. | N/A | . | -f, –format | The file format for the report. | Can be either pdf, png, or csv. The default is pdf. | N/A | . | -w, –width | The window width in pixels for the report. | Default is 1680. | N/A | . | -l, –height | The minimum window height in pixels for the report. | Default is 600. | N/A | . | -n, –filename | The file name of the report. | Default is reporting. | opensearch-report-YYY-MM-DDTHH-mm-ss.sssZ | . | -e, –transport | The transport mechanism for sending the email. | For Amazon SES, specify ses. Amazon SES requires an AWS configuration on your system to store the credentials. For SMTP, use smtp and also specify the login credentials with –smtpusername and –smtppassword. | OPENSEARCH_TRANSPORT | . | -s, –from | The email address of the sender. | For example, user@amazon.com. | OPENSEARCH_FROM | . | -r, –to | The email address of the recipient. | For example, user@amazon.com. | OPENSEARCH_TO | . | –smtphost | The hostname of the SMTP server. | For example, SMTP_HOST. | OPENSEARCH_SMTP_HOST | . | –smtpport | The port for the SMTP connection. | For example, SMTP_PORT. | OPENSEARCH_SMTP_PORT | . | –smtpsecure | Specifies to use TLS when connecting to the server. | For example, SMTP_SECURE. | OPENSEARCH_SMTP_SECURE | . | –smtpusername | The SMTP username. | For example, SMTP_USERNAME. | OPENSEARCH_SMTP_USERNAME | . | –smtppassword | The SMTP password. | For example, SMTP_PASSWORD. | OPENSEARCH_SMTP_PASSWORD | . | –subject | The email subject text encased in quotes. | Can be any string. The default is “This is an email containing your dashboard report”. | OPENSEARCH_EMAIL_SUBJECT | . | –note | The email body, either a string or a path to a text file. | file. The default note is “Hi,\\nHere is the latest report!” | OPENSEARCH_EMAIL_NOTE | . | -h, –help | Specifies to display the list of optional arguments from the command line. | N/A |   | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/creating-reports-with-the-reporting-cli/reporting-cli-options/index.html",
    "relUrl": "/analytics/opensearch-dashboard/creating-reports-with-the-reporting-cli/reporting-cli-options/index.html"
  },"101": {
    "doc": "Reporting CLI options",
    "title": "Getting help",
    "content": "To get a list of all available CLI arguments, run the following command: . $ opensearch-reporting-cli -h . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/creating-reports-with-the-reporting-cli/reporting-cli-options/index.html#getting-help",
    "relUrl": "/analytics/opensearch-dashboard/creating-reports-with-the-reporting-cli/reporting-cli-options/index.html#getting-help"
  },"102": {
    "doc": "Scheduling reports with AWS Lambda",
    "title": "Scheduling reports with AWS Lambda",
    "content": "You can use AWS Lambda with the Reporting CLI tool to specify an AWS Lambda function to trigger the report generation. This requires that you use an AMD64 system and Docker. Prerequisites . To use the Reporting CLI with AWS Lambda, you need to do the following preliminary steps. | Get an AWS account. For instructions, see Creating an AWS account in the AWS Account Management reference guide. | Set up an Amazon Elastic Container Registry (ECR). For instructions, see Getting started with Amazon ECR using the AWS Management Console. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/creating-reports-with-the-reporting-cli/schedule-aws-reports/index.html",
    "relUrl": "/analytics/opensearch-dashboard/creating-reports-with-the-reporting-cli/schedule-aws-reports/index.html"
  },"103": {
    "doc": "Scheduling reports with AWS Lambda",
    "title": "Step 1: Create a container image with a Dockerfile",
    "content": "You need to assemble the container image by running a Dockerfile. When you run the Dockerfile, it downloads the OpenSearch artifact required to use the Reporting CLI. To learn more about Dockerfiles, see Dockerfile reference. Copy the following sample configurations into a Dockerfile: . # Define function directory ARG FUNCTION_DIR=\"/function\" # Base image of the docker container FROM node:lts-slim as build-image # Include global arg in this stage of the build ARG FUNCTION_DIR # AWS Lambda runtime dependencies RUN apt-get update &amp;&amp; \\ apt-get install -y \\ g++ \\ make \\ unzip \\ libcurl4-openssl-dev \\ autoconf \\ automake \\ libtool \\ cmake \\ python3 \\ libkrb5-dev \\ curl # Copy function code WORKDIR ${FUNCTION_DIR} RUN npm install @opensearch-project/reporting-cli &amp;&amp; npm install aws-lambda-ric # Build Stage 2: Copy Build Stage 1 files in to Stage 2. Install chrome, then remove chrome to keep the dependencies. FROM node:lts-slim # Include global arg in this stage of the build ARG FUNCTION_DIR # Set working directory to function root directory WORKDIR ${FUNCTION_DIR} # Copy in the build image dependencies COPY --from=build-image ${FUNCTION_DIR} ${FUNCTION_DIR} # Install latest chrome dev package and fonts to support major char sets (Chinese, Japanese, Arabic, Hebrew, Thai and a few others) # Note: this installs the necessary libs to make the bundled version of Chromium that Puppeteer installs, work. RUN apt-get update \\ &amp;&amp; apt-get install -y wget gnupg \\ &amp;&amp; wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | apt-key add - \\ &amp;&amp; sh -c 'echo \"deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main\" &gt;&gt; /etc/apt/sources.list.d/google.list' \\ &amp;&amp; apt-get update \\ &amp;&amp; apt-get install -y google-chrome-stable fonts-ipafont-gothic fonts-wqy-zenhei fonts-thai-tlwg fonts-kacst fonts-freefont-ttf libxss1 \\ --no-install-recommends \\ &amp;&amp; apt-get remove -y google-chrome-stable \\ &amp;&amp; rm -rf /var/lib/apt/lists/* ENTRYPOINT [\"/usr/local/bin/npx\", \"aws-lambda-ric\"] ENV HOME=\"/tmp\" CMD [ \"/function/node_modules/@opensearch-project/reporting-cli/src/index.handler\" ] . Next, run the following build command within the same directory that contains the Dockerfile: . docker build -t opensearch-reporting-cli . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/creating-reports-with-the-reporting-cli/schedule-aws-reports/index.html#step-1-create-a-container-image-with-a-dockerfile",
    "relUrl": "/analytics/opensearch-dashboard/creating-reports-with-the-reporting-cli/schedule-aws-reports/index.html#step-1-create-a-container-image-with-a-dockerfile"
  },"104": {
    "doc": "Scheduling reports with AWS Lambda",
    "title": "Step 2: Create a private repository with Amazon ECR",
    "content": "You need to follow the instructions to create an image repository, see Getting started with Amazon ECR using the AWS Management Console. Give your repository the name opensearch-reporting-cli. In addition to the Amazon ECR instructions, you need to make several adjustments for the Reporting CLI to function properly as described in the following steps in this procedure. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/creating-reports-with-the-reporting-cli/schedule-aws-reports/index.html#step-2-create-a-private-repository-with-amazon-ecr",
    "relUrl": "/analytics/opensearch-dashboard/creating-reports-with-the-reporting-cli/schedule-aws-reports/index.html#step-2-create-a-private-repository-with-amazon-ecr"
  },"105": {
    "doc": "Scheduling reports with AWS Lambda",
    "title": "Step 3: Push the image to the private repository",
    "content": "You need to get several commands from the AWS ECR Console to run within the Dockerfile directory. | After you create your repository, select it from Private repositories. | Choose view push commands. | Copy and run each command shown in Push commands for opensearch-reporting-cli sequentially in the Dockerfile directory. | . For more details about Docker push commands, see Pushing a Docker image in the Amazon ECR user guide. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/creating-reports-with-the-reporting-cli/schedule-aws-reports/index.html#step-3-push-the-image-to-the-private-repository",
    "relUrl": "/analytics/opensearch-dashboard/creating-reports-with-the-reporting-cli/schedule-aws-reports/index.html#step-3-push-the-image-to-the-private-repository"
  },"106": {
    "doc": "Scheduling reports with AWS Lambda",
    "title": "Step 4: Create a Lambda function with the container image",
    "content": "Now that you have a container image created for the Reporting CLI, you need to create a function defined as the container image. | Open the AWS Lambda console and choose Functions. | Choose Create function, then choose Container image and fill in a name for the function. | In Container image URI, choose Browse images and select opensearch-reporting-cli for the image repository. | In Images select the image, and choose Select image. | In Architecture, choose x86_64. | Choose Create function. | Go to Lambda &gt; functions and choose the function you created. | Choose Configuration &gt; General configuration &gt; Edit timeout and set the timeout in lambda to 5 minutes to allow the Reporting CLI to generate the report. | Change the Ephemeral storage setting to at least 1024MB. The default setting is not a sufficient storage amount to support report generation. | Next, test the function either by providing values JSON format or by providing AWS Lambda environment variables. | . | If the function contains fixed values, such as email address you do not need a JSON file. You can specify an environment variable in AWS Lambda. | If the function takes a variable key-value pair, then you need to specify the values in the JSON with the same naming convention as command options, for example the --credentials option requires the username and password. | . The following example shows fixed values provided for the sender and recipient email addresses: . { \"url\": \"https://playground.opensearch.org/app/dashboards#/view/084aed50-6f48-11ed-a3d5-1ddbf0afc873\", \"transport\": \"ses\", \"from\": \"sender@amazon.com\", \"to\": \"recipient@amazon.com\", \"subject\": \"Test lambda docker image\" } . To learn more about AWS Lambda functions, see Deploying Lambda functions as container images in the AWS Lambda documentation. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/creating-reports-with-the-reporting-cli/schedule-aws-reports/index.html#step-4-create-a-lambda-function-with-the-container-image",
    "relUrl": "/analytics/opensearch-dashboard/creating-reports-with-the-reporting-cli/schedule-aws-reports/index.html#step-4-create-a-lambda-function-with-the-container-image"
  },"107": {
    "doc": "Scheduling reports with AWS Lambda",
    "title": "Step 5: Add the trigger to start the AWS Lambda function",
    "content": "Set the trigger to start running the report. AWS Lambda can use any AWS service as a trigger, such as SNS, S3, or an AWS CloudWatch EventBridge. | In the Triggers section, choose Add trigger. | Select a trigger from the list. For example, you can set an AWS CloudWatch Event. To learn more about Amazon ECR events you can schedule, see Sample events from Amazon ECR. | Choose Test to initiate the function. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/creating-reports-with-the-reporting-cli/schedule-aws-reports/index.html#step-5-add-the-trigger-to-start-the-aws-lambda-function",
    "relUrl": "/analytics/opensearch-dashboard/creating-reports-with-the-reporting-cli/schedule-aws-reports/index.html#step-5-add-the-trigger-to-start-the-aws-lambda-function"
  },"108": {
    "doc": "Scheduling reports with AWS Lambda",
    "title": "(Optional) Step 6: Add the role permission for Amazon SES",
    "content": "If you want to use Amazon SES for the email transport, you need to set up permissions. | Select Configuration and choose Execution role. | In Summary, choose Permissions. | Select {}JSON to open the JSON policy editor. | Add the permissions for the Amazon SES resource that you want to use. | . The following example provides the resource ARN for the send email action: . { \"Effect\": \"Allow\", \"Action\": [ \"ses:SendEmail\", \"ses:SendRawEmail\" ], \"Resource\": \"arn:aws:ses:us-west-2:555555511111:identity/username@amazon.com\" } . To learn more about setting role permissions, see Permissions in the AWS Lambda user guide. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/creating-reports-with-the-reporting-cli/schedule-aws-reports/index.html#optional-step-6-add-the-role-permission-for-amazon-ses",
    "relUrl": "/analytics/opensearch-dashboard/creating-reports-with-the-reporting-cli/schedule-aws-reports/index.html#optional-step-6-add-the-role-permission-for-amazon-ses"
  },"109": {
    "doc": "Scheduling reports with the cron utility",
    "title": "Scheduling reports with the cron utility",
    "content": "You can use the cron command-line utility to initiate a report request with the Reporting CLI that runs periodically at any date or time interval. Follow the cron expression syntax to specify the date and time that precedes the command that you want to initiate. To learn about the cron expression syntax, see Cron expression reference. To get help with cron, open the man page by running the following command: . man cron . Prerequisites . | You need a machine with cron installed. | You need to install the Reporting CLI. See Downloading and installing the Reporting CLI tool | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/creating-reports-with-the-reporting-cli/schedule-cron-reports/index.html",
    "relUrl": "/analytics/opensearch-dashboard/creating-reports-with-the-reporting-cli/schedule-cron-reports/index.html"
  },"110": {
    "doc": "Scheduling reports with the cron utility",
    "title": "Specifying the report details",
    "content": "Open the crontab editor by running the following command: . crontab -e . In the crontab editor, enter the report request. The following example shows a cron report that runs every day at 8:00 AM: . 0 8 * * * opensearch-reporting-cli -u https://playground.opensearch.org/app/dashboards#/view/084aed50-6f48-11ed-a3d5-1ddbf0afc873 -e ses -s &lt; . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/creating-reports-with-the-reporting-cli/schedule-cron-reports/index.html#specifying-the-report-details",
    "relUrl": "/analytics/opensearch-dashboard/creating-reports-with-the-reporting-cli/schedule-cron-reports/index.html#specifying-the-report-details"
  },"111": {
    "doc": "Using environment variables with the Reporting CLI",
    "title": "Using environment variables with the Reporting CLI",
    "content": "Instead of explicitly providing values in the command line, you can save them as environment variables. The Reporting CLI reads environment variables from the current directory inside the project. To set the environment variables in Linux, use the following command: . export NAME=VALUE . Each line should use the format NAME=VALUE. Each line that starts with a hashtag (#) is considered to be a comment. Quotation marks (“) don’t get any special handling. Values from the command line argument have higher priority than the environment file. For example, if you add the file name as test in the .env file and also add the --filename report command option, the generated report’s name will be report. EXAMPLE: REQUESTING A PNG REPORT WITH ENVIRONMENT VARIABLES SET . The following command requests a report with basic authentication in PNG format: . opensearch-reporting-cli --url https://localhost:5601/app/dashboards#/view/7adfa750-4c81-11e8-b3d7-01146121b73d --format png --auth basic --credentials admin:admin . Upon success, the report will download to the current directory. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/creating-reports-with-the-reporting-cli/using-env/index.html",
    "relUrl": "/analytics/opensearch-dashboard/creating-reports-with-the-reporting-cli/using-env/index.html"
  },"112": {
    "doc": "Using environment variables with the Reporting CLI",
    "title": "Using Amazon SES to request an email with a report attachment",
    "content": "To use Amazon SES as the email transport mechanism, the following prerequisites apply: . | The sender’s email address must be verified by Amazon SES. The AWS Command Line Interface (AWS CLI) is required to interact with Amazon SES. To configure basic settings used by the AWS CLI, see Quick configuration with aws configure in the AWS Command Line Interface user guide. | Amazon SES transport requires the ses:SendRawEmail role: | . { \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"ses:SendRawEmail\", \"Resource\": \"*\" } ] } . The following command requests an email with the report attached: . opensearch-reporting-cli --url https://localhost:5601/app/dashboards#/view/7adfa750-4c81-11e8-b3d7-01146121b73d --transport ses --from &lt;sender_email_id&gt; --to &lt;recipient_email_id&gt; . The following command uses default values for all other options. You can also set OPENSEARCH_FROM, OPENSEARCH_TO, and OPENSEARCH_TRANSPORT in your .env file and use the following command: . opensearch-reporting-cli --url https://localhost:5601/app/dashboards#/view/7adfa750-4c81-11e8-b3d7-01146121b73d . To modify the body of your email, you can edit the index.hbs file. EXAMPLE: SENDING A REPORT TO AN EMAIL ADDRESS WITH SMTP . To send a report to an email address with SMTP transport, you need to set the options OPENSEARCH_SMTP_HOST, OPENSEARCH_SMTP_PORT, OPENSEARCH_SMTP_USER, OPENSEARCH_SMTP_PASSWORD, and OPENSEARCH_SMTP_SECURE in your .env file. Once the transport options are set in your .env file, you can send the email using the following command: . opensearch-reporting-cli --url https://localhost:5601/app/dashboards#/view/7adfa750-4c81-11e8-b3d7-01146121b73d --transport smtp --from &lt;sender_email_id&gt; --to &lt;recipient_email_id&gt; . You can choose to set options using either your .env file or the command line argument values in any combination. Make sure to specify all required values to avoid errors. To modify the body of your email, you can edit the index.hbs file. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/creating-reports-with-the-reporting-cli/using-env/index.html#using-amazon-ses-to-request-an-email-with-a-report-attachment",
    "relUrl": "/analytics/opensearch-dashboard/creating-reports-with-the-reporting-cli/using-env/index.html#using-amazon-ses-to-request-an-email-with-a-report-attachment"
  },"113": {
    "doc": "Using environment variables with the Reporting CLI",
    "title": "Limitations",
    "content": "The following limitations apply to environment variable usage with the Reporting CLI: . | Supported platforms are Windows x86, Windows x64, Mac Intel, Mac ARM, Linux x86, and Linux x64. For any other platform, users can take advantage of the CHROMIUM_PATH environment variable to use custom Chromium. | If a URL contains an exclamation point (!), then the history expansion needs to be disabled temporarily. Depending on which shell you are using, you can disable history expansion using one of the following commands: . | For bash, use set +H. | For zsh, use setopt nobanghist. | . Alternatively, you can add a URL value as an environment variable using this format: URL=\"&lt;url-with-!&gt;\". | All command options only accept lowercase letters. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/creating-reports-with-the-reporting-cli/using-env/index.html#limitations",
    "relUrl": "/analytics/opensearch-dashboard/creating-reports-with-the-reporting-cli/using-env/index.html#limitations"
  },"114": {
    "doc": "Using environment variables with the Reporting CLI",
    "title": "Troubleshooting",
    "content": "To resolve MessageRejected: Email address is not verified, see Why am I getting a 400 “message rejected” error with the message “Email address is not verified” from Amazon SES? in the AWS Knowledge Center. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/creating-reports-with-the-reporting-cli/using-env/index.html#troubleshooting",
    "relUrl": "/analytics/opensearch-dashboard/creating-reports-with-the-reporting-cli/using-env/index.html#troubleshooting"
  },"115": {
    "doc": "Customizing Your Branding",
    "title": "Customizing your branding",
    "content": "INTRODUCED 1.2 . By default, OpenSearch Dashboards uses the OpenSearch logo, but if you want to use custom branding elements such as the favicon or main Dashboards logo, you can do so by editing opensearch_dashboards.yml or by including a custom opensearch_dashboards.yml file when you start your OpenSearch cluster. For example, if you’re using Docker to start your OpenSearch cluster, include the following lines in the opensearch-dashboards section of your docker-compose.yml file: . volumes: ./opensearch_dashboards.yml:/usr/share/opensearch-dashboards/config/opensearch_dashboards.yml . Doing so replaces the Docker image’s default opensearch_dashboards.yml with your custom opensearch_dashboards.yml file, so be sure to include your desired settings as well. For example, if you want to configure TLS for OpenSearch Dashboards, see Configure TLS for OpenSearch Dashboards. Re-launch OpenSearch Dashboards, and OpenSearch Dashboards now uses your custom elements. ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/customize-brand/index.html#customizing-your-branding",
    "relUrl": "/analytics/opensearch-dasboard/customize-brand/index.html#customizing-your-branding"
  },"116": {
    "doc": "Customizing Your Branding",
    "title": "Branding elements",
    "content": "The following elements in OpenSearch Dashboards are customizable: . | Setting | Corresponding branding element | . | logo | Header logo. See #1 in the image. | . | mark | OpenSearch Dashboards mark. See #2 in the image | . | loadingLogo | Loading logo used when OpenSearch Dashboards is starting. See #3 in the image. | . | faviconUrl | Website icon. Loads next to the application title. See #4 in the image. | . | applicationTitle | The application’s title. See #5 in the image. | . To consolidate navigation controls and reduce the space the header takes up on the page, see [Condensed header](https://opensearch.org/docs/latest/dashboards/branding/#condensed-header). To start using your own branding elements in OpenSearch Dashboards, first uncomment this section of opensearch_dashboards.yml: . # opensearchDashboards.branding: # logo: # defaultUrl: \"\" # darkModeUrl: \"\" # mark: # defaultUrl: \"\" # darkModeUrl: \"\" # loadingLogo: # defaultUrl: \"\" # darkModeUrl: \"\" # faviconUrl: \"\" # applicationTitle: \"\" . Add the URLs you want to use as branding elements to the appropriate setting. Valid image types are SVG, PNG, and GIF. Customization of dark mode Dashboards is also available, but you first must supply a valid link to defaultUrl, and then link to your preferred image with darkModeUrl. If you don’t provide a darkModeUrl link, then Dashboards uses the provided defaultUrl element for dark mode. You are not required to customize all branding elements, so if you wanted to, it’s perfectly valid to change just the logo or any other element. Leave unchanged elements as commented. The following example demonstrates how to use SVG files as logos but leaves the other elements as defaults. logo: defaultUrl: \"https://example.com/validUrl.svg\" darkModeUrl: \"https://example.com/validDarkModeUrl.svg\" # mark: # defaultUrl: \"\" # darkModeUrl: \"\" # loadingLogo: # defaultUrl: \"\" # darkModeUrl: \"\" # faviconUrl: \"\" applicationTitle: \"My custom application\" . We recommend linking to images that are hosted on a web server, but if you really want to use locally hosted images, save your images inside assets, and then configure opensearch_dashboards.yml to use the correct paths. You can access locally stored images through the ui/assets folder. The following example assumes the default port of 5601 that Dashboards uses and demonstrates how to link to locally stored images. logo: defaultUrl: \"https://localhost:5601/ui/assets/my-own-image.svg\" darkModeUrl: \"https://localhost:5601/ui/assets/dark-mode-my-own-image.svg\" mark: defaultUrl: \"https://localhost:5601/ui/assets/my-own-image2.svg\" darkModeUrl: \"https://localhost:5601/ui/assets/dark-mode-my-own-image2.svg\" # loadingLogo: # defaultUrl: \"\" # darkModeUrl: \"\" # faviconUrl: \"\" applicationTitle: \"My custom application\" . Condensed header . The condensed header view reduces the footprint of the header and frees up space on the page by combining navigational elements into a single header bar. The current default view remains close in appearance to the two-bar header offered in the previous version of Dashboards, with minor differences. To specify the condensed header, add the configuration property useExpandedHeader to the opensearch_dashboards.yml file and set the value to false, as the following example illustrates. # opensearchDashboards.branding: # logo: defaultUrl: \"https://example.com/sample.svg\" darkModeUrl: \"https://example.com/dark-mode-sample.svg\" # mark: # defaultUrl: \"\" # darkModeUrl: \"\" # loadingLogo: # defaultUrl: \"\" # darkModeUrl: \"\" # faviconUrl: \"\" applicationTitle: \"my custom application\" useExpandedHeader: false . In a future release, default behavior will become useExpandedHeader: false. If you want to retain the default view in subsequent releases, you can explicitly set the property to true in advance. Alternatively, you can also do this when upgrading. The condensed view header appears as in the example below. | Header element | Description | . | OpenSearch logo | See #1. Functions as the home button. | . | Header bar | See #2. A single header bar used for all navigation controls. | . The default view remains close to the traditional view, with minor changes. | Header element | Description | . | Home button | See #1. Returns to the home page and provides an indication when a page is loading. | . | Header label | See #2. The label also functions as a home button. | . | Navigation controls | See #3. Additional navigation controls on right-side insertion points. | . PRESERVING NAGIVATION ELEMENTS IN THE DEFAULT VIEW . You can continue using the top header bar in the default view for custom navigation links (such as menu items and plugins). Follow the steps below to keep these elements in the top header in the default view. Replace the property coreStart.chrome.navControls.registerRight(...) with coreStart.chrome.navControls.registerExpandedRight(...) and then replace the property coreStart.chrome.navControls.registerCenter(...) with coreStart.chrome.navControls.registerExpandedCenter(...) . Make sure the configuration property useExpandedHeader is explicitly set to true. ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/customize-brand/index.html#branding-elements",
    "relUrl": "/analytics/opensearch-dasboard/customize-brand/index.html#branding-elements"
  },"117": {
    "doc": "Customizing Your Branding",
    "title": "Sample configuration",
    "content": "The following configuration enables the security plugin and SSL within OpenSearch Dashboards and uses custom branding elements to replace the OpenSearch logo and application title. server.host: \"0\" opensearch.hosts: [\"https://localhost:9200\"] opensearch.ssl.verificationMode: none opensearch.username: \"kibanaserver\" opensearch.password: \"kibanaserver\" opensearch.requestHeadersAllowlist: [ authorization,securitytenant ] #server.ssl.enabled: true #server.ssl.certificate: /path/to/your/server/certificate #server.ssl.key: /path/to/your/server/key opensearch_security.multitenancy.enabled: true opensearch_security.multitenancy.tenants.preferred: [\"Private\", \"Global\"] opensearch_security.readonly_mode.roles: [\"kibana_read_only\"] # Use this setting if you are running opensearch-dashboards without https opensearch_security.cookie.secure: false opensearchDashboards.branding: logo: defaultUrl: \"https://example.com/sample.svg\" darkModeUrl: \"https://example.com/dark-mode-sample.svg\" # mark: # defaultUrl: \"\" # darkModeUrl: \"\" # loadingLogo: # defaultUrl: \"\" # darkModeUrl: \"\" # faviconUrl: \"\" applicationTitle: \"Just some testing\" . ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/customize-brand/index.html#sample-configuration",
    "relUrl": "/analytics/opensearch-dasboard/customize-brand/index.html#sample-configuration"
  },"118": {
    "doc": "Customizing Your Branding",
    "title": "Customizing Your Branding",
    "content": " ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/customize-brand/index.html",
    "relUrl": "/analytics/opensearch-dasboard/customize-brand/index.html"
  },"119": {
    "doc": "Adding multiple data sources",
    "title": "Adding multiple data sources.",
    "content": "The multiple data sources feature is an experimental feature released in OpenSearch 2.4. It can’t be used in a production environment. For updates on the feature’s progress or to leave feedback on improving the feature, see the [OpenSearch Forum discussion](https://forum.opensearch.org/t/feedback-experimental-feature-connect-to-external-data-sources/11144). You can add multiple data sources to a single dashboard. OpenSearch Dashboards allows you to dynamically manage data sources, create index patterns based on those data sources, and execute queries against a specific data source and then combine visualizations in one dashboard. In this tutorial we provide the steps for enabling the data_source setting in Dashboards; adding credentials, data source connections, and index patterns; and combining visualizations in a single dashboard. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/exploring-data/add-datasources/index.html#adding-multiple-data-sources",
    "relUrl": "/analytics/opensearch-dashboard/exploring-data/add-datasources/index.html#adding-multiple-data-sources"
  },"120": {
    "doc": "Adding multiple data sources",
    "title": "Try it: Exploring the multiple data sources feature in your local environment",
    "content": "This tutorial uses a preconfigured data source and index pattern, and you aren’t required to configure settings. However, you’ll need to enable the data_source setting in the configuration file before before getting started with exploring this feature. The multiple data sources feature is experimental and can’t be deployed into production. You can try it out with a sample data source and a sample index pattern. Before getting started, you must first edit the YAML configuration. The following section provides the steps for enabling the feature. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/exploring-data/add-datasources/index.html#try-it-exploring-the-multiple-data-sources-feature-in-your-local-environment",
    "relUrl": "/analytics/opensearch-dashboard/exploring-data/add-datasources/index.html#try-it-exploring-the-multiple-data-sources-feature-in-your-local-environment"
  },"121": {
    "doc": "Adding multiple data sources",
    "title": "Modifying the multiple data sources settings",
    "content": "Dashboards is configured in the cluster settings, and the multiple data sources feature is disabled by default. To enable it, you need to edit the configuration in opensearch_dashboards.yml and then restart the cluster. To enable the feature: . | Navigate to your Dashboards home directory; for example, in Docker, /usr/share/opensearch-dashboards. | Open your local copy of the Dashboards configuration file, opensearch_dashboards.yml. If you don’t have a copy, get one from GitHub: opensearch_dashboards.yml. | Set data_source.enabled: false to data_source.enabled: true and save the configuration. | Restart the Dashboards container. | Verify the feature configuration settings were created and configured properly by connecting to Dashboards through http://localhost:5601 and viewing the Stack Management console. Data Sources Experimental will appear in the sidebar. Alternatively, you can open on http://localhost:5601/app/management/opensearch-dashboards/dataSources. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/exploring-data/add-datasources/index.html#modifying-the-multiple-data-sources-settings",
    "relUrl": "/analytics/opensearch-dashboard/exploring-data/add-datasources/index.html#modifying-the-multiple-data-sources-settings"
  },"122": {
    "doc": "Adding multiple data sources",
    "title": "Creating a data source connection",
    "content": "A data source connection specifies the parameters needed to connect to a data source. These parameters form a connection string for the data source. In Dashboards, you can add new data source connections or edit existing connections. To create a new data source connection: . | Open Dashboards. If you’re not running the security plugin, go to http://localhost:5601. If you’re running the security plugin, go to https://localhost:5601 and log in with the username admin and password admin. | Under Management in the OpenSearch Dashboards main menu, choose Stack Management, _Data Sources Experimental, Data Sources, and then choose Create data source connection, as shown in the following image. | Add information to each field to configure Connection Details, Endpoint URL, and Authentication Method, as shown in the following image. For this tutorial, the Endpoint URL is http://localhost:5601/app/management/opensearch-dashboards/dataSources. | . In Connection Details, enter a title for the connection and the endpoint URL used to connect to the data source. A description of the connection is optional. For Authentication Method, first select the type of authentication: . | No authentication: No authentication is used to connect to the data source. | Username &amp; Password: A basic username and password are used to connect to the data source. | AWS SigV4: An AWS Signature Version 4 authenticating request is used to connect to the data source. AWS SigV4 requires an access key ID and a secret access key. First specify the _Region, and then enter the Access Key and Secret Key for authorization. For information on available Regions for AWS accounts, see Available Regions. For more on SigV4 authentication requests, see Authenticating Requests (AWS Signature Version 4). | . When you select the authentication method, the applicable fields appear for the selected method. Enter the required details. After you have entered the appropriate details in all of the required fields, the Test connection and Create data source connection buttons become active. You can choose Test connection to confirm that the connection is valid. | Choose Create data source connection to save your settings. The connection is created. The active window returns to the Data Sources main page, and the new connection appears in the list of data sources. You can also delete the data source connection from this page by selecting the check box to the left of the title and then choosing Delete 1 connection to the right of the search bar. Selecting multiple check boxes for multiple connections is also supported. | . Editing and updating a data source connection . To make changes to the data source connection, select a connection in the list on the Data Sources main page. The connection details window opens, as shown in the following image. To make changes to Connection Details, edit one or both of the Title and Description fields and choose Save changes in the lower-right corner of the screen. You can also cancel changes here. To change the Authentication Method, choose a different authentication method, enter your credentials if applicable, and then choose Save changes in the lower-right corner of the screen. The changes are saved. When Username &amp; Password is the selected authentication method, you can update the password by choosing Update stored password next to the Password field. In the pop-up window, enter a a new password in the first field and then enter it again in the second field to confirm. Choose Update stored password in the pop-up window. The new password is saved. Choose Test connection in the upper-right corner of the screen to confirm that the connection is valid. When AWS SigV4 is the selected authentication method, you can update the credentials by choosing Update stored AWS credential. In the pop-up window, enter a new access key in the first field and a new secret key in the second field. Choose Update stored AWS credential in the pop-up window. The new credentials are saved. Choose Test connection in the upper-right corner of the screen to confirm that the connection is valid. To delete the data source connection, choose the red trash can icon in the upper-right corner of the screen. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/exploring-data/add-datasources/index.html#creating-a-data-source-connection",
    "relUrl": "/analytics/opensearch-dashboard/exploring-data/add-datasources/index.html#creating-a-data-source-connection"
  },"123": {
    "doc": "Adding multiple data sources",
    "title": "Creating an index pattern",
    "content": "Index patterns allow you to access the OpenSearch data that you want to explore. An index pattern selects the data to use and allows you to define the field properties. Learn how to load your own data and create an index pattern following these steps. This tutorial uses the preconfigured index pattern opensearch_dashboards_sample_data_ecommerce Default. | In the Dashboards console, choose Index Patterns &gt; Create index pattern, as shown in the following image. | Choose Use external data source connection. | Start typing in the Search data sources field to search for the data source you created earlier and then select the data source and Next step, as shown in the following image. | Add an Index pattern name to define the index pattern and then choose Next step, as shown in the following image. | Select an option for the Time field and then choose Create index pattern, as shown in the following image. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/exploring-data/add-datasources/index.html#creating-an-index-pattern",
    "relUrl": "/analytics/opensearch-dashboard/exploring-data/add-datasources/index.html#creating-an-index-pattern"
  },"124": {
    "doc": "Adding multiple data sources",
    "title": "Searching data",
    "content": "Before you start searching for data, set up the time filter. The sample index pattern used for this tutorial contains time-based data. You can set a time filter that displays only the data within a specified time range, and you can choose the time filter to change the time range or select a specific time range in the histogram. Adjusting the time filter . To adjust the time filter: . | In the Dashboards console, choose Discover and confirm that the index pattern being used is opensearch_dashboards_sample_data_ecommerce. | Choose the calendar icon to change the time field. The default is Last 15 minutes. | Change the time field to Last 7 days and choose Refresh, as shown in the following image. | To set the start and end times, choose the bar next to the time filter. In the popup, select Absolute, Relative, or Now and then specify the required options, as shown in the following image. | . Selecting a time range from the histogram . To select a time range for the histogram, you can do one of the following: . | Select the bar that represents the time range you want to zoom in on. | Select the bar and drag to view a specific time range. You must start the selection with the cursor over the background of the chart (the cursor changes to a plus sign when you hover over a valid start point). | Select the dropdown and then select an interval. | . The following image shows a date histogram with an interval dropdown list. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/exploring-data/add-datasources/index.html#searching-data",
    "relUrl": "/analytics/opensearch-dashboard/exploring-data/add-datasources/index.html#searching-data"
  },"125": {
    "doc": "Adding multiple data sources",
    "title": "Creating data visualizations for a dashboard",
    "content": "Follow these steps to learn how to create data visualizations for a dashboard: . | In the Dashboards console, choose Visualize &gt; Create visualization. | Select the visualization type. For this tutorial, choose Line. | Select a source. For this tutorial, choose the index pattern opensearch_dashboards_sample_data_ecommerce. | Under Buckets, choose Add &gt; X-axis. | In the Aggregation field, choose Date Histogram and then choose Update. | Optional: Choose Save and add the file name. This tutorial uses preconfigured data visualizations, so you can’t save the file for this tutorial. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/exploring-data/add-datasources/index.html#creating-data-visualizations-for-a-dashboard",
    "relUrl": "/analytics/opensearch-dashboard/exploring-data/add-datasources/index.html#creating-data-visualizations-for-a-dashboard"
  },"126": {
    "doc": "Adding multiple data sources",
    "title": "Connecting visualizations in a single dashboard",
    "content": "Follow these steps to connect your visualizations in a single dashboard: . | In the Dashboards console, choose Dashboard &gt; Create dashboard. | Choose Add an existing and then select the data you want to add. | Choose Save and add the dashboard name in the Title field. This tutorial uses preconfigured dashboards, so you won’t be able to save your dashboard. | Click on the white space left of Add panels to view the visualizations in a single dashboard. | . Your dashboard might look like the one in the following image. You have now explored the data sources experimental feature. To provide feedback on how this feature can be improved ahead of its release for production use, comment in the OpenSearch forum. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/exploring-data/add-datasources/index.html#connecting-visualizations-in-a-single-dashboard",
    "relUrl": "/analytics/opensearch-dashboard/exploring-data/add-datasources/index.html#connecting-visualizations-in-a-single-dashboard"
  },"127": {
    "doc": "Adding multiple data sources",
    "title": "Understanding feature limitations",
    "content": "The following limitations apply to this experimental feature: . | The multiple data sources feature is supported for index-pattern-based visualizations only. | The visualization types Time Series Visual Builder (TSVB), Vega and Vega-Lite, and timeline are not supported. | External plugins, such as Gantt chart, and non-visualization plugins, such as the developer console, are not supported. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/exploring-data/add-datasources/index.html#understanding-feature-limitations",
    "relUrl": "/analytics/opensearch-dashboard/exploring-data/add-datasources/index.html#understanding-feature-limitations"
  },"128": {
    "doc": "Adding multiple data sources",
    "title": "Related topics",
    "content": ". | OpenSearch Forum | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/exploring-data/add-datasources/index.html#related-topics",
    "relUrl": "/analytics/opensearch-dashboard/exploring-data/add-datasources/index.html#related-topics"
  },"129": {
    "doc": "Adding multiple data sources",
    "title": "Adding multiple data sources",
    "content": " ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/exploring-data/add-datasources/index.html",
    "relUrl": "/analytics/opensearch-dashboard/exploring-data/add-datasources/index.html"
  },"130": {
    "doc": "Exploring Data",
    "title": "Exploring data",
    "content": "Discover in OpenSearch Dashboards helps you extract insights and get value out of data assets across your organization. Discover enables you to: . | Explore data. You can explore, customize, and filter data as well as search data using Dashboards Query Language (DQL). | Analyze data. You can analyze data, view individual documents, and create tables summarizing data contents. | Visualize data. You can display findings from your saved searches in a single dashboard that combines different data visualization types. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/exploring-data/index.html#exploring-data",
    "relUrl": "/analytics/opensearch-dashboard/exploring-data/index.html#exploring-data"
  },"131": {
    "doc": "Exploring Data",
    "title": "Try it: Exploring sample data with Discover",
    "content": "This tutorial shows you how to use Discover to analyze and understand a sample dataset. At the end of this tutorial, you should be ready to use Discover with your own data. Before starting this tutorial, make sure you’ve added the Sample flight data. See Quickstart guide for OpenSearch Dashboards for information about how to get started. Setting up data . Watch the following short video or start with the tutorial steps to learn how to set up a sample dataset in Discover. | Verify access to OpenSearch Dashboards by connecting to http://localhost:5601 from a browser. The default username and password are admin. | On the Home page, choose Discover in the navigation pane. | On the index pattern toolbar, select the opensearch_dashboards_sample_data_flights dataset. | On the time filter toolbar, choose the calendar icon and then change the time range to Last 7 days. | . Exploring the data fields . In the Discover panel, you’ll see a table that shows all the documents that match your search. The table includes a list of data fields that are available in the document table, as shown in the following image. Follow these steps to explore the data fields: . | View the list of Available fields. | Choose Cancelled to view the values (true and false). | Choose the plus (+) sign to add the field to the document table. The field will be automatically added to Selected fields and the document table. | Select FlightDelay from the Available fields list, and then choose the plus (+) sign to add the field to the document table. | Optional: Rearrange the table columns by selecting the table header and then choosing Move left or Move right. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/exploring-data/index.html#try-it-exploring-sample-data-with-discover",
    "relUrl": "/analytics/opensearch-dashboard/exploring-data/index.html#try-it-exploring-sample-data-with-discover"
  },"132": {
    "doc": "Exploring Data",
    "title": "Searching data",
    "content": "You can use the search toolbar or enter a DQL query in the DevTools console to search data in Dashboards, as shown in the following image. The search toolbar is best for basic queries, such as searching by a field name. DQL is best for complex queries, such as searching data using a term, string, Boolean, date, range, or nested query. Follow these steps to search data: . | In the search toolbar, enter the Boolean query. For example, enter FlightDelay:true AND FlightDelayMin &gt;= 60 to search the data for flights delayed by 60 minutes or more. | Choose Update. | Optional: Choose the arrow (&gt;) in a table row to expand the row and view the document table details. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/exploring-data/index.html#searching-data",
    "relUrl": "/analytics/opensearch-dashboard/exploring-data/index.html#searching-data"
  },"133": {
    "doc": "Exploring Data",
    "title": "Filtering data",
    "content": "Filters allow you to refine sets of documents to subsets of those documents. For example, you can filter data to include or exclude certain fields, as shown in the following image. Follow these steps to filter data: . | In the filter bar, choose Add filter. | Select options from the Field, Operator, and Value dropdown lists. For example, Cancelled, is, and true. | Choose Save. | To remove the filter, choose the close icon (x) next to the filter name. | Optional: Add more filters to further explore the data. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/exploring-data/index.html#filtering-data",
    "relUrl": "/analytics/opensearch-dashboard/exploring-data/index.html#filtering-data"
  },"134": {
    "doc": "Exploring Data",
    "title": "Analyzing data in the document table",
    "content": "You can view the document table fields to better understand the data and gather insights for more informed decision-making: . | Choose the arrow icon (&gt;) to expand a table row. | View the fields and details. | Switch between the Table and JSON tabs to view the different formats, as shown in the following image. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/exploring-data/index.html#analyzing-data-in-the-document-table",
    "relUrl": "/analytics/opensearch-dashboard/exploring-data/index.html#analyzing-data-in-the-document-table"
  },"135": {
    "doc": "Exploring Data",
    "title": "Saving the search",
    "content": "Saving a search saves the query text, filters, and current data view. To save your search to use it later, generate a report, or build visualizations and dashboards: . | Choose the save icon in the toolbar. | Give the search a title, and then choose Save. | Choose the save icon to access the saved search, as shown in the following image. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/exploring-data/index.html#saving-the-search",
    "relUrl": "/analytics/opensearch-dashboard/exploring-data/index.html#saving-the-search"
  },"136": {
    "doc": "Exploring Data",
    "title": "Visualizing the search",
    "content": "You can quickly visualize an aggregated field from Discover: . | From the Available fields list, select FlightDelayType and then choose Visualize, as shown in the following image. | . Dashboards creates a visualization for this field, which in this case is a basic bar chart, as shown in the following image. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/exploring-data/index.html#visualizing-the-search",
    "relUrl": "/analytics/opensearch-dashboard/exploring-data/index.html#visualizing-the-search"
  },"137": {
    "doc": "Exploring Data",
    "title": "Exploring Data",
    "content": " ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/exploring-data/index.html",
    "relUrl": "/analytics/opensearch-dashboard/exploring-data/index.html"
  },"138": {
    "doc": "Settig the time filter",
    "title": "Setting the time filter",
    "content": "You can change the time range to display dashboard data over minutes, hours, days, weeks, months, or years. The default time range is Last 15 minutes. You can change the time range at the dashboard level or under Stack Management &gt; Advanced Settings &gt; Time filter defaults. To change the time range at the dashboard level, perform the following steps: . | From an OpenSearch Dashboards application (Discover, Dashboard, or Visualize), select the time clock or calendar icon. | Select one of the time filter options, as shown in the following image: . | Quick select: Choose a time based on the last or next number of seconds, minutes, hours, days, or another time unit. | Commonly used: Choose a common time range like Today, Last 7 days, or Last 30 days. | Recently used date ranges: Select a previously used time range. | Refresh every: Set an automatic refresh period. | . | Choose Show dates to set start and end times, and then select anywhere inside the toolbar to access the time filter pop-up window, as shown in the following image. | Select Absolute, Relative, or Now and specify ranges. | Choose Update to apply changes, as shown in the following image. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/exploring-data/settime-filter/index.html#setting-the-time-filter",
    "relUrl": "/analytics/opensearch-dashboard/exploring-data/settime-filter/index.html#setting-the-time-filter"
  },"139": {
    "doc": "Settig the time filter",
    "title": "Settig the time filter",
    "content": " ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/exploring-data/settime-filter/index.html",
    "relUrl": "/analytics/opensearch-dashboard/exploring-data/settime-filter/index.html"
  },"140": {
    "doc": "Using Dashboards Query Language",
    "title": "Using Dashboards Query Language",
    "content": "Dashboards Query Language (DQL) is a simple text-based query language for filtering data in OpenSearch Dashboards. Similar to Query DSL, DQL uses an HTTP request body. For example, to display your site visitor data for a host in the United States, you would enter geo.dest:US in the search field, as shown in the following image. Before you can search data in Dashboards, you must index it. In OpenSearch, the basic unit of data is a JSON document. Within an index, OpenSearch identifies each document using a unique ID. To learn more about indexing in OpenSearch, see Index data. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/exploring-data/using-dql/index.html",
    "relUrl": "/analytics/opensearch-dashboard/exploring-data/using-dql/index.html"
  },"141": {
    "doc": "Using Dashboards Query Language",
    "title": "Searching with terms queries",
    "content": "The most basic query specifies the search term, for example: . host:www.example.com . To access an object’s nested field, list the complete path to the field separated by periods. For example, use the following path to retrieve the lat field in the coordinates object: . coordinates.lat:43.7102 . DQL supports leading and trailing wildcards, so you can search for any terms that match your pattern, for example: . host.keyword:*.example.com/* . To check whether a field exists or has any data, use a wildcard to see whether Dashboards returns any results,for example: . host.keyword:* . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/exploring-data/using-dql/index.html#searching-with-terms-queries",
    "relUrl": "/analytics/opensearch-dashboard/exploring-data/using-dql/index.html#searching-with-terms-queries"
  },"142": {
    "doc": "Using Dashboards Query Language",
    "title": "Searching with Boolean queries",
    "content": "To mix and match or combine multiple queries for more refined results, you can use the Boolean operators and, or, and not. DQL is not case sensitive, so AND and and are the same, for example: . host.keyword:www.example.com and response.keyword:200 . You also can use multiple Boolean operators in one query, for example: . geo.dest:US or response.keyword:200 and host.keyword:www.example.com . Remember that Boolean operators follow the logical precedence order of not, and, and or, so if you have an expression like the one in the preceding example, response.keyword:200 and host.keyword:www.example.com is evaluated first. To avoid confusion, use parentheses to dictate the order in which you want to evaluate operands. If you want to evaluate geo.dest:US or response.keyword:200 first, you can use an expression like the following: . (geo.dest:US or response.keyword:200) and host.keyword:www.example.com . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/exploring-data/using-dql/index.html#searching-with-boolean-queries",
    "relUrl": "/analytics/opensearch-dashboard/exploring-data/using-dql/index.html#searching-with-boolean-queries"
  },"143": {
    "doc": "Using Dashboards Query Language",
    "title": "Querying dates and ranges",
    "content": "DQL supports numeric inequalities, for example, bytes &gt;= 15 and memory &lt; 15. You can use the same method to find a date before or after the date specified in the query. &gt; indicates a search for a date after the specified date, and &lt; returns dates before the specified date, for example, @timestamp &gt; \"2020-12-14T09:35:33. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/exploring-data/using-dql/index.html#querying-dates-and-ranges",
    "relUrl": "/analytics/opensearch-dashboard/exploring-data/using-dql/index.html#querying-dates-and-ranges"
  },"144": {
    "doc": "Using Dashboards Query Language",
    "title": "Querying nested fields",
    "content": "Searching a document with nested fields requires you to specify the full path of the field to be retrieved. In the following example document, the superheroes field has nested objects: . { \"superheroes\":[ { \"hero-name\": \"Superman\", \"real-identity\": \"Clark Kent\", \"age\": 28 }, { \"hero-name\": \"Batman\", \"real-identity\": \"Bruce Wayne\", \"age\": 26 }, { \"hero-name\": \"Flash\", \"real-identity\": \"Barry Allen\", \"age\": 28 }, { \"hero-name\": \"Robin\", \"real-identity\": \"Dick Grayson\", \"age\": 15 } ] } . To retrieve documents that match a specific field using DQL, specify the field, for example: . superheroes: {hero-name: Superman} . To retrieve documents that match multiple fields, specify all the fields, for example: . superheroes: {hero-name: Superman} and superheroes: {hero-name: Batman} . You can combine multiple Boolean and range queries to create a more refined query, for example: . superheroes: {hero-name: Superman and age &lt; 50} . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/exploring-data/using-dql/index.html#querying-nested-fields",
    "relUrl": "/analytics/opensearch-dashboard/exploring-data/using-dql/index.html#querying-nested-fields"
  },"145": {
    "doc": "Using Dashboards Query Language",
    "title": "Querying doubly nested objects",
    "content": "If a document has doubly nested objects (objects nested inside other objects), retrieve a field value by specifying the full path to the field. In the following example document, the superheroes object is nested inside the justice-league object: . { \"justice-league\": [ { \"superheroes\":[ { \"hero-name\": \"Superman\", \"real-identity\": \"Clark Kent\", \"age\": 28 }, { \"hero-name\": \"Batman\", \"real-identity\": \"Bruce Wayne\", \"age\": 26 }, { \"hero-name\": \"Flash\", \"real-identity\": \"Barry Allen\", \"age\": 28 }, { \"hero-name\": \"Robin\", \"real-identity\": \"Dick Grayson\", \"age\": 15 } ] } ] } . The following image shows the query result using the example notation justice-league.superheroes: {hero-name:Superman}. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/exploring-data/using-dql/index.html#querying-doubly-nested-objects",
    "relUrl": "/analytics/opensearch-dashboard/exploring-data/using-dql/index.html#querying-doubly-nested-objects"
  },"146": {
    "doc": "Guide for opensearch Dashboard",
    "title": "Guide for OpenSearch Dashboard",
    "content": "This quickstart guide covers the core concepts that you need to understand to get started with OpenSearch Dashboards. You’ll learn how to: . | Add sample data. | Explore and inspect data. | Visualize data. Before you get started, make sure you’ve installed OpenSearch and OpenSearch Dashboards. For information on installation and configuration, see Install and configure OpenSearch and Install and configure OpenSearch Dashboards. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/opensearch-search-guide/index.html#guide-for-opensearch-dashboard",
    "relUrl": "/analytics/opensearch-dasboard/opensearch-search-guide/index.html#guide-for-opensearch-dashboard"
  },"147": {
    "doc": "Guide for opensearch Dashboard",
    "title": "Adding sample data",
    "content": "Sample datasets come with visualizations, dashboards, and other tools to help you explore Dashboards before you add your own data. To add sample data, perform the following steps: . | Verify access to OpenSearch Dashboards by connecting to http://localhost:5601 from a browser. The default username and password are admin. | On the OpenSearch Dashboards Home page, choose Add sample data. | Choose Add data to add the datasets, as shown in the following image. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/opensearch-search-guide/index.html#adding-sample-data",
    "relUrl": "/analytics/opensearch-dasboard/opensearch-search-guide/index.html#adding-sample-data"
  },"148": {
    "doc": "Guide for opensearch Dashboard",
    "title": "Exploring and inspecting data",
    "content": "In Discover, you can: . | Choose data to explore, set a time range for that data, search it using Dashboards Query Language (DQL), and filter the results. | Explore the data, view individual documents, and create tables summarizing the data’s contents. | Visualize your findings. | . Try it: Getting familiar with Discover . | On the OpenSearch Dashboards Home page, choose Discover. | Change the time filter to Last 7 days, as shown in the following image. | Search using the DQL query FlightDelay:true AND DestCountry: US AND FlightDelayMin &gt;= 60 and then choose Update. You should see results for US-bound flights delayed by 60 minutes or more, as shown in the following image. | To filter data, choose Add filter and then select an Available field. For example, select FlightDelayType, is, and Weather delay from the Field, Operator, and Value dropdown lists, as shown in the following image. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/opensearch-search-guide/index.html#exploring-and-inspecting-data",
    "relUrl": "/analytics/opensearch-dasboard/opensearch-search-guide/index.html#exploring-and-inspecting-data"
  },"149": {
    "doc": "Guide for opensearch Dashboard",
    "title": "Visualizing data",
    "content": "Raw data can be difficult to comprehend and use. Data visualizations help you prepare and present data in a visual form. In Dashboard you can: . | Display data in a single view. | Build dynamic dashboards. | Create and share reports. | Embed analytics to differentiate your applications. | . Try it: Getting familiar with Dashboard . | On the OpenSearch Dashboards Home page, choose Dashboard. | Choose [Flights] Global Flight Data in the Dashboards window, as shown in the following image. | To add panels to the dashboard, choose Edit and then Add from the toolbar. | In the Add panels window, choose the existing panel [Flights] Delay Buckets. You’ll see a pop-up window on the lower right confirming that you’ve added the panel. | Select x to close the Add panels window. | View the added panel [Flights] Delay Buckets, which is added as the last panel on the dashboard, as shown in the following image. | . Try it: Creating a visualization panel . Continuing with the preceding dashboard, you’ll create a bar chart comparing the number of canceled flights and delayed flights to delay type and then add the panel to the dashboard: . | Change the default time range from 24 hours to Last 7 days. | In the toolbar, choose Edit, then Create new. | Select VisBuilder in the New Visualizations window. | In the Data Source dropdown list, choose opensearch_dashboards_sample_data_flights. | Drag the fields Cancelled and FlightDelay to the y-axis column. | Drag the field FlightDelayType to the x-axis column. | Choose Save and name the visualization in the Title field. | Choose Save and return. The following bar chart is added as the last panel on the dashboard, as shown in the following image. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/opensearch-search-guide/index.html#visualizing-data",
    "relUrl": "/analytics/opensearch-dasboard/opensearch-search-guide/index.html#visualizing-data"
  },"150": {
    "doc": "Guide for opensearch Dashboard",
    "title": "Interacting with data",
    "content": "Interactive dashboards allow you analyze data in more depth and filter it in several ways. In Dashboards, you can interact directly with data on a dashboard by using dashboard-level filters. For example, continuing with the preceding dashboard, you can filter to show delays and cancellations for a specific airline. Try it: Interacting with the sample flight data . On the [Flights] Airline Carrier panel, choose OpenSearch-Air. The dashboard updates automatically. Choose Save to save the customized dashboard. Alternatively, you can apply filters using the dashboard toolbar: . | In the dashboard toolbar, choose Add filter. | From the Field, Operator, and Value dropdown lists, choose Carrier, is, and OpenSearch-Air, respectively, as shown in the following image. | Choose Save. The dashboard updates automatically, and the result is the dashboard shown in the following image. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/opensearch-search-guide/index.html#interacting-with-data",
    "relUrl": "/analytics/opensearch-dasboard/opensearch-search-guide/index.html#interacting-with-data"
  },"151": {
    "doc": "Guide for opensearch Dashboard",
    "title": "Next steps",
    "content": ". | Visualize data. To learn more about data visualizations in OpenSearch Dashboards, see Building data visualizations. | Create dashboards. To learn more about creating dashboards in OpenSearch Dashboards, see Creating dashboards. | Explore data. To learn more about exploring data in OpenSearch Dashboards, see Exploring data. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/opensearch-search-guide/index.html#next-steps",
    "relUrl": "/analytics/opensearch-dasboard/opensearch-search-guide/index.html#next-steps"
  },"152": {
    "doc": "Guide for opensearch Dashboard",
    "title": "Guide for opensearch Dashboard",
    "content": " ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/opensearch-search-guide/index.html",
    "relUrl": "/analytics/opensearch-dasboard/opensearch-search-guide/index.html"
  },"153": {
    "doc": "Data streams",
    "title": "Data streams",
    "content": "INTRODUCED 2.6 . In OpenSearch Dashboards, the Index Management application allows you to view and manage data streams as shown in the following image. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/index-management-in-dashboards/data-streams/index.html",
    "relUrl": "/analytics/opensearch-dashboard/index-management-in-dashboards/data-streams/index.html"
  },"154": {
    "doc": "Data streams",
    "title": "Viewing a data stream",
    "content": "To view a data stream and its health status, choose Data streams under Index management as shown in the following image. The following are the three data stream health statuses: . | Green: All primary and replica shards are assigned. | Yellow: At least one replica shard is not assigned. | Red: At least one primary shard is not assigned. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/index-management-in-dashboards/data-streams/index.html#viewing-a-data-stream",
    "relUrl": "/analytics/opensearch-dashboard/index-management-in-dashboards/data-streams/index.html#viewing-a-data-stream"
  },"155": {
    "doc": "Data streams",
    "title": "Creating a data stream",
    "content": "To create a data stream, perform the following steps: . | Under Index Management, choose Data streams. | Choose Create data stream. | Enter a name for the data stream under Data stream name. | Ensure that you have a matching index template. This will be populated under Matching index template, as shown in the following image. | The Inherited settings from template and Index alias sections are read-only, and display the backing indexes that are contained in the data stream. | The number of primary shards, number of replicas, and the refresh interval are inherited from the template, as shown in the following image. | Choose Create data stream. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/index-management-in-dashboards/data-streams/index.html#creating-a-data-stream",
    "relUrl": "/analytics/opensearch-dashboard/index-management-in-dashboards/data-streams/index.html#creating-a-data-stream"
  },"156": {
    "doc": "Data streams",
    "title": "Deleting a data stream",
    "content": "To delete a data stream, perform the following steps: . | Under Index Management, choose Data streams. | Select the data stream that you want to delete. | Choose Actions, and then choose Delete. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/index-management-in-dashboards/data-streams/index.html#deleting-a-data-stream",
    "relUrl": "/analytics/opensearch-dashboard/index-management-in-dashboards/data-streams/index.html#deleting-a-data-stream"
  },"157": {
    "doc": "Data streams",
    "title": "Rolling over a data stream",
    "content": "To perform a rollover operation on a data stream, perform the following steps: . | Under Index Management, choose Data streams. | Choose Actions, and then choose Roll over, as shown in the following image. | Under Configure source, select the source data stream on which you want to perform the rollover operation. | Choose Roll over, as shown in the following image. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/index-management-in-dashboards/data-streams/index.html#rolling-over-a-data-stream",
    "relUrl": "/analytics/opensearch-dashboard/index-management-in-dashboards/data-streams/index.html#rolling-over-a-data-stream"
  },"158": {
    "doc": "Data streams",
    "title": "Force merging data streams",
    "content": "To perform a force merge operation on two or more indexes, perform the following steps: . | Under Index Management, choose Data streams. | Select the data streams on which you want to perform the force merge operation. | Choose Actions, and then choose Force merge. | Under Configure source index, specify the data streams you want to force merge. | Optionally, under Advanced settings you can to choose to Flush indices or Only expunge delete and then specify the Max number of segments to merge to as shown in the following image. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/index-management-in-dashboards/data-streams/index.html#force-merging-data-streams",
    "relUrl": "/analytics/opensearch-dashboard/index-management-in-dashboards/data-streams/index.html#force-merging-data-streams"
  },"159": {
    "doc": "Force merge",
    "title": "Force merge",
    "content": "INTRODUCED 2.6 . OpenSearch Dashboards allows you to perform a force merge operation on two or more indexes with Index Management. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/index-management-in-dashboards/force-merge/index.html",
    "relUrl": "/analytics/opensearch-dashboard/index-management-in-dashboards/force-merge/index.html"
  },"160": {
    "doc": "Force merge",
    "title": "Force merging indexes",
    "content": "To perform a force merge operation on two or more indexes, perform the following steps: . | Under Index Management, choose Indices. | Select the indexes you want to force merge. | Choose Actions, and then choose Force merge, as shown in the following image. | Under Configure source index, specify the indexes you want to force merge. | Optionally, under Advanced settings you can to choose to Flush indices or Only expunge delete and then specify the Max number of segments to merge to as shown in the following image. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/index-management-in-dashboards/force-merge/index.html#force-merging-indexes",
    "relUrl": "/analytics/opensearch-dashboard/index-management-in-dashboards/force-merge/index.html#force-merging-indexes"
  },"161": {
    "doc": "Force merge",
    "title": "Force merging data streams",
    "content": "To perform a force merge operation on two or more indexes, perform the following steps: . | Under Index Management, choose Data streams. | Select the data streams you want to force merge. | Choose Actions, and then choose Force merge. | Under Configure source index, specify the data streams you want to force merge. | Optionally, under Advanced settings you can to choose to Flush indices or Only expunge delete and then specify the Max number of segments to merge to as shown in the following image. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/index-management-in-dashboards/force-merge/index.html#force-merging-data-streams",
    "relUrl": "/analytics/opensearch-dashboard/index-management-in-dashboards/force-merge/index.html#force-merging-data-streams"
  },"162": {
    "doc": "Index management in Dashboards",
    "title": "Index management in Dashboards",
    "content": "INTRODUCED 2.5 . Previously, users relied on REST APIs or YAML configurations for basic administrative operations and interventions. This release takes the first step toward a unified administration panel in OpenSearch Dashboards with the launch of several index management UI enhancements. The new interface provides a more user-friendly way to run common indexing and data stream operations. Now you can perform create, read, update, and delete (CRUD) and mapping operations for indexes, index templates, and aliases through the UI. Additionally, you can open, close, reindex, shrink, and split indexes. The UI runs index status and data validation before submitting requests and lets you compare changes with previously saved settings before making updates. . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/index-management-in-dashboards/index.html",
    "relUrl": "/analytics/opensearch-dashboard/index-management-in-dashboards/index.html"
  },"163": {
    "doc": "Index management in Dashboards",
    "title": "Related articles",
    "content": ". | Indexes | Data streams | Force merge | Rollover | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/index-management-in-dashboards/index.html#related-articles",
    "relUrl": "/analytics/opensearch-dashboard/index-management-in-dashboards/index.html#related-articles"
  },"164": {
    "doc": "Indexes",
    "title": "Indexes",
    "content": "INTRODUCED 2.5 . In the Index Management section, you can perform the operations available in the Index API. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/index-management-in-dashboards/indexes/index.html",
    "relUrl": "/analytics/opensearch-dashboard/index-management-in-dashboards/indexes/index.html"
  },"165": {
    "doc": "Indexes",
    "title": "Index policies",
    "content": "Policies are configurations that define the possible states of an index, the actions to perform when an index enters a given state, and the conditions that must be met to transition between states: . | States: The possible states of an index, including the default state for new indexes. For example, you might name your states hot, warm, or delete. For more information, see States. | Actions: Any actions that you want the plugin to take when an index enters a given state, such as performing a rollover. For more information, see Actions. | Transitions: The conditions that must be met for an index to move into a new state. For example, if an index is more than 8 weeks old, you might want to move it to the delete state. For more information, see Transitions. | . You can also upload a JSON document to specify an index policy. You have complete flexibility in designing your policies. You can create any state, transition to any other state, and specify any number of actions in each state. To attach policies to indexes, perform the following steps: . | Under Index Management, choose Index policies. | Select the index or indexes to which you want to attach your policy. | Choose the Apply policy button. | From the Policy ID menu, select the policy that you created. View the preview of your policy. | (Optional): Specify a rollover alias if your policy includes a rollover operation. Make sure that the alias already exists. For more information about the rollover operation, see rollover. | Choose the Apply button. | . After you attach a policy to an index, Index State Management (ISM) creates a job that runs every 5 minutes by default to perform policy actions, check conditions, and transition the index into different states. To change the default time interval for this job, see Settings. Policy jobs don’t run if the cluster state is red. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/index-management-in-dashboards/indexes/index.html#index-policies",
    "relUrl": "/analytics/opensearch-dashboard/index-management-in-dashboards/indexes/index.html#index-policies"
  },"166": {
    "doc": "Indexes",
    "title": "Managed indexes",
    "content": "To attach policies to indexes, perform the following steps: . | Under Index Management, choose Manage Indices. | Select the index or indexes to which you want to attach your policy. | Choose the Change policy button. | Choose the Apply policy button. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/index-management-in-dashboards/indexes/index.html#managed-indexes",
    "relUrl": "/analytics/opensearch-dashboard/index-management-in-dashboards/indexes/index.html#managed-indexes"
  },"167": {
    "doc": "Indexes",
    "title": "Indexes",
    "content": "The Indices section displays a list of indexes in your OpenSearch cluster. For each index, you can see its health status (green, yellow, or red), policy (if the index is managed by a policy), status, total size, primary sizes, total documents, deleted documents, primaries, and replicas. The following are the three index health statuses: . | Green: All primary and replica shards are assigned. | Yellow: At least one replica shard is not assigned. | Red: At least one primary shard is not assigned. | . Creating an index . While you can create an index by using a document as a base, you can also create an empty index for later use. To create an index, select the Create Index button located under the Indices section of Index Management. Then define the index by setting the following parameters: . | Index name | Number of primary shards | Number of replicas | Refresh interval | . You can also add fields and objects using either the visual editor or the JSON editor. The Advanced settings allow you to upload a JSON configuration. Applying a policy . If you analyze time-series data, you likely want to prioritize new data over old data. You might periodically perform certain operations on older indexes, such as reducing replica count or deleting them. ISM is a plugin that lets you automate these periodic administrative operations by triggering them based on changes in the index age, index size, or number of documents. You can define policies that automatically handle index rollovers or deletions to fit your use case. For example, you can define a policy that moves your index into a read_only state after 30 days and then deletes it after a set period of 90 days. You can also set up the policy to send you a notification message when the index is deleted. You might want to perform an index rollover after a certain amount of time or run a force_merge operation on an index during off-peak hours to improve search performance during peak hours. To apply a policy, select the index to which you want to apply the policy from the Indices list under Index Management. Then select the Actions button and select Apply policy from the dropdown list as shown in the following image. Closing an index . The close index operation closes an index. Once an index is closed, you cannot add data to it or search for any data within the index. To close an index, select the index you want to close from the Indices list under Index Management. Then select the Actions button and select Close from the dropdown list. Opening an index . The open index operation opens a closed index, letting you add data to it or search for data within the index. To open an index, select the index you want to open from the Indices list under Index Management. Then select the Actions button and select Open from the dropdown list. Reindexing an index . The reindex operation lets you copy all of your data or a subset of data from a source index into a destination index. To reindex an index, select the index from the Indices list under Index Management. Then select the Actions button and select Reindex from the dropdown list as shown in the following image. Shrinking an index . The shrink index operation copies all of the data in an existing index into a new index with fewer primary shards. To shrink an index, select the index you want to shrink from the Indices list under Index Management. Then choose the Actions button and choose Shrink from the dropdown list as shown in the following image. Splitting an index . The split index operation splits an existing read-only index into a new index, splitting each primary shard into a number of primary shards in the new index. To split an index, select the index you want to split from the Indices list under Index Management. Then choose the Actions button and choose Split from the dropdown list as shown in the following image. Deleting an index . If you no longer need an index, you can use the delete index operation to delete it. To delete an index, select the index you want to delete from the Indices list under Index Management. Then select the Actions button and select Delete from the dropdown list. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/index-management-in-dashboards/indexes/index.html",
    "relUrl": "/analytics/opensearch-dashboard/index-management-in-dashboards/indexes/index.html"
  },"168": {
    "doc": "Indexes",
    "title": "Templates",
    "content": "Index templates let you initialize new indexes with predefined mappings and settings. For example, if you continuously index log data, you can define an index template so that all of the indexes have the same number of shards and replicas as shown in the following image. Creating a template . To create a template, choose the Create template button on the Templates page under Index Management. Next, define the template: . | Enter the template name. | Select the template type. | Specify any index patterns you would like to use. | Set the priority of the template. | Select an index alias. | Set the number of primary shards. | Set the number of replicas. | Set the refresh intervals. | Add fields and objects for your index mapping using either the visual editor or the JSON editor. | Under Advanced Settings you can specify advanced index settings with a comma-delimited list as shown in the following image. | . Editing a template . To edit a template, select the template you want to edit from the list of templates. Next, select the Actions dropdown list and select the Edit option. Deleting a template . To delete a template, select the template you want to delete from the list of templates. Next, select the Actions dropdown list and select the Delete option. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/index-management-in-dashboards/indexes/index.html#templates",
    "relUrl": "/analytics/opensearch-dashboard/index-management-in-dashboards/indexes/index.html#templates"
  },"169": {
    "doc": "Indexes",
    "title": "Aliases",
    "content": "An alias is a virtual index name that can point to one or more indexes. If your data is spread across multiple indexes, rather than keeping track of which indexes to query, you can create an alias and query it instead as shown in the following image. To create an alias, perform the following steps: . | Choose the Create Alias button on the Aliases page under Index Management. | Specify the alias name. | Enter the index, or index patterns, to be included in the alias. | Choose Create alias as shown in the following image. | . To edit an alias, perform the following steps: . | Select the alias you want to edit. | Choose the Actions button. | Choose Edit from the dropdown list. | . To delete an alias, perform the following steps: . | Select the alias you want to edit. | Choose the Actions button. | Choose Delete from the dropdown list. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/index-management-in-dashboards/indexes/index.html#aliases",
    "relUrl": "/analytics/opensearch-dashboard/index-management-in-dashboards/indexes/index.html#aliases"
  },"170": {
    "doc": "Indexes",
    "title": "Rollup jobs",
    "content": "The Rollup Jobs section under Index Management allows you to create or update index rollup jobs. To create a rollup job, perform the following steps: . | Choose the Create rollup job button on the Rollup Jobs page under Index Management. | Set the name, source index, and target index. | Choose Next. | Set the timestamp field and interval type. | Optionally, set additional aggregations and metrics. | Choose Next. | Under Schedule, check or uncheck Enable job by default. | Set the Continuous, Execution frequency, Rollup interval, and Pages per execution settings. | Additionally, you can set an execution delay. | Choose Next. | Review the settings for the rollup job and choose Create. | . You can also enable and disable rollup jobs by choosing the corresponding buttons on the Rollup Jobs page. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/index-management-in-dashboards/indexes/index.html#rollup-jobs",
    "relUrl": "/analytics/opensearch-dashboard/index-management-in-dashboards/indexes/index.html#rollup-jobs"
  },"171": {
    "doc": "Indexes",
    "title": "Transform jobs",
    "content": "You can create, start, stop, and complete operations with transform jobs. To create a transform job, perform the following steps: . | Choose the Create transform job button on the Transform Jobs page under Index Management. | Set the name, source index, and target index. | Choose Next. | Select the fields to transform. From the table, select a field you want to transform by choosing + next to the field name. | Choose Next. | Check or uncheck Job enabled by default. | Set the transform execution interval and whether the schedule is continuous. | Optionally, set pages per execution under the Advanced dropdown list. | Choose Next. | Review the settings for the rollup job and choose Create. | . You can also enable and disable rollup jobs by choosing the corresponding buttons on the Transform Jobs page. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/index-management-in-dashboards/indexes/index.html#transform-jobs",
    "relUrl": "/analytics/opensearch-dashboard/index-management-in-dashboards/indexes/index.html#transform-jobs"
  },"172": {
    "doc": "Indexes",
    "title": "Long-running operation status check",
    "content": "Certain index operations take additional time to complete (usually more than 30 seconds, but up to tens of minutes or hours). This is tracked in the index status column on the Indices page. You can check the status of the reindex, shrink, and split operations because they are one-time, non-recursive operations. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/index-management-in-dashboards/indexes/index.html#long-running-operation-status-check",
    "relUrl": "/analytics/opensearch-dashboard/index-management-in-dashboards/indexes/index.html#long-running-operation-status-check"
  },"173": {
    "doc": "Indexes",
    "title": "Security integration",
    "content": "Permission control is managed with existing permissions or action groups that are enforced at the API level. There is currently no UI-level permission control. Users with permission to access the ISM plugin are able to view new pages. They can also make changes if they have permission to run the related APIs. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/index-management-in-dashboards/indexes/index.html#security-integration",
    "relUrl": "/analytics/opensearch-dashboard/index-management-in-dashboards/indexes/index.html#security-integration"
  },"174": {
    "doc": "Indexes",
    "title": "Error handling",
    "content": "Similar to API calls, if the operation fails immediately, you will be notified with an error message. However, if it is a long-running operation, you will be notified of the failure at the time of failure, or you can check the index status on the Indices page. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/index-management-in-dashboards/indexes/index.html#error-handling",
    "relUrl": "/analytics/opensearch-dashboard/index-management-in-dashboards/indexes/index.html#error-handling"
  },"175": {
    "doc": "Rollover",
    "title": "Rollover",
    "content": "INTRODUCED 2.6 . OpenSearch Dashboards allows you to perform an index rollover operation with Index Management. ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/index-management-in-dashboards/rollover/index.html",
    "relUrl": "/analytics/opensearch-dashboard/index-management-in-dashboards/rollover/index.html"
  },"176": {
    "doc": "Rollover",
    "title": "Data streams",
    "content": "To perform a rollover operation on a data stream, perform the following steps: . | Under Index Management, choose Data streams. | Choose Actions, and then choose Roll over, as shown in the following image. | Under Configure source, select the source data stream on which you want to perform the rollover operation. | Choose Roll over, as shown in the following image. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/index-management-in-dashboards/rollover/index.html#data-streams",
    "relUrl": "/analytics/opensearch-dashboard/index-management-in-dashboards/rollover/index.html#data-streams"
  },"177": {
    "doc": "Rollover",
    "title": "Aliases",
    "content": "To perform a rollover operation on an alias, perform the following steps: . | Under Index Management, choose Aliases. | Choose Actions, and then choose Roll over, as shown in the following image. | Under Configure source, select the source alias on which you want to perform the rollover operation. | If the alias does not contain a write index, you are prompted to assign a write index, as shown in the following image. | Under Configure a new rollover index and on the Define index pane, specify an index name and an optional index alias. | Under Index settings, specify the number of primary shards, the number of replicas, and the refresh interval, as shown in the following image. | Choose Roll over. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dashboard/index-management-in-dashboards/rollover/index.html#aliases",
    "relUrl": "/analytics/opensearch-dashboard/index-management-in-dashboards/rollover/index.html#aliases"
  },"178": {
    "doc": "Opensearch Dashboard",
    "title": "Overview",
    "content": " ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/index.html#overview",
    "relUrl": "/analytics/opensearch-dasboard/index.html#overview"
  },"179": {
    "doc": "Opensearch Dashboard",
    "title": "Opensearch Dashboard",
    "content": " ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/index.html",
    "relUrl": "/analytics/opensearch-dasboard/index.html"
  },"180": {
    "doc": "Managing search telemetry settings",
    "title": "Managing search telemetry settings",
    "content": "You can use search telemetry to analyze search request performance by success or failure in OpenSearch Dashboards. OpenSearch stores telemetry data in the .kibana_1 index. Because there are thousands of concurrent search requests from OpenSearch Dashboards, the heavy traffic can cause significant load in an OpenSearch cluster. OpenSearch clusters perform better with search telemetry turned off. ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/manage-search/index.html",
    "relUrl": "/analytics/opensearch-dasboard/manage-search/index.html"
  },"181": {
    "doc": "Managing search telemetry settings",
    "title": "Turning on search telemetry",
    "content": "Search usage telemetry is turned off by default. To turn it on, you need to set data.search.usageTelemetry.enabled to true in the opensearch_dashboards.yml file. You can find the OpenSearch Dashboards YAML file in the opensearch-project repository on GitHub. Turning on telemetry in the opensearch_dashboards.yml file overrides the default search telemetry setting of false in the Data plugin configuration file. Turning search telemetry on or off . The following table shows the data.search.usageTelemetry.enabled values you can set in opensearch_dashboards.yml to turn search telemetry on or off. | OpenSearch Dashboards YAML value | Search telemetry status: on or off | . | true | On | . | false | Off | . | none | Off | . SAMPLE OPENSEARCH_DASHBOARDS.YML WITH TELEMETRY ENABLED . This OpenSearch Dashboards YAML file excerpt shows the telemetry setting set to true to turn on search telemetry: . # Set the value of this setting to false to suppress # search usage telemetry to reduce the load of the OpenSearch cluster. data.search.usageTelemetry.enabled: true . ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/manage-search/index.html#turning-on-search-telemetry",
    "relUrl": "/analytics/opensearch-dasboard/manage-search/index.html#turning-on-search-telemetry"
  },"182": {
    "doc": "Running queries in the console",
    "title": "Running queries in the console",
    "content": "You can use the OpenSearch Dev Tools Console to send queries to OpenSearch. ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/run-queries/index.html",
    "relUrl": "/analytics/opensearch-dasboard/run-queries/index.html"
  },"183": {
    "doc": "Running queries in the console",
    "title": "Navigating to the console",
    "content": "To open the console, select Dev Tools on the main OpenSearch Dashboards page: . You can open the console from any other page by navigating to the main menu and selecting Management &gt; Dev Tools. ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/run-queries/index.html#navigating-to-the-console",
    "relUrl": "/analytics/opensearch-dasboard/run-queries/index.html#navigating-to-the-console"
  },"184": {
    "doc": "Running queries in the console",
    "title": "Writing queries",
    "content": "Write your queries in the editor pane on the left side of the console: . You can collapse and expand parts of your query by selecting the small triangles next to the line numbers. To learn more about writing queries in OpenSearch domain-specific language (DSL), see Query DSL. Comments . Use # at the beginning of a line to write single-line comments. Autocomplete . OpenSearch provides autocomplete suggestions for fields, indexes and their aliases, and templates. To configure autocomplete preferences, update them in Console Settings. ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/run-queries/index.html#writing-queries",
    "relUrl": "/analytics/opensearch-dasboard/run-queries/index.html#writing-queries"
  },"185": {
    "doc": "Running queries in the console",
    "title": "Sending the request",
    "content": "To send a query to OpenSearch, select the query by placing the cursor anywhere in the query text. Then choose the triangle on the top right of the request or press Ctrl/Cmd+Enter: . OpenSearch displays the response in the response pane on the right side of the console: . ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/run-queries/index.html#sending-the-request",
    "relUrl": "/analytics/opensearch-dasboard/run-queries/index.html#sending-the-request"
  },"186": {
    "doc": "Running queries in the console",
    "title": "Working in the cURL and console formats",
    "content": "The console uses an easier syntax to format REST requests than the curl command. For example, the following curl command runs a search query: . curl -XGET http://localhost:9200/shakespeare/_search?pretty -H 'Content-Type: application/json' -d' { \"query\": { \"match\": { \"text_entry\": \"To be, or not to be\" } } }' . The same query has a simpler syntax in the console format: . GET shakespeare/_search { \"query\": { \"match\": { \"text_entry\": \"To be, or not to be\" } } } . If you paste a curl command directly into the console, the command is automatically converted into the format the console uses. To import a query in cURL format, select the query, then select the wrench icon and choose Copy as cURL: . ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/run-queries/index.html#working-in-the-curl-and-console-formats",
    "relUrl": "/analytics/opensearch-dasboard/run-queries/index.html#working-in-the-curl-and-console-formats"
  },"187": {
    "doc": "Running queries in the console",
    "title": "Viewing documentation",
    "content": "To view the OpenSearch documentation, select the wrench icon, and choose Open documentation. ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/run-queries/index.html#viewing-documentation",
    "relUrl": "/analytics/opensearch-dasboard/run-queries/index.html#viewing-documentation"
  },"188": {
    "doc": "Running queries in the console",
    "title": "Auto indenting",
    "content": "To use auto indent, select the queries that you want to format, select the wrench icon, and choose Auto indent. Auto indenting a collapsed query expands it. Auto indenting a well-formatted query puts the request body on a single line. This is useful for working with bulk APIs. ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/run-queries/index.html#auto-indenting",
    "relUrl": "/analytics/opensearch-dasboard/run-queries/index.html#auto-indenting"
  },"189": {
    "doc": "Running queries in the console",
    "title": "Viewing your request history",
    "content": "You can view up to the 500 most recent requests that OpenSearch ran successfully. To view request history, select History from the top menu. If you select the request you want to view from the left pane, the query is shown in the right pane. To copy the query into the editor pane, select the query text and then select Apply. To clear the history, select Clear. ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/run-queries/index.html#viewing-your-request-history",
    "relUrl": "/analytics/opensearch-dasboard/run-queries/index.html#viewing-your-request-history"
  },"190": {
    "doc": "Running queries in the console",
    "title": "Updating the console settings",
    "content": "To update your preferences, select Settings from the top menu: . ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/run-queries/index.html#updating-the-console-settings",
    "relUrl": "/analytics/opensearch-dasboard/run-queries/index.html#updating-the-console-settings"
  },"191": {
    "doc": "Running queries in the console",
    "title": "Using keyboard shortcuts",
    "content": "To view all available keyboard shortcuts, select Help from the top menu. ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/run-queries/index.html#using-keyboard-shortcuts",
    "relUrl": "/analytics/opensearch-dasboard/run-queries/index.html#using-keyboard-shortcuts"
  },"192": {
    "doc": "Snapshot management",
    "title": "Snapshot management",
    "content": "You can set up Snapshot Management (SM) in OpenSearch Dashboards. Snapshots are backups of a cluster’s indexes and state. The state includes cluster settings, node information, index metadata (mappings, settings, templates), and shard allocation. Snapshots have two main uses: . | Recovering from failure . For example, if cluster health goes red, you might restore the red indexes from a snapshot. | Migrating from one cluster to another . For example, if you’re moving from a proof of concept to a production cluster, you might take a snapshot of the former and restore it on the latter. | . You can take and restore snapshots using snapshot management in OpenSearch Dashboards. If you need to automate snapshots creation, you can use a snapshot policy. ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/snapshot-management/index.html",
    "relUrl": "/analytics/opensearch-dasboard/snapshot-management/index.html"
  },"193": {
    "doc": "Snapshot management",
    "title": "Creating a repository",
    "content": "Before you create an SM policy, you need to set up a repository for snapshots. | On the top menu bar, go to OpenSearch Plugins &gt; Snapshot Management. | In the left panel, under Snapshot Management, select Repositories. | Choose the Create Repository button. | Enter the repository name, type, and location. | (Optional) Select Advanced Settings and enter additional settings for this repository as a JSON object. Example: . { \"chunk_size\": null, \"compress\": false, \"max_restore_bytes_per_sec\": \"40m\", \"max_snapshot_bytes_per_sec\": \"40m\", \"readonly\": false } . | Choose the Add button. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/snapshot-management/index.html#creating-a-repository",
    "relUrl": "/analytics/opensearch-dasboard/snapshot-management/index.html#creating-a-repository"
  },"194": {
    "doc": "Snapshot management",
    "title": "Deleting a repository",
    "content": "To delete a snapshot repository configuration, select the repository from the Repositories list and then choose the Delete button. ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/snapshot-management/index.html#deleting-a-repository",
    "relUrl": "/analytics/opensearch-dasboard/snapshot-management/index.html#deleting-a-repository"
  },"195": {
    "doc": "Snapshot management",
    "title": "Creating an SM policy",
    "content": "Create an SM policy to set up automatic snapshots. An SM policy defines an automated snapshot creation schedule and an optional automated deletion schedule. | On the top menu bar, go to OpenSearch Plugins &gt; Snapshot Management. | In the left panel, under Snapshot Management, select Snapshot Policies. | Select the Create Policy button. | In the Policy settings section: . | Enter the policy name. | (Optional) Enter the policy description. | . | In the Source and destination section: . | Select or enter source indexes either as a list or as an index pattern. | Select a repository for snapshots. To create a new repository, select the Create button. | . | In the Snapshot schedule section: . | Select the desired snapshot frequency or enter a custom cron expression for snapshot frequency. | Select the start time and time zone. | . | In the Retention period section: . | Choose to retain all snapshots or specify retention conditions (the maximum age of retained snapshots). | (Optional) In Additional settings, select the minimum and maximum number of retained snapshots, deletion frequency, and deletion start time. | . | In the Notifications section, select the snapshot activities you want to be notified about. | (Optional) In the Advanced settings section, select the desired options: . | Include cluster state in snapshots | Ignore unavailable indices | Allow partial snapshots | . | Select the Create button. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/snapshot-management/index.html#creating-an-sm-policy",
    "relUrl": "/analytics/opensearch-dasboard/snapshot-management/index.html#creating-an-sm-policy"
  },"196": {
    "doc": "Snapshot management",
    "title": "View, edit, or delete an SM policy",
    "content": "You can view, edit, or delete an SM policy on the policy details page. | On the top menu bar, go to OpenSearch Plugins &gt; Snapshot Management. | In the left panel, under Snapshot Management, select Snapshot Policies. | Click on the Policy name of the policy you want to view, edit, or delete. The policy settings, snapshot schedule, snapshot retention period, notifications, and last creation and deletion are displayed in the policy details page. If a snapshot creation or deletion fails, you can view information about the failure in the Last Creation/Deletion section. To view the failure message, click on the cause in the Info column. | To edit or delete the SM policy, select the Edit or Delete button. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/snapshot-management/index.html#view-edit-or-delete-an-sm-policy",
    "relUrl": "/analytics/opensearch-dasboard/snapshot-management/index.html#view-edit-or-delete-an-sm-policy"
  },"197": {
    "doc": "Snapshot management",
    "title": "Enable, disable, or delete SM policies",
    "content": ". | On the top menu bar, go to OpenSearch Plugins &gt; Snapshot Management. | In the left panel, under Snapshot Management, select Snapshot Policies. | Select one or more policies in the list. | To enable or disable selected SM policies, select the Enable or Disable button. To delete selected SM policies, in the Actions list, select the Delete option. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/snapshot-management/index.html#enable-disable-or-delete-sm-policies",
    "relUrl": "/analytics/opensearch-dasboard/snapshot-management/index.html#enable-disable-or-delete-sm-policies"
  },"198": {
    "doc": "Snapshot management",
    "title": "View snapshots",
    "content": ". | On the top menu bar, go to OpenSearch Plugins &gt; Snapshot Management. | In the left panel, under Snapshot Management, select Snapshots. All automatically or manually taken snapshots appear in the list. | To view a snapshot, click on its Name. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/snapshot-management/index.html#view-snapshots",
    "relUrl": "/analytics/opensearch-dasboard/snapshot-management/index.html#view-snapshots"
  },"199": {
    "doc": "Snapshot management",
    "title": "Take a snapshot",
    "content": "Use the steps below to take a snapshot manually: . | On the top menu bar, go to OpenSearch Plugins &gt; Snapshot Management. | In the left panel, under Snapshot Management, select Snapshots. | Select the Take snapshot button. | Enter the snapshot name. | Select or enter source indexes either as a list or as an index pattern. | Select a repository for the snapshot. | (Optional) In the Advanced options section, select the desired options: . | Include cluster state in snapshots | Ignore unavailable indices | Allow partial snapshots | . | Choose the Add button. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/snapshot-management/index.html#take-a-snapshot",
    "relUrl": "/analytics/opensearch-dasboard/snapshot-management/index.html#take-a-snapshot"
  },"200": {
    "doc": "Snapshot management",
    "title": "Deleting a snapshot",
    "content": "The Delete button deletes a snapshot from a repository. | To view a list of your repositories, choose Repositories under the Snapshot Management section. | To view a list of your snapshots, choose Snapshots under the Snapshot Management section. | . ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/snapshot-management/index.html#deleting-a-snapshot",
    "relUrl": "/analytics/opensearch-dasboard/snapshot-management/index.html#deleting-a-snapshot"
  },"201": {
    "doc": "Snapshot management",
    "title": "Restoring a snapshot",
    "content": ". | On the top menu bar, go to OpenSearch Plugins &gt; Snapshot Management. | In the left panel, under Snapshot Management, select Snapshots. The Snapshots tab is selected by default. | Select the checkbox next to the snapshot you want to restore, as shown in the following image: . You can only restore snapshots with the status of Success or Partial. The status of the snapshot is displayed in the Snapshot status column. | In the Restore snapshot flyout, select the options for restoring the snapshot. The Restore snapshot flyout lists the snapshot name and status. To view the list of indexes in the snapshot, select the number under Indices (for example, 27 in the following image). This number represents the number of indexes in the snapshot. For more information about the options in the Restore snapshot flyout, see Restore snapshots. Ignoring missing indexes . If you specify which indexes you want to restore from the snapshot and select the Ignore unavailable indices option, the restore operation ignores the indexes that are missing from the snapshot. For example, if you want to restore the log1 and log2 indexes, but log2 is not in the snapshot, log1 is restored and log2 is ignored. If you don’t select Ignore unavailable indices, the entire restore operation fails if an index to be restored is missing from a snapshot. Custom index settings . You can choose to customize some settings for the indexes restored from a snapshot:  • Select the Customize index settings checkbox to provide new values for the specified index settings. All newly restored indexes will use these values instead of the ones in the snapshot.  • Select the Ignore index settings checkbox to specify the settings in the snapshot to ignore. All newly restored indexes will use the cluster defaults for these settings. The examples in the following image set index.number_of_replicas to 0, index.auto_expand_replicas to true, and index.refresh_interval and index.max_script_fields to the cluster default values for all newly restored indexes. For more information about index settings, see Index settings. For a list of settings that you cannot change or ignore, see Restore snapshots. After choosing the options, select the Restore snapshot button. | (Optional) To monitor the restore progress, select View restore activities in the confirmation dialog. You can also monitor the restore progress at any time by selecting the Restore activities in progress tab, as shown in the following image. You can view the percentage of the job that has been completed in the Status column. Once the snapshot restore is complete, the Status changes to Completed (100%). The Restore activities in progress panel is not persistent. It displays only the progress of the current restore operation. If multiple restore operations are running, the panel displays the most recent one. To view the status of each index being restored, select the link in the Indices being restored column (in the preceding image, the 27 Indices link). The Indices being restored flyout (shown in the following image) displays each index and its restore status. | . After the restore operation is complete, the restored indexes are listed in the Indices panel. To view the indexes, in the left panel, under Index Management, choose Indices. ",
    "url": "http://localhost:4000/analytics/opensearch-dasboard/snapshot-management/index.html#restoring-a-snapshot",
    "relUrl": "/analytics/opensearch-dasboard/snapshot-management/index.html#restoring-a-snapshot"
  },"202": {
    "doc": "Overview",
    "title": "Elysium Overview",
    "content": "Overview . ",
    "url": "http://localhost:4000/analytics/overview/index.html#elysium-overview",
    "relUrl": "/analytics/overview/index.html#elysium-overview"
  },"203": {
    "doc": "Overview",
    "title": "Introduction",
    "content": "Elysium Overview is a Overview tool designed to help users quickly integrate and Monitor data within a database. ",
    "url": "http://localhost:4000/analytics/overview/index.html#introduction",
    "relUrl": "/analytics/overview/index.html#introduction"
  },"204": {
    "doc": "Overview",
    "title": "Overview",
    "content": " ",
    "url": "http://localhost:4000/analytics/overview/index.html",
    "relUrl": "/analytics/overview/index.html"
  },"205": {
    "doc": "Analytics",
    "title": "Elysium Analytics",
    "content": "Overview . ",
    "url": "http://localhost:4000/observability/analytics/index.html#elysium-analytics",
    "relUrl": "/observability/analytics/index.html#elysium-analytics"
  },"206": {
    "doc": "Analytics",
    "title": "Introduction",
    "content": "Elysium Analytics is a Analytics tool designed to help users quickly analyse and Monitor data within a database. ",
    "url": "http://localhost:4000/observability/analytics/index.html#introduction",
    "relUrl": "/observability/analytics/index.html#introduction"
  },"207": {
    "doc": "Analytics",
    "title": "Analytics",
    "content": " ",
    "url": "http://localhost:4000/observability/analytics/index.html",
    "relUrl": "/observability/analytics/index.html"
  },"208": {
    "doc": "Dashboards",
    "title": "Observability Dashboards",
    "content": " ",
    "url": "http://localhost:4000/observability/dashboards/index.html#observability-dashboards",
    "relUrl": "/observability/dashboards/index.html#observability-dashboards"
  },"209": {
    "doc": "Dashboards",
    "title": "Dashboards",
    "content": " ",
    "url": "http://localhost:4000/observability/dashboards/index.html",
    "relUrl": "/observability/dashboards/index.html"
  },"210": {
    "doc": "Observability",
    "title": "Observability",
    "content": "Observability Documentation . About DocumentationAbout DocumentationAbout DocumentationAbout DocumentationAbout DocumentationAbout DocumentationAbout DocumentationAbout DocumentationAbout DocumentationAbout DocumentationAbout DocumentationAbout DocumentationAbout DocumentationAbout DocumentationAbout DocumentationAbout DocumentationAbout DocumentationAbout DocumentationAbout DocumentationAbout DocumentationAbout DocumentationAbout DocumentationAbout DocumentationAbout DocumentationAbout DocumentationAbout DocumentationAbout DocumentationAbout DocumentationAbout DocumentationAbout Documentation . ",
    "url": "http://localhost:4000/observability/index.html",
    "relUrl": "/observability/index.html"
  },"211": {
    "doc": "Metrics",
    "title": "Elysium Metrics",
    "content": "Overview . ",
    "url": "http://localhost:4000/observability/metrics/index.html#elysium-metrics",
    "relUrl": "/observability/metrics/index.html#elysium-metrics"
  },"212": {
    "doc": "Metrics",
    "title": "Introduction",
    "content": "Elysium Metrics is a metric tool designed to help users quickly integrate and Monitor data within a database. ",
    "url": "http://localhost:4000/observability/metrics/index.html#introduction",
    "relUrl": "/observability/metrics/index.html#introduction"
  },"213": {
    "doc": "Metrics",
    "title": "Metrics",
    "content": " ",
    "url": "http://localhost:4000/observability/metrics/index.html",
    "relUrl": "/observability/metrics/index.html"
  },"214": {
    "doc": "Overview",
    "title": "Elysium Overview",
    "content": "Overview . ",
    "url": "http://localhost:4000/observability/overview/index.html#elysium-overview",
    "relUrl": "/observability/overview/index.html#elysium-overview"
  },"215": {
    "doc": "Overview",
    "title": "Introduction",
    "content": "Elysium Overview is a Overview tool designed to help users quickly integrate and Monitor data within a database. ",
    "url": "http://localhost:4000/observability/overview/index.html#introduction",
    "relUrl": "/observability/overview/index.html#introduction"
  },"216": {
    "doc": "Overview",
    "title": "Overview",
    "content": " ",
    "url": "http://localhost:4000/observability/overview/index.html",
    "relUrl": "/observability/overview/index.html"
  },"217": {
    "doc": "Alerts",
    "title": "Security Alerts",
    "content": "This section describes the Elysium Security Alerts and its components. Any event or a group of events that is an anomaly (or a red flag) can be called an alert (or trigger or alarm). What makes this an anomaly is generally decided and defined by the client itself. For example, let us say if we have a threshold for some measure, say execution time. If the value of that measure crosses a certain threshold value, then we can call it an anomaly, or in other words, an alert. Ideally, alerts are supposed to be as minimal as possible. The software from which we receive logs is called source software, or simply sources. Examples of sources include - Windows Security, Dell Boomi, Microsoft Azure, Watchguard Firewall etc. The sources differ from client to client. ",
    "url": "http://localhost:4000/security/alerts/index.html#security-alerts",
    "relUrl": "/security/alerts/index.html#security-alerts"
  },"218": {
    "doc": "Alerts",
    "title": "Alerts Interface",
    "content": "Click on “Alerts” under Security Menu to access the Security Alerts. We have three alert tabs . | Alert Rules | Alerts | Alerts Dashboard | . ",
    "url": "http://localhost:4000/security/alerts/index.html#alerts-interface",
    "relUrl": "/security/alerts/index.html#alerts-interface"
  },"219": {
    "doc": "Alerts",
    "title": "Alert Rules",
    "content": "Shows all the alert rules have been defined for various sources, along with their status, properties etc. It also allows users to create new alert rules and configure their properties. | The alert rules we define appear here with - | ID: Auto-increment sequence number | Category: Type of the alert. Rule-based and Behaviour Alerts are the two alert types. Refer to the below image for more detail. | Rule - Shows the source name and a semi SQL | -like condition describing the configured rule | Properties - Shows other properties of the alert rule such as severity, rollup window, message, additional comments &amp; email recipients. The severity of the alert can be low/medium/high. Rollup window tells us the time window for clubbing the alerts as alert count in the email notifications. Message and additional comments contain any additional description of the alert. Email recipients shows the email IDs to which the alert notification has to be sent. | Created At - Shows the timestamp when the alert rule is created | Created By - Shows the user who created the alert rule | Immediate Notifications - Shows whether an immediate notification has to | be sent or not, when the alert is triggered. Whenever an alert is triggered, it has to be notified or shown to the client. This is currently being done in a couple of ways - email notifications, Looker dashboards and the ‘Alerts Table’ page. The user can either enable or disable it. Alert notifications are of three types - immediate, scheduled and manual. In immediate notification, mail is sent immediately after an alert is triggered. In scheduled notification (report scheduler), a consolidated list of all alerts that have occurred within a user-defined time period is mailed (say every hour or day or week or month). This time period can be defined once by the user, and a mail notification will be sent periodically at that fixed time. In manual notification, a consolidated report of all the alerts that have occurred for a particular day is mailed, upon the user’s request. | Status - Shows whether the alert rule is in active or inactive state | Action - Has options to Edit, Delete, Activate &amp; Deactivate the alert rule | At the top are the ‘Report Scheduler’ and ‘Add New Rule’ options. The ‘Report Scheduler’ gives a report of all the alerts that have occurred within the specified frequency mentioned by the user. All high-priority alerts will be sent to the user everyday by default. The ‘Add New Rule’ option can be used to create a new alert rule. Let us see that below. | . 1)Add New Rule . The ‘Add New Rule’ link is at the top right corner of the ‘Manage Alert Rules’ page, where you can define a new alert rule step-by-step. There are currently two categories of alerts. Select either of the two options. | Behavior-Based: Alerts based on the behavior of a user or system. | Rule-Based: Alerts based on a pre-defined rule. We can define multiple combinations of rules using AND, OR operators corresponding to the sources (Boomi, Azure) | . After clicking on create new alert rule you will navigate to create alert page where you can different steps and forms like this: . We have three steps for creating alert rule . | Choose Method: Select the category to create rule or behaviour type of alert rule by clicking on the toggle buttons like this | . ",
    "url": "http://localhost:4000/security/alerts/index.html#alert-rules",
    "relUrl": "/security/alerts/index.html#alert-rules"
  },"220": {
    "doc": "Alerts",
    "title": "Behaviour Alerts",
    "content": "Alerts based on the behavior of a user or system are call Behaviour Alerts. As can be seen in the picture below, we start defining the alert rule by choosing from different categories of alert rules: Real-Time and Schedule. The first option gives the flexibility of tying each triggered to an event in the source table (“Real-time”) or triggering it independent of a particular event(“Schedule”) . Real-Time vs Schedule Triggers: The main difference is that Real-Time Triggers are generated after each event and compared with previous events within the specified rolling time window whereas Scheduled Triggers are generated as per the run frequency specified by the users for all the events that occur inside the specified rolling time window. A. Real-time Trigger Alerts . These are alert that searches for events continuously near Real-Time. They trigger alert actions when results meet user-defined conditions within a rolling time window. For example, a SOC Admin can set up an alert to get notified as soon a fifth failed login attempt is performed by a user within the last 24 hours. Real-time alerts have two threshold types:- Absolute and Relative. Absolute vs Relative Thresholds: Absolute Thresholds are specific numeric values that are entered by the user when defining the alerts which then compared with the Metric. Relative Thresholds are thresholds where an aggregate or a grouping function is applied on the Threshold and is then compared to the specific value for that event. An example of an alert condition with an Absolute Threshold is Avg(duration)&gt;1000. Here 1000 is the threshold as defined by the user. An example of an alert condition with a Relative Threshold is Duration &gt; (avg(duration) * 2). Here (avg(duration) * 2) is the threshold as defined by the user. A1. Absolute Threshold . These are alerts that have a threshold as an absolute value as defined by the user i.e the alert triggering criteria is a number value that is specified when creating the alerts. It can be set up in such a way that the alerts will be triggered when the encountered value is &gt;=, &lt;=, =, etc. than the threshold value defined. Below is the text which will be shown in Condition preview when you create a Real-time alert with an Absolute threshold. WHEN sum(duration) FOR EACH Domain &gt; 1000 IN LAST 10 Hours FOR EACH RESULT . The below image shows us the different parameters which the user would need to input to set up a real-time - Absolute alert condition. All the fields are mandatory to set up an alert condition. 1.Source . Shows all the source systems from which we receive logs for a particular client. Examples of sources include - Windows Security, Dell Boomi, Microsoft Azure, Watchguard Firewall, etc. The sources differ from client to client. 2.Feature . Feature lists the different fields for each source over which metric can be formed. The fields in Feature can either be of type string or number and each type is associated with its own set of metrics ( specified below ). 3.Metrics . Metrics are the different mathematical aggregate or grouping functions that can be applied over a feature. The different Metrics currently available in Version 1.75 are sum, avg, min, max, count, P90, P10, Rate, and median. All the Metrics are applicable for Features with type number whereas only count and Rate are applicable for strings since not all mathematical groupings are suited for strings. The usage for all metrics except P90, P10, and Rate are self-explanatory and straightforward. The explanation for P90, P10, and Rate can be found in the appendix section. 4.Context . Context is the attribute/column from the source with which you group the Metrics. The results will be calculated/grouped by each value in the context field. “GLOBAL” context is also given as an option that allows you to calculate the metric on all the new data rather than to split it up for each context. For example, you can choose “src_user_name” as context if you want the max(event_id) for each src_user_name, however, to choose the max(event_id) for the entire dataset, you can choose GLOBAL as the context. 5.Operator . This is the comparison operator which has to be specified between the Metric and the Threshold. Eg : &gt;, &gt;=, =, etc. 6.Threshold . The threshold is the number value defined by the user which will be compared with the Metrics value. 7.Timeframe . The timeframe is the rolling time window entered by the user associated with the particular alert. 8.Timeunit . The time unit is the measure of timeframe entered. The current options are minutes and hours. Now that we have gone through all the components that make an Absolute Threshold alert, the below representation highlights all the components that users would have entered on the alert condition that was built. ",
    "url": "http://localhost:4000/security/alerts/index.html#behaviour-alerts",
    "relUrl": "/security/alerts/index.html#behaviour-alerts"
  },"221": {
    "doc": "Alerts",
    "title": "Rule Based Alerts",
    "content": "These are relatively simpler alert rules, where you can create simple to very complex nested rule conditions that are checked across each event in the source table. You can see the sample UI below whereby choosing “Add Group” option, you add a nested conditional branch whereas the “ADD Rule” option just adds another condition to the same branch. ",
    "url": "http://localhost:4000/security/alerts/index.html#rule-based-alerts",
    "relUrl": "/security/alerts/index.html#rule-based-alerts"
  },"222": {
    "doc": "Alerts",
    "title": "Notification Settings:",
    "content": "The notification settings are very similar between the different kinds of alerts, so an in-depth explanation is not required for this section. However in Rule based alerts, the context is provided in the notification settings since context does not affect the results in Rule based alert and can be used to just roll up the data. | Define Rule: Enter the source, after selecting source there will one input where you can enter your condition type and condition for alert rule | Define Alert Properties: Fill the required fields in this step to create a rule. The number of fieldsdiffer on selection category in the first step (rule/behaviour). Required Fields: Title, Severity | . Optional Fields: Description, Email notifications, Email recepients . For Rule based - Email notifications – true, submit these fields . For Behaviour based – Run Frequency . If real time is scheduled submit the cron-expression too as shown below . After submitting all the required fields, you can click on save to create the new alert rule. If the alert data, you submitted is valid it will create new alert rule and navigates you back to the alerts page where you can see your alert created in the table. To do any changes click on actions for that particular row and edit them update them . 2)Search . Type in this search box to search specific alert rules using keywords like alert title, id’s, status etc… . These are the results for the keyword ‘title’ that from the search box . 3)Actions on table . | Click on arrow icon to view complete alert rule data | . | Click on menu icon to view actions that can be performed on alert rules | . Onclick on all actions icon as shown in first picture it will display three different actions as shown in second picture . | Delete Action – On Click on delete action you will get a confirm pop up like this. | . | Select Cancel option for not deleting the rule | Select Confirm option for deleting the rule, after the rule gets deleted table gets refreshed and shows the updated data | . After clicking on confirm button table will loads and shows updated alert rules . | Edit Action – To Edit any specific rule click on the edit option which it will navigates you to the edit page | . After clicking edit you will navigate to this page where you can edit alert rules data and update the rule successfully . 3. Activate/ Deactivate Action – To Activate or Deactivate the rule select this option as shown in the below image . After clicking on activate/ deactivate button table loads and shows updated status of alert rules . ",
    "url": "http://localhost:4000/security/alerts/index.html#notification-settings",
    "relUrl": "/security/alerts/index.html#notification-settings"
  },"223": {
    "doc": "Alerts",
    "title": "Alerts",
    "content": "On selecting alerts tab, you can see the table like the below image: . Table Interface . This page shows all the alerts that have been triggered so far, based on the alert rules defined by the client. Details about the alerts like - Source (source name), Parent ID (parent alert ID), Alert Name (alert name and condition) &amp; Count (clone count, or count of similar alerts) are shown. The alerts can also be filtered based on date, or can be searched with the parent ID, as shown in the below image. | Search Box: Search here for alerts with keywords like title | Date Picker: You can select the specified dates to check the generated alerts in that time period. | . ",
    "url": "http://localhost:4000/security/alerts/index.html",
    "relUrl": "/security/alerts/index.html"
  },"224": {
    "doc": "Alerts",
    "title": "Alerts Dashboard",
    "content": "On selecting alerts dashboards tab, you can see the alerts dashboard iframe like the below image: . Text . ",
    "url": "http://localhost:4000/security/alerts/index.html#alerts-dashboard",
    "relUrl": "/security/alerts/index.html#alerts-dashboard"
  },"225": {
    "doc": "Build You Own Dashboards",
    "title": "Build Your Own Dashboards:",
    "content": "Build your own dashboards using pre-defined Elysium data models. Step 1: Click “Add New Dashboard” Button . Step 2: Specify the Dashboard Title and Click “ Save ” . Step 3: Click on “Edit Dashboard” . Step 4: click on “Add” &gt; “Visualization” . Step 5: Choose the Model you would like to build the dashboard on . Steps to create a quick visualization: . Step 7: Specify the Tile Title . Step 8: Click on the Fields to use from the Model Pane on the left side it gets added to the right bottom Data section on the right side, ideally there must be one dimension and one measure field to be used for each Visualization. Step 9: Add fields to filter section by choosing the 3 lines icon next to the field you want to filter on. Note: Add only tile specific filters here, if you need this filter across the dashboard, then set it globally as per Step No.12 below . Step 10: Choose the Visualization Type and Click Edit to change the settings of the visualization. Step 11: Click Run to view the output and Click Save to Save the tile . Note: Please ensure to save the dashboard as per step 16, if not changes would not be applied . Step 12: To Add filters Globally for the dashboard, Click Filters &gt; Add Filter . Step 13: Choose the field to filter on . Step 14: Set the default value if needed and click Add . Step 15: To add more visualization to the dashboard, Click Add &gt; Visualization on top of the dashboard and repeat all the steps above. Or you can duplicate the existing tile by choosing the 3 dots &gt; Duplicate Tile and click Edit on the duplicate tile and make changes as needed. Step 16: Click Save on the top right corner to Save the dashboard. The dashboards gets saved in the Personal Dashboard Folder . If you would like to make this dashboard shared with other users, click 3 dots &gt; Move to Shared . And the dashboard will be visible in the Shared Folder . Sample Dashboard . ",
    "url": "http://localhost:4000/security/dashboards/byod/index.html#build-your-own-dashboards",
    "relUrl": "/security/dashboards/byod/index.html#build-your-own-dashboards"
  },"226": {
    "doc": "Build You Own Dashboards",
    "title": "Build You Own Dashboards",
    "content": " ",
    "url": "http://localhost:4000/security/dashboards/byod/index.html",
    "relUrl": "/security/dashboards/byod/index.html"
  },"227": {
    "doc": "Dashboard Interface",
    "title": "Dashboards Interface",
    "content": "Click on “Dashboards” under Security Menu to access the Security Dashboards . ",
    "url": "http://localhost:4000/security/dashboards/interface/index.html#dashboards-interface",
    "relUrl": "/security/dashboards/interface/index.html#dashboards-interface"
  },"228": {
    "doc": "Dashboard Interface",
    "title": "Dashboard Interface",
    "content": " ",
    "url": "http://localhost:4000/security/dashboards/interface/index.html",
    "relUrl": "/security/dashboards/interface/index.html"
  },"229": {
    "doc": "Metadata Models",
    "title": "Dashboard Metadata Models:",
    "content": "| S.No | Model Category | Model Name | Short Description | IOC Fields | Metrics | . | 1 | Alerts | Elysium Alerts | Provides |   |   | . | 2 | Alerts | NetSkope Alerts |   |   |   | . | 3 | Behavorial | Security Posture |   |   |   | . | 4 | Behavorial | User Activity |   |   |   | . ",
    "url": "http://localhost:4000/security/dashboards/metadata-models/index.html#dashboard-metadata-models",
    "relUrl": "/security/dashboards/metadata-models/index.html#dashboard-metadata-models"
  },"230": {
    "doc": "Metadata Models",
    "title": "Metadata Models",
    "content": " ",
    "url": "http://localhost:4000/security/dashboards/metadata-models/index.html",
    "relUrl": "/security/dashboards/metadata-models/index.html"
  },"231": {
    "doc": "List of Dashboards",
    "title": "List of Dashboards:",
    "content": "Security Analytics Dashboards: . | S.No | Dashboard Name | Short Description | Use-Case | . | 1 | Security Posture | Provides complete security |   | . | 2 | Network Activity Dashboard |   |   | . | 3 |   |   |   | . Source Specific Dashboards . ",
    "url": "http://localhost:4000/security/dashboards/list/index.html#list-of-dashboards",
    "relUrl": "/security/dashboards/list/index.html#list-of-dashboards"
  },"232": {
    "doc": "List of Dashboards",
    "title": "List of Dashboards",
    "content": " ",
    "url": "http://localhost:4000/security/dashboards/list/index.html",
    "relUrl": "/security/dashboards/list/index.html"
  },"233": {
    "doc": "How to Use",
    "title": "How to use:",
    "content": "This section describes about the Elysium dashboards Structure and how to use them effectively. Dashboards are typically split in to 5 Sections. ",
    "url": "http://localhost:4000/security/dashboards/how-to-use/index.html#how-to-use",
    "relUrl": "/security/dashboards/how-to-use/index.html#how-to-use"
  },"234": {
    "doc": "How to Use",
    "title": "How to Use",
    "content": " ",
    "url": "http://localhost:4000/security/dashboards/how-to-use/index.html",
    "relUrl": "/security/dashboards/how-to-use/index.html"
  },"235": {
    "doc": "Dashboards",
    "title": "Security Dashboards",
    "content": "This section describes the Elysium Security Dashboards and its components. Elysium Security Dashboards provides Descriptive, Predictive and Perspective Analytics Dashboards across varied sources based on your organization security sources. ",
    "url": "http://localhost:4000/security/dashboards/index.html#security-dashboards",
    "relUrl": "/security/dashboards/index.html#security-dashboards"
  },"236": {
    "doc": "Dashboards",
    "title": "Dashboards",
    "content": " ",
    "url": "http://localhost:4000/security/dashboards/index.html",
    "relUrl": "/security/dashboards/index.html"
  },"237": {
    "doc": "Security",
    "title": "Security",
    "content": "Security Documentation . ",
    "url": "http://localhost:4000/security/index.html",
    "relUrl": "/security/index.html"
  },"238": {
    "doc": "Notebooks",
    "title": "Elysium Notebooks",
    "content": "search engine . ",
    "url": "http://localhost:4000/security/notebooks/index.html#elysium-notebooks",
    "relUrl": "/security/notebooks/index.html#elysium-notebooks"
  },"239": {
    "doc": "Notebooks",
    "title": "Introduction",
    "content": "Elysium Notebooks is a security tool designed to help users quickly secure and Monitor data within a database. ",
    "url": "http://localhost:4000/security/notebooks/index.html#introduction",
    "relUrl": "/security/notebooks/index.html#introduction"
  },"240": {
    "doc": "Notebooks",
    "title": "Notebooks",
    "content": " ",
    "url": "http://localhost:4000/security/notebooks/index.html",
    "relUrl": "/security/notebooks/index.html"
  },"241": {
    "doc": "Overview",
    "title": "Elysium Overview",
    "content": "Overview . ",
    "url": "http://localhost:4000/security/overview/index.html#elysium-overview",
    "relUrl": "/security/overview/index.html#elysium-overview"
  },"242": {
    "doc": "Overview",
    "title": "Introduction",
    "content": "Elysium Overview is a Overview tool designed to help users quickly integrate and Monitor data within a database. ",
    "url": "http://localhost:4000/security/overview/index.html#introduction",
    "relUrl": "/security/overview/index.html#introduction"
  },"243": {
    "doc": "Overview",
    "title": "Overview",
    "content": " ",
    "url": "http://localhost:4000/security/overview/index.html",
    "relUrl": "/security/overview/index.html"
  },"244": {
    "doc": "Dashboards",
    "title": "Dashboards",
    "content": "This section describes number of Dashboards available, not all users have access to all the Dashboards, an Admin will have access to this page to control accessibility of Dashboards for a user. In general, there are MainDashboard and for each mainDashboard will have sub-Dashboard. An Admin can create newDashboardand can delete existingDashboard. ",
    "url": "http://localhost:4000/user-management/admin/dashboards/index.html",
    "relUrl": "/user-management/admin/dashboards/index.html"
  },"245": {
    "doc": "Dashboards",
    "title": "Dashboard Interface",
    "content": ". | Click on “Admin” inside bottom left side menu displaying username to access the Dashboard page. | By default, Users page is selected, click on the Dashboard tab to access Dashboard page. | . ",
    "url": "http://localhost:4000/user-management/admin/dashboards/index.html#dashboard-interface",
    "relUrl": "/user-management/admin/dashboards/index.html#dashboard-interface"
  },"246": {
    "doc": "Dashboards",
    "title": "How to use:",
    "content": ". | There are Tabs inside Admin section, by default Users page is selected. | Click on the Dashboards tab to access the Dashboard page. | . ",
    "url": "http://localhost:4000/user-management/admin/dashboards/index.html#how-to-use",
    "relUrl": "/user-management/admin/dashboards/index.html#how-to-use"
  },"247": {
    "doc": "Dashboards",
    "title": "Search bar:",
    "content": ". | Admin can search for specific Menu by Name or by Created Date. | . ",
    "url": "http://localhost:4000/user-management/admin/dashboards/index.html#search-bar",
    "relUrl": "/user-management/admin/dashboards/index.html#search-bar"
  },"248": {
    "doc": "Dashboards",
    "title": "Add New Dashboard: (Button)",
    "content": ". | This button is to create a new Dashboard. | On clicking this button, a form pops up with input fields to fill. | . ",
    "url": "http://localhost:4000/user-management/admin/dashboards/index.html#add-new-dashboard-button",
    "relUrl": "/user-management/admin/dashboards/index.html#add-new-dashboard-button"
  },"249": {
    "doc": "Dashboards",
    "title": "Steps to create New Menu:",
    "content": ". | Parent ID, Name, Level are text input fields which an Admin can specify the Name of Dashboard. | By default, Parent ID and Level will be prefilled. | . | Role: input field defines what role to assign for the New Menu, this is a drop-down filed which has some predefined role options available to select and can search for specific role from available options. | . | Users: Input is a drop-down field which has all the available users as options, to assign new Menu to all the required users can be selected with multiple selection option. | . | Cancel &amp; Save: (Button) to create a user with filled details click on save button or if want to cancel user creation process click on cancel button. | . | This table provides information on Dashboard details like ID, Name, Status, Level, Users, Roles, created (created date and time). | . | Drop-down: action button on click will expand and display Hidden sub-dashboards in Table format, which will have number of sub-dashboards in rows. Each row will have an Action Button to perform an action on each sub-dashboard. | . ",
    "url": "http://localhost:4000/user-management/admin/dashboards/index.html#steps-to-create-new-menu",
    "relUrl": "/user-management/admin/dashboards/index.html#steps-to-create-new-menu"
  },"250": {
    "doc": "Dashboards",
    "title": "Actions:",
    "content": ". | Click on Three dots populated on each row of a Dashboard which pops up options to perform an action on each Dashboard data. | . | Delete: Click on Three Dots &gt; Delete which gives a confirmation message on the screen to take a final confirmation if the delete action should be confirmed. | Click on Confirm option to delete a Menu or click on Cancel button to terminate the action. | . | Edit: Click on Three Dots &gt; Edit which pops up a prefilled form, if want to edit any information regarding a particular Dashboard change the data and click on Edit button. | . | Add New Sub-Dashboard: (Button) clicking on will pop up a form with input fields to be filled in to create a new Sub-Dashboard. | . | Activate/Deactivate: Click on Three Dots &gt; Activate/Deactivate will change the Active Status of Dashboard | . | Parent ID, Name, Level, URL, Color Code, Code, Description are text input fields where an Admin can specify with details inside input field. | By default, Parent ID and Level will be prefilled (which cannot be changed). | . | Role: input field defines what role to assign for the New Dashboard, this is a drop-down filed which has some predefined role options available to select and can search for specific role by searching from available options. | . | Users: Input is a drop-down field which has all the available users as options, to assign new Dashboard to all the required users can be selected with multiple selection option. | Cancel &amp; Save: (Button) to create a Dashboard with filled details click on save button or if want to terminate creation process click on cancel button. | . ",
    "url": "http://localhost:4000/user-management/admin/dashboards/index.html#actions",
    "relUrl": "/user-management/admin/dashboards/index.html#actions"
  },"251": {
    "doc": "Dashboards",
    "title": "Pagination:",
    "content": ". | Click on Row per page which populates some options which describe the number of Rows of Dashboard per page that should be displayed inside the table. | Describe number of pages available. | . ",
    "url": "http://localhost:4000/user-management/admin/dashboards/index.html#pagination",
    "relUrl": "/user-management/admin/dashboards/index.html#pagination"
  },"252": {
    "doc": "Menus",
    "title": "Menus",
    "content": "This section describesnumber of menusavailable, not all users have access to all the Menu on the Sidebar, an Admin willhave accessto this page to control accessibility of Menus for a user.In general, there are Main menus and for each main menu will have sub-Menus. An Admin can create new Menuandcan delete existing Menus. ",
    "url": "http://localhost:4000/user-management/admin/menus/index.html",
    "relUrl": "/user-management/admin/menus/index.html"
  },"253": {
    "doc": "Menus",
    "title": "Menus Interface",
    "content": ". | Click on “Admin” inside bottom left side menu displaying username to access the Menus page. | By default, Users page is selected, click on the Menus tab to access Menu page. | . ",
    "url": "http://localhost:4000/user-management/admin/menus/index.html#menus-interface",
    "relUrl": "/user-management/admin/menus/index.html#menus-interface"
  },"254": {
    "doc": "Menus",
    "title": "How to use:",
    "content": ". | There are Tabs inside Admin section, by default Users page is selected. | Click on the Menus tab to access the Menus page. | . ",
    "url": "http://localhost:4000/user-management/admin/menus/index.html#how-to-use",
    "relUrl": "/user-management/admin/menus/index.html#how-to-use"
  },"255": {
    "doc": "Menus",
    "title": "Search bar:",
    "content": ". | Admin can search for specific Menu by Name, Icon or by Created Date. | . ",
    "url": "http://localhost:4000/user-management/admin/menus/index.html#search-bar",
    "relUrl": "/user-management/admin/menus/index.html#search-bar"
  },"256": {
    "doc": "Menus",
    "title": "Add New Menu: (Button)",
    "content": ". | This button is to create a new Menu. | On clicking this button, a form pops up with input fields to fill. | . ",
    "url": "http://localhost:4000/user-management/admin/menus/index.html#add-new-menu-button",
    "relUrl": "/user-management/admin/menus/index.html#add-new-menu-button"
  },"257": {
    "doc": "Menus",
    "title": "Steps to create New Menu:",
    "content": ". | Parent ID, Name, Level, Icon are text input fields which an Admin can specify the Name and type of Icon. | By default, Parent ID and Level will be prefilled. | . | Role: input field defines what role to assign for the New Menu, this is a drop-down filed which has some predefined role options available to select and can search for specific role by searching from available options. | . | Users: Input is a drop-down field which has all the available users as options, to assign new Menu to all the required users can be selected with multiple selection option. | . | Cancel &amp; Save: (Button) to create a user with filled details click on save button or if want to cancel user creation process click on cancel button. | . | This table provides information on Menu details like ID, Name, Icon, Status, Users, Roles, created (created date and time). | . . | Drop-down: action button on click will expand and display Hidden sub-menu in Table format, which will have number of sub-menus in rows. Each row will have an Action Button to perform an action on each sub-menu. | . ",
    "url": "http://localhost:4000/user-management/admin/menus/index.html#steps-to-create-new-menu",
    "relUrl": "/user-management/admin/menus/index.html#steps-to-create-new-menu"
  },"258": {
    "doc": "Menus",
    "title": "Actions:",
    "content": ". | Click on Three dots populated on each row of a Menu which pops up options to perform an action on each Menu data. | . | Delete: Click on Three Dots &gt; Delete which gives a confirmation message on the screen to take a final confirmation if the delete action should be confirmed. | Click on Confirm option to delete a Menu or click on Cancel button to terminate the action. | . | Edit: Click on Three Dots &gt; Edit which pops up a prefilled form, if want to edit any information regarding a particular Menu, change the data and click on Edit button. | . | Activate/Deactivate: Click on Three Dots &gt; Activate/Deactivate will change the Active Status of Menu | . | Add New Sub-Menu: (Button) clicking on will pop up a form with input fields to be filled in to create a new Sub-Menu. | . | Parent ID, Name, Level, Icon are text input fields where an Admin can specify the Name and type of Icon. | By default, Parent ID and Level will be prefilled (which cannot be changed). | . | Role: input field defines what role to assign for the New Menu, this is a drop-down filed which has some predefined role options available to select and can search for specific role by searching from available options. | . | Users: Input is a drop-down field which has all the available users as options, to assign new Menu to all the required users can be selected with multiple selection option. | . | Cancel &amp; Save: (Button) to create a user with filled details click on save button or if want to cancel user creation process click on cancel button. | . ",
    "url": "http://localhost:4000/user-management/admin/menus/index.html#actions",
    "relUrl": "/user-management/admin/menus/index.html#actions"
  },"259": {
    "doc": "Menus",
    "title": "Pagination:",
    "content": ". | Click on Row per page which populates some options which describe the number of Rows of Menus per page that should be displayed inside the table. | Describe number of pages available. | . ",
    "url": "http://localhost:4000/user-management/admin/menus/index.html#pagination",
    "relUrl": "/user-management/admin/menus/index.html#pagination"
  },"260": {
    "doc": "Roles",
    "title": "Roles",
    "content": "This section describes the Elysium number of Roles created and their details regarding types of roles, Activestatus and number users per Each role . And an Adminwillhave the access to create a new Role , delete existing Roles or activate or deactivate existing Roles and can assignUserswithRole. ",
    "url": "http://localhost:4000/user-management/admin/roles/index.html",
    "relUrl": "/user-management/admin/roles/index.html"
  },"261": {
    "doc": "Roles",
    "title": "Roles Interface",
    "content": ". | Click on “Admin” inside bottom left side menu displaying username to access the Roles page. | By default, Users page is selected, Click on Roles tab to access roles page. | | . ",
    "url": "http://localhost:4000/user-management/admin/roles/index.html#roles-interface",
    "relUrl": "/user-management/admin/roles/index.html#roles-interface"
  },"262": {
    "doc": "Roles",
    "title": "How to use:",
    "content": ". | There are Tabs inside Admin section, by default Users page is selected. | Click on Roles tab to access roles page. | . ",
    "url": "http://localhost:4000/user-management/admin/roles/index.html#how-to-use",
    "relUrl": "/user-management/admin/roles/index.html#how-to-use"
  },"263": {
    "doc": "Roles",
    "title": "Search bar:",
    "content": ". | Admin can search using Role’s information like Name of Role or by Description. | . ",
    "url": "http://localhost:4000/user-management/admin/roles/index.html#search-bar",
    "relUrl": "/user-management/admin/roles/index.html#search-bar"
  },"264": {
    "doc": "Roles",
    "title": "Add New Role: (Button)",
    "content": ". | This button is to create a new Role with role details. | On clicking this button, a form pops up with input fields to fill. | . ",
    "url": "http://localhost:4000/user-management/admin/roles/index.html#add-new-role-button",
    "relUrl": "/user-management/admin/roles/index.html#add-new-role-button"
  },"265": {
    "doc": "Roles",
    "title": "Steps to create New Role:",
    "content": ". | Input files like Role Name &amp; Description can be typed and fill the details of the Role. | . | The index pattern is a drop-down filed which has some options which can be selected with single selection option. | . | Users Input is a drop-down field which has all the available users as options, to assign new role to all the required users can be selected with multiple selection option. | . | Dashboard: drag and drop field which has available dashboards on the left and selected dashboards on the right, there are some dashboard options available on the left section need to drag and drop the required dashboard option on the right section. | . | Menu: selectable button options which has available menu as a transparent button with ‘+’ icon, to select which menus the user should have access click on the require menu button which turns it into Blue filled button with Tick icon. | . | Cancel &amp; Save: (Button) to create a user with filled details click on save button or if want to cancel user creation process click on cancel button. | . ",
    "url": "http://localhost:4000/user-management/admin/roles/index.html#steps-to-create-new-role",
    "relUrl": "/user-management/admin/roles/index.html#steps-to-create-new-role"
  },"266": {
    "doc": "Roles",
    "title": "Role Table:",
    "content": ". | This table provides information on Roles details like Role Name, Description, Status, User ID (number of users are assigned with the role). | . ",
    "url": "http://localhost:4000/user-management/admin/roles/index.html#role-table",
    "relUrl": "/user-management/admin/roles/index.html#role-table"
  },"267": {
    "doc": "Roles",
    "title": "Actions:",
    "content": ". | Click on Three dots populated on each row of a Role which pops up options to perform an action on each Role data. | . | click on Three Dots a pop-up menu option of actions appears to be performed on a Role data. | . | Delete: Click on Three Dots &gt; Delete which gives a confirmation message on the screen to take a final confirmation if the delete action should be confirmed. | Click on Confirm option to delete a user or click on Cancel button to terminate the action. | . | Edit: Click on Three Dots &gt; Edit which pops up a prefilled form, if want to edit any information regarding a particular Role, change the data and click on Save button. | . | Activate/Deactivate: Click on Three Dots &gt; Activate/Deactivate will change the Active Status of Role | . ",
    "url": "http://localhost:4000/user-management/admin/roles/index.html#actions",
    "relUrl": "/user-management/admin/roles/index.html#actions"
  },"268": {
    "doc": "Roles",
    "title": "Pagination:",
    "content": ". | Click on Row per page which populates some options which describe the number of Rows of users per page that should be displayed inside the table. | Describe number of pages available. | . ",
    "url": "http://localhost:4000/user-management/admin/roles/index.html#pagination",
    "relUrl": "/user-management/admin/roles/index.html#pagination"
  },"269": {
    "doc": "Users",
    "title": "Users",
    "content": "This section describes the Elysium number of users created and their details regarding active and inactive, their roles. And an Adminwillhave the access to create a new user, delete existinguseror activate or deactivate existing users and can assign roles to the users. ",
    "url": "http://localhost:4000/user-management/admin/users/index.html",
    "relUrl": "/user-management/admin/users/index.html"
  },"270": {
    "doc": "Users",
    "title": "Users Interface",
    "content": "Click on “Admin”inside bottom left side menu displaying username to access the user’s page. ",
    "url": "http://localhost:4000/user-management/admin/users/index.html#users-interface",
    "relUrl": "/user-management/admin/users/index.html#users-interface"
  },"271": {
    "doc": "Users",
    "title": "How to use:",
    "content": ". | There are Tabs inside Admin section, by default Users page is selected. | . ",
    "url": "http://localhost:4000/user-management/admin/users/index.html#how-to-use",
    "relUrl": "/user-management/admin/users/index.html#how-to-use"
  },"272": {
    "doc": "Users",
    "title": "Search bar:",
    "content": ". | Admin can search using users’ information like First name, Last Name, Email. | . ",
    "url": "http://localhost:4000/user-management/admin/users/index.html#search-bar",
    "relUrl": "/user-management/admin/users/index.html#search-bar"
  },"273": {
    "doc": "Users",
    "title": "Add New User: (Button)",
    "content": ". | This button is to create new user with user details. | On clicking this button, a form pops up with input fields to fill. | . ",
    "url": "http://localhost:4000/user-management/admin/users/index.html#add-new-user-button",
    "relUrl": "/user-management/admin/users/index.html#add-new-user-button"
  },"274": {
    "doc": "Users",
    "title": "Steps to create New User:",
    "content": ". | Input files like First Name, Last Name, Email can be typed and fill the details of the user. | . | Time zone: field which defines the users Time zone, it is a drop-down field which can be selected from available time Zone options. | . | Role: input field defines what role to assign for the user, this is a drop-down filed which has some predefined role options available to select. | . | Is Admin: Check box input file defines if the user is Admin or not, clicking on the check box gives a blue tick mark which describes the new user is an Admin. | . | Dashboard: drag and drop field which has available dashboards on the left and selected dashboards on the right, there are some dashboard options available on the left section need to drag and drop the required dashboard option on the right section. | . | Menu: selectable button options which has available menu as a transparent button with ‘+’ icon, to select which menus the user should have access click on the require menu button which turns it into Blue filled button with Tick icon. | . | Cancel &amp; Save: (Button) to create a user with filled details click on save button or if want to cancel user creation process click on cancel button. | . ",
    "url": "http://localhost:4000/user-management/admin/users/index.html#steps-to-create-new-user",
    "relUrl": "/user-management/admin/users/index.html#steps-to-create-new-user"
  },"275": {
    "doc": "Users",
    "title": "User Table:",
    "content": ". | This table provides information on user details like First Name, Last Name, Email, Admin, Time zone, Status and Actions options. | . ",
    "url": "http://localhost:4000/user-management/admin/users/index.html#user-table",
    "relUrl": "/user-management/admin/users/index.html#user-table"
  },"276": {
    "doc": "Users",
    "title": "Actions:",
    "content": ". | Click on Three dots populated on each row of a user which pops up options to perform an action on each user. | . | On click of Three Dots will pop up options of actions to be performed on a user. | . | Delete: Click on Three Dots &gt; Delete which gives a confirmation message on the screen to take a final confirmation if the delete action should be confirmed. | Click on Confirm option to delete a user or click on Cancel button to terminate the action. | . | Edit: Click on Three Dots &gt; Edit which pops up a prefilled form, if want to edit any information regarding a particular User, change the data and click on Save button. | . | Activate/Deactivate: Click on Three Dots &gt; Activate/Deactivate will change the Active Status of User | . ",
    "url": "http://localhost:4000/user-management/admin/users/index.html#actions",
    "relUrl": "/user-management/admin/users/index.html#actions"
  },"277": {
    "doc": "Users",
    "title": "Pagination:",
    "content": ". | Click on Row per page which populates some options which describe the number of Rows of users per page that should be displayed inside the table. | Describe number of pages available. | . ",
    "url": "http://localhost:4000/user-management/admin/users/index.html#pagination",
    "relUrl": "/user-management/admin/users/index.html#pagination"
  },"278": {
    "doc": "Data Connections",
    "title": "Data Connections",
    "content": "This section describes number of Data Connections available, not all users have access to all the Data Connections, an Admin will have access to this page to control accessibility of Dashboards for a user. An Admin can create new Data Connectionsand can delete existing Data Connections. ",
    "url": "http://localhost:4000/user-management/admin/data-connections/index.html",
    "relUrl": "/user-management/admin/data-connections/index.html"
  },"279": {
    "doc": "Data Connections",
    "title": "Data Connections Interface",
    "content": ". | Click on “Admin” inside bottom left side menu displaying username to access the Dashboard page. | By default, the Users page is selected, click on the Data Connections tab to access Data connections page. | . ",
    "url": "http://localhost:4000/user-management/admin/data-connections/index.html#data-connections-interface",
    "relUrl": "/user-management/admin/data-connections/index.html#data-connections-interface"
  },"280": {
    "doc": "Data Connections",
    "title": "How to use:",
    "content": ". | There are Tabs inside Admin section, by default Users page is selected. | Click on the Data Connections tab to access the Dashboard page. | . Search bar: . | Admin can search for specific Data Connection by Name, Data type or Source. | . ",
    "url": "http://localhost:4000/user-management/admin/data-connections/index.html#how-to-use",
    "relUrl": "/user-management/admin/data-connections/index.html#how-to-use"
  },"281": {
    "doc": "Data Connections",
    "title": "Add New Connection: (Button)",
    "content": ". | This button is to create a new Connection. | On clicking this button, a form pops up with input fields to fill. | . ",
    "url": "http://localhost:4000/user-management/admin/data-connections/index.html#add-new-connection-button",
    "relUrl": "/user-management/admin/data-connections/index.html#add-new-connection-button"
  },"282": {
    "doc": "Data Connections",
    "title": "Steps to create New Connection:",
    "content": ". | Database Type &amp; Timezone is a drop-down select input field which will have options to select. | . | Name, Account, Host URL, User, Database, Warehouse, Schema, Role and Password are mandatory text input fields to fill in the data related to new Data Connections. | . | Cancel &amp; Save: (Button) to create a Data Connection with filled details click on save button or if want to Terminate creation process click on cancel button. | . | This table provides information on Data Connections details. | . | Drop-down: action button on click will expand and reveal Hidden Data Connections Information. | . ",
    "url": "http://localhost:4000/user-management/admin/data-connections/index.html#steps-to-create-new-connection",
    "relUrl": "/user-management/admin/data-connections/index.html#steps-to-create-new-connection"
  },"283": {
    "doc": "Data Connections",
    "title": "Actions:",
    "content": ". | Click on Three dots populated on each row of a Data Connection which pops up options to perform an action on each Connection data. | . | Delete: Click on Three Dots &gt; Delete which gives a confirmation message on the screen to take a final confirmation if the delete action should be confirmed. | Click on Confirm option to delete a Connection or click on Cancel button to terminate the action. | . | Edit: Click on Three Dots &gt; Edit which pops up a prefilled form, if want to edit any information regarding a particular Data Connection change the data and click on Save button. | If you need to terminate the creation process, click on the Cancel button. | . | Activate/Deactivate: Click on Three Dots &gt; Activate/Deactivate will change the Active Status of Data Connection. | . Pagination: . | Click on Row per page which populates some options which describe the number of Rows of Data Connections per page that should be displayed inside the table. | Describe number of pages available. | . ",
    "url": "http://localhost:4000/user-management/admin/data-connections/index.html#actions",
    "relUrl": "/user-management/admin/data-connections/index.html#actions"
  },"284": {
    "doc": "Admin",
    "title": "Admin",
    "content": " ",
    "url": "http://localhost:4000/user-management/admin/index.html",
    "relUrl": "/user-management/admin/index.html"
  },"285": {
    "doc": "User Management",
    "title": "User Management",
    "content": "User Management Documentation . ",
    "url": "http://localhost:4000/user-management/index.html",
    "relUrl": "/user-management/index.html"
  },"286": {
    "doc": "User Profile",
    "title": "User Profile Interface",
    "content": "Click on “ Profile ” inside bottom left side menu displaying username to access the User Profile page. ",
    "url": "http://localhost:4000/user-management/ser-profile/index.html#user-profile-interface",
    "relUrl": "/user-management/ser-profile/index.html#user-profile-interface"
  },"287": {
    "doc": "User Profile",
    "title": "How to use:",
    "content": ". | First Name, Last Name, Email &amp; Tenant: are Text input fields which can be changed by typing new Information. | Email &amp; Tenant fields are non-changeable fields. | . | Time zone: Is drop-down field which has pre-defined values as options to collect. | . | Profile Picture: Click on the pencil icon which will populate a window of local drive where you can access local drive files. | . | Choose the right image file type ex: JPEGs/Jpg/Svg/Png. | After selecting the picture click on the Open Button. | . | Once the picture is selected it will be displayed in that section. | . | Update Password: (Button) to change the old password Click on Update password Button. | A form will pop up with input Fields. | . | There are three sections, Old Password, Password, Confirm Password. | Old password section has previous old password which cannot be changed. | Password sections need to fill new password. | Confirm Password section need to fill the same password entered inside Password filed. | Both password and Confirm Password should be similar and should match. | After entering a new password click on Update Password button to apply the changes. | If you need to Terminate Password changing process, click on Cancel Button. | . | Save: (Button) After adding all the user Details click on Save Button to apply the changes. | . ",
    "url": "http://localhost:4000/user-management/ser-profile/index.html#how-to-use",
    "relUrl": "/user-management/ser-profile/index.html#how-to-use"
  },"288": {
    "doc": "User Profile",
    "title": "User Profile",
    "content": " ",
    "url": "http://localhost:4000/user-management/ser-profile/index.html",
    "relUrl": "/user-management/ser-profile/index.html"
  },"289": {
    "doc": "Settings",
    "title": "Settings",
    "content": "This section describes the Elysium Page settings like Themechange. ",
    "url": "http://localhost:4000/user-management/settings/index.html",
    "relUrl": "/user-management/settings/index.html"
  },"290": {
    "doc": "Settings",
    "title": "Settings Interface",
    "content": "Click on “Settings” inside bottom left side menu displaying username to access theSettings page. ",
    "url": "http://localhost:4000/user-management/settings/index.html#settings-interface",
    "relUrl": "/user-management/settings/index.html#settings-interface"
  },"291": {
    "doc": "Settings",
    "title": "How to use:",
    "content": ". | There are Tabs inside the Settings page, by default General Settings tab is selected. | . ",
    "url": "http://localhost:4000/user-management/settings/index.html#how-to-use",
    "relUrl": "/user-management/settings/index.html#how-to-use"
  },"292": {
    "doc": "Settings",
    "title": "Theme:",
    "content": ". . | To change the Theme of the Application, click on the switch button to switch from Dark theme to Light theme. | . | After adding changes to settings Click on Save Button to confirm the changes done. | . ",
    "url": "http://localhost:4000/user-management/settings/index.html#theme",
    "relUrl": "/user-management/settings/index.html#theme"
  }
}
